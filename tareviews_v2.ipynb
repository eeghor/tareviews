{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.common.action_chains import ActionChains\n",
    "\n",
    "from collections import defaultdict\n",
    "import re\n",
    "import json\n",
    "import os\n",
    "import time\n",
    "import arrow\n",
    "import random\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import subprocess\n",
    "import zipfile\n",
    "\n",
    "from attraction import Attraction\n",
    "from review import Review\n",
    "from user import User\n",
    "\n",
    "import scattertext as st\n",
    "import spacy\n",
    "\n",
    "nlp = spacy.load('en')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    " class Trip:\n",
    "    \n",
    "    def __init__(self, filter):\n",
    "        \n",
    "        options = webdriver.ChromeOptions()\n",
    "        options.add_argument('--ignore-certificate-errors')\n",
    "        options.add_argument('--ignore-ssl-errors')\n",
    "        options.add_argument('--incognito')\n",
    "        options.add_argument('--start-maximized')\n",
    "        prefs = {\"profile.default_content_setting_values.notifications\" : 2}\n",
    "        options.add_experimental_option(\"prefs\",prefs)\n",
    "\n",
    "        options.add_argument('--headless')\n",
    "        \n",
    "        self.driver = webdriver.Chrome('webdriver/chromedriver', options=options)\n",
    "        \n",
    "        self.FILTREVS = defaultdict()\n",
    "        self.REVIEWS = defaultdict()\n",
    "        \n",
    "        # counter to see how many annoying things get killed\n",
    "        self.KILLED = defaultdict(int)\n",
    "        \n",
    "        self.FILTERS = filter\n",
    "        \n",
    "        print(f'filter: {\" | \".join([k + \":\" + str(v) for k, v in self.FILTERS.items() if v])}')\n",
    "        \n",
    "        self.DATA_DIR = 'data'\n",
    "        self.COLLECT_DIR = 'data-collected'\n",
    "        \n",
    "        if not os.path.exists(self.DATA_DIR):\n",
    "            os.mkdir(self.DATA_DIR)\n",
    "            \n",
    "        if not os.path.exists(self.COLLECT_DIR):\n",
    "            os.mkdir(self.COLLECT_DIR)\n",
    "        \n",
    "        self.LOCATION_IDS = json.load(open(os.path.join(self.DATA_DIR, 'tradvisor_location_ids.json')))\n",
    "        \n",
    "    def attr_id_from_url(self, url_):\n",
    "        \n",
    "        \"\"\"\n",
    "        extract attraction ID from attraction URL\n",
    "        \"\"\"\n",
    "        \n",
    "        try:\n",
    "            id_ = re.search(r'(?<=-)d\\d+(?=-)', url_).group(0)\n",
    "        except:\n",
    "            id_ = None\n",
    "            \n",
    "        return id_\n",
    "            \n",
    "    def do_click(self, e, max_=3):\n",
    "        \n",
    "        \"\"\"\n",
    "        try to click on element e and return True if it worked or False otherwise\n",
    "        \"\"\"\n",
    "        \n",
    "        # assume not click\n",
    "        _clicked = False\n",
    "        _c = 0\n",
    "\n",
    "        while (not _clicked) and (_c < max_):\n",
    "\n",
    "            try:\n",
    "                e.click()\n",
    "                _clicked = True\n",
    "            except:\n",
    "                try:\n",
    "                    self.driver.find_element_by_css_selector('span.ui_overlay>div.ui_close_x').click()\n",
    "                    self.KILLED['overlay'] += 1\n",
    "                except:\n",
    "                    # try to catch and close all sliders\n",
    "                    els = list(self.driver.find_elements_by_css_selector('div[class^=\"QSISlider\"]>div'))\n",
    "                    for i, d in enumerate(els):\n",
    "                        if d.text.strip().lower() == 'Not right now, thanks.'.strip().lower():\n",
    "                            try:\n",
    "                                els[i-1].click()\n",
    "                                self.KILLED['slide'] += 1\n",
    "                                break\n",
    "                            except:\n",
    "                                continue\n",
    "                    for _ in self.driver.find_elements_by_css_selector('div.sbx_close[onclick]'):\n",
    "                        try:\n",
    "                            _.click()\n",
    "                            self.KILLED['infobar'] += 1\n",
    "                        except:\n",
    "                            pass        \n",
    "            _c += 1\n",
    "\n",
    "        return _clicked\n",
    "    \n",
    "    def process_paginator(self, pg, off=30, pref='oa'):\n",
    "        \n",
    "        p_numbers = [int(s.text.strip()) for s in pg.find_elements_by_css_selector('div') if s.text.strip().isdigit()]\n",
    "        \n",
    "        if p_numbers:\n",
    "            total_pages = p_numbers[-1]\n",
    "        else:\n",
    "            raise Exception('no pages in paginator!')\n",
    "        \n",
    "        current_page_url = self.driver.current_url\n",
    "        last_page_url = self.driver.current_url\n",
    "        \n",
    "        page_urls = [current_page_url]\n",
    "        \n",
    "        for _ in pg.find_elements_by_css_selector('div>a'):\n",
    "            if _.text.isdigit():\n",
    "                last_page_url = _.get_attribute('href')\n",
    "                \n",
    "        if total_pages > 1:\n",
    "            for i in range(1, total_pages):\n",
    "                # starts from page 2 (page 1 has no -oa[number]- part)\n",
    "                page_urls.append(re.sub('Activities-', 'Activities-' + pref + str(off*i) + '-', current_page_url))\n",
    "                \n",
    "        return total_pages, page_urls\n",
    "        \n",
    "    def get_attraction_pages(self, loc):\n",
    "        \n",
    "        \"\"\"\n",
    "        go to the home page for location loc and collect all attractions; if loc is a state, collect attractions\n",
    "        for every location in that state\n",
    "        \n",
    "        \"\"\"\n",
    "        \n",
    "        self.MAIN_LOCATION = loc\n",
    "        \n",
    "        # home_urls will be a list of tuples like \n",
    "        # [('tasmania', 'hobart', 'https://www.tripadvisor.com.au/Home-g255097'), \n",
    "        #  ('tasmania', 'launceston', 'https://www.tripadvisor.com.au/Home-g255344')...\n",
    "        \n",
    "        home_urls = []\n",
    "        \n",
    "        self.collected_attractions = defaultdict(lambda: defaultdict(lambda: defaultdict()))\n",
    "        \n",
    "        \"\"\"\n",
    "        {'tasmania': {'hobart': {attr_id: {name: market,\n",
    "                                            url: 'https:/www...'}}}\n",
    "        \"\"\"\n",
    "        \n",
    "        # if loc is state\n",
    "        if self.MAIN_LOCATION in self.LOCATION_IDS:\n",
    "            for city in self.LOCATION_IDS[loc]:\n",
    "                home_urls.append((self.MAIN_LOCATION, city, f'https://www.tripadvisor.com.au/Home-{self.LOCATION_IDS[loc][city]}'))\n",
    "        else:\n",
    "            for state_ in self.LOCATION_IDS:\n",
    "                if self.MAIN_LOCATION in self.LOCATION_IDS[state_]:\n",
    "                    home_urls.append((state_, self.MAIN_LOCATION, f'https://www.tripadvisor.com.au/Home-{self.LOCATION_IDS[state_][loc]}'))\n",
    "                    \n",
    "        if not home_urls:\n",
    "            print(f'no attractions to pick for {loc.upper()}!')\n",
    "            return self\n",
    "        \n",
    "        for state_, city_, homeurl in home_urls:\n",
    "            \n",
    "            print(f'collecting attractions for {city_.upper()}, {state_.upper()}...')\n",
    "            \n",
    "            self.driver.get(homeurl)\n",
    "            \n",
    "            # ---- find and click the Things to Do icon; assume it MUST be there\n",
    "            \n",
    "            thingstodo_clicked = False\n",
    "            \n",
    "            while not thingstodo_clicked:\n",
    "                \n",
    "                try:\n",
    "                    things_to_do_icon = WebDriverWait(self.driver, 10) \\\n",
    "                                .until(EC.presence_of_element_located((By.CSS_SELECTOR, 'span.ui_icon.attractions + span')))\n",
    "                except:\n",
    "                    raise Exception('failed to find Things to do icon!')\n",
    "                \n",
    "                if things_to_do_icon.text.strip().lower() != 'Things to do'.strip().lower():\n",
    "                    continue\n",
    "                    \n",
    "                res = self.do_click(things_to_do_icon)\n",
    "                    \n",
    "                if not res:\n",
    "                    print('failed to click Things to do icon! retrying..')\n",
    "                else:\n",
    "                    thingstodo_clicked = True\n",
    "                \n",
    "            # ------- ok, so clicked the icon; now the question is whether there are many 'top' things to \n",
    "            # do or just a few; the latter means no need to look for the See More button\n",
    "            \n",
    "            moveon = False\n",
    "            few_attractions = False\n",
    "            \n",
    "            # try to click See More first\n",
    "            \n",
    "            while 1:\n",
    "                \n",
    "                try:\n",
    "                    c_mo = WebDriverWait(self.driver, 10) \\\n",
    "                            .until(EC.element_to_be_clickable((By.CSS_SELECTOR, \n",
    "                                    'div[class|=\"attractions-attraction-overview-main-TopPOIs__see_more\"]')))\n",
    "                except:\n",
    "                    # if there's no See More it's just 1 page with attractions\n",
    "                    page_urls = [self.driver.current_url]\n",
    "                    few_attractions = True\n",
    "                    break\n",
    "                \n",
    "                seeless = False\n",
    "                \n",
    "                while not seeless:\n",
    "                    \n",
    "                    res = self.do_click(c_mo)\n",
    "                    \n",
    "                    # didn't click..\n",
    "                    if not res:\n",
    "\n",
    "                        try:\n",
    "                            # there is this See More button but still folded, so apparently we didn't click properly\n",
    "                            self.driver.find_element_by_css_selector('span.ui_icon.single-chevron-down')\n",
    "                        except:\n",
    "                            seeless = True\n",
    "                    # look like clicked See More..\n",
    "                    else:\n",
    "                        try:\n",
    "                            WebDriverWait(self.driver, 10) \\\n",
    "                                .until(EC.presence_of_element_located((By.CSS_SELECTOR, \n",
    "                                    'span.ui_icon.single-chevron-up')))\n",
    "\n",
    "                            seeless = True\n",
    "                        except:\n",
    "                            print('no See Less, need to click See more again')\n",
    "                break                \n",
    "            \n",
    "            # paginator only available if there are many attractions; however, there may be no paginator if See More\n",
    "            # was clicked but there are still too few attractions\n",
    "            \n",
    "            if not few_attractions:\n",
    "                \n",
    "                try:\n",
    "                    pg = WebDriverWait(self.driver, 10) \\\n",
    "                            .until(EC.presence_of_element_located((By.CSS_SELECTOR, \n",
    "                                    'div[class|=\"attractions-attraction-overview-main-Pagination__container\"]')))\n",
    "                except:\n",
    "                    pg = None\n",
    "                \n",
    "                if pg:\n",
    "                    total_pages, page_urls = self.process_paginator(pg) \n",
    "                else:\n",
    "                    page_urls = [self.driver.current_url]\n",
    "\n",
    "            print('visiting attraction pages..')\n",
    "\n",
    "            for i, attr_page_url in enumerate(page_urls, 1):\n",
    "                \n",
    "                print(f'page {i}/{len(page_urls)}..', end='')\n",
    "\n",
    "                if attr_page_url != self.driver.current_url:\n",
    "                    self.driver.get(attr_page_url)\n",
    "                \n",
    "                if i == 1:\n",
    "                    \n",
    "                    attr_topick_css = 'div[class|=\"attractions-attraction-overview-pois-PoiGrid__wrapper\"]' + \\\n",
    "                                      '>li[class^=\"attractions-attraction-overview-pois-PoiCard__item\"]' + \\\n",
    "                                      '>div[class|=\"attractions-attraction-overview-pois-PoiCard__card_info\"]'\n",
    "                            \n",
    "                    attr_topick = len(self.driver.find_elements_by_css_selector(attr_topick_css))\n",
    "                    \n",
    "                    while attr_topick:\n",
    "                        \n",
    "                        for attr_card in self.driver.find_elements_by_css_selector(attr_topick_css):\n",
    "\n",
    "                            try:\n",
    "                                url_ = attr_card.find_element_by_css_selector('div>a[class|=\"attractions-attraction-overview-pois-PoiInfo__name\"]') \\\n",
    "                                                        .get_attribute('href')\n",
    "                            except:\n",
    "                                print('didn\\'t get attraction url! moving on to next attraction card..')\n",
    "                                continue\n",
    "                            \n",
    "                            id_ = self.attr_id_from_url(url_)\n",
    "                            \n",
    "                            if not id_:\n",
    "                                print('failed to extract attraction id!')\n",
    "                                continue\n",
    "                            \n",
    "                            try:\n",
    "                                self.collected_attractions[state_][city_][id_] = {'url': url_}\n",
    "                                attr_topick -= 1\n",
    "                            except:\n",
    "                                pass\n",
    "\n",
    "                elif i > 1:\n",
    "                    \n",
    "                    attr_topick_css = 'div.attraction_list>div' + \\\n",
    "                                      '>div>div.listing>div.listing_details>div.listing_info'\n",
    "                        \n",
    "                    attr_topick = len(self.driver.find_elements_by_css_selector(attr_topick_css))\n",
    "                    \n",
    "                    while attr_topick:\n",
    "                        \n",
    "                        for attr_card in self.driver.find_elements_by_css_selector(attr_topick_css):\n",
    "\n",
    "                            try:\n",
    "                                url_ = attr_card.find_element_by_css_selector('div.tracking_attraction_title.listing_title>a').get_attribute('href')\n",
    "                            except:\n",
    "                                print('didn\\'t get attraction url! moving on to next attraction card..')\n",
    "                                continue\n",
    "                                \n",
    "                            try:\n",
    "                                id_ = re.search(r'(?<=-)d\\d+(?=-)', url_).group(0)\n",
    "                            except:\n",
    "                                print('failed to extract attraction id!')\n",
    "                                continue\n",
    "                            \n",
    "                            try:\n",
    "                                self.collected_attractions[state_][city_][id_] = {'url': url_}\n",
    "                                attr_topick -= 1\n",
    "                            except:\n",
    "                                pass\n",
    "            \n",
    "                print('ok')\n",
    "    \n",
    "        return self\n",
    "\n",
    "    def select_filters(self) -> int:\n",
    "        \n",
    "        \"\"\"\n",
    "        apply filter on the attraction page and return the number of reviews available\n",
    "        after the filter has been applied\n",
    "        \"\"\"\n",
    "        \n",
    "        d = {'traveller_rating': {'data-name': 'ta_rating',\n",
    "                                  'input-values': {'Excellent': '5',\n",
    "                                                   'Very good': '4',\n",
    "                                                   'Average': '3',\n",
    "                                                   'Poor': '2',\n",
    "                                                   'Terrible': '1'},\n",
    "                                 'pick': self.FILTERS['traveller_rating']},\n",
    "            'traveller_type': {'data-name': 'traveler_filter',\n",
    "                               'input-values': {'Families': '3',\n",
    "                                                'Couples': '2',\n",
    "                                                'Solo': '5',\n",
    "                                                'Business': '1',\n",
    "                                                'Friends': '4'},\n",
    "                              'pick': self.FILTERS['traveller_type']},\n",
    "            'time_of_year': {'data-name': 'season',\n",
    "                             'input-values': {'Mar-May': '1',\n",
    "                                              'Jun-Aug': '2',\n",
    "                                              'Sep-Nov': '3',\n",
    "                                              'Dec-Feb': '4'},\n",
    "                            'pick': self.FILTERS['time_of_year']},\n",
    "            'language': {'data-name': 'language',\n",
    "                         'input-values': {'English': 'en',\n",
    "                                          'Japanese': 'ja'},\n",
    "                         'pick': self.FILTERS['language']}}\n",
    "\n",
    "        def is_selected(css_selector_st):\n",
    "\n",
    "            try:\n",
    "                WebDriverWait(self.driver, 5) \\\n",
    "                            .until(EC.presence_of_element_located((By.CSS_SELECTOR, \n",
    "                                                                   css_selector_st + '>input[checked=\"checked\"]')))\n",
    "                return True\n",
    "\n",
    "            except:\n",
    "                return False\n",
    "\n",
    "        def _click(css_selector_st, max_attempts=3):\n",
    "\n",
    "            times_tried = 0\n",
    "\n",
    "            flag_before = is_selected(css_selector_st)\n",
    "            flag_after = flag_before\n",
    "\n",
    "            while (times_tried <= max_attempts) and (flag_after == flag_before):\n",
    "\n",
    "                times_tried += 1   \n",
    "\n",
    "                try:\n",
    "                    e = WebDriverWait(self.driver, 20) \\\n",
    "                            .until(EC.element_to_be_clickable((By.CSS_SELECTOR, css_selector_st)))\n",
    "                except:\n",
    "                    e = None\n",
    "                    print(f'failed to find {css_selector_st}!')\n",
    "                \n",
    "                if e:\n",
    "                    res = self.do_click(e)\n",
    "\n",
    "                flag_after = is_selected(css_selector_st)    \n",
    "\n",
    "            return (flag_after != flag_before)\n",
    "\n",
    "        for filt in d:\n",
    "\n",
    "            value = d[filt]['pick']\n",
    "            \n",
    "            # note that even if value is None, attempt to uncheck everything that might be checked\n",
    "            to_uncheck = [other_value for other_value in d[filt]['input-values'] if other_value != value]\n",
    "\n",
    "            if to_uncheck:\n",
    "\n",
    "                for other_value in to_uncheck:\n",
    "\n",
    "                    tr_pick = d[filt]['input-values'][other_value]\n",
    "                    dname = d[filt]['data-name']\n",
    "                    st = f'div.choices[data-name=\"{dname}\"]>div[data-value=\"{tr_pick}\"]'\n",
    "\n",
    "                    if is_selected(st):\n",
    "                        res = _click(st)\n",
    "\n",
    "            if value:\n",
    "\n",
    "                tr_pick = d[filt]['input-values'][value]\n",
    "                dname = d[filt]['data-name']\n",
    "                st = f'div.choices[data-name=\"{dname}\"]>div[data-value=\"{tr_pick}\"]'\n",
    "\n",
    "                if is_selected(st):\n",
    "                    continue\n",
    "                else:\n",
    "                    _selected =  _click(st)\n",
    "\n",
    "        try:\n",
    "            lang_code = d['language']['input-values'][d['language']['pick']] \n",
    "            css_count = f'div.choices[data-name=\"language\"]>div[data-value=\"{lang_code}\"]>label.label>span.count'\n",
    "            c_txt = WebDriverWait(self.driver, 6) \\\n",
    "                            .until(EC.presence_of_element_located((By.CSS_SELECTOR, css_count))).text.strip()\n",
    "            c = int(re.sub(r'[(,)]','',c_txt))\n",
    "        except:\n",
    "            # if no review count it's because there are not reviews left after filtering\n",
    "            return 0\n",
    "            \n",
    "        return int(c)\n",
    "    \n",
    "    def get_reviews_this_attraction(self, attr_url, min_total_reviews):\n",
    "        \n",
    "        # first go to the attraction page\n",
    "        self.driver.get(attr_url)\n",
    "        \n",
    "        a_id = self.attr_id_from_url(attr_url)\n",
    "        \n",
    "        attr_details = defaultdict(name=None, total_reviews=None, category=None, rating_chart=None)\n",
    "                    \n",
    "        try:\n",
    "            attr_details['name'] = self.driver.find_element_by_css_selector('div.attractionsHeader>h1#HEADING').text\n",
    "        except:\n",
    "            try:\n",
    "                # it's probably a tour provider\n",
    "                tour_operator = self.driver.find_element_by_css_selector('h1[id=\"HEADING\"][class|=\"attractions-supplier-profile-\"]').text.strip()\n",
    "                print(f'looks like a tour operator: {tour_operator}')\n",
    "            except:\n",
    "                pass\n",
    "            \n",
    "        # if this is attraction without name, something is wrong and we are not collecting anything\n",
    "        if not attr_details['name']:\n",
    "            return None\n",
    "        \n",
    "        # how namy reviews does this attractio have?\n",
    "        # if there's no rating (so no reviews) simply return 0 reviews right away\n",
    "        try:\n",
    "            self.driver.find_element_by_css_selector('div.section.rating>a.ui_bubble_rating.noReviewsBubbles')\n",
    "            revs = 0\n",
    "        except BaseException as e:\n",
    "            # so there are some reviews..\n",
    "            try:\n",
    "                # 21,121 Reviews\n",
    "                revs = int(self.driver.find_element_by_css_selector('div.ratingContainer>a>span.reviewCount') \\\n",
    "                            .text.replace(',','').split()[0])\n",
    "            except:\n",
    "                print('failed to find the total number of reviews!')\n",
    "                revs = 0\n",
    "        \n",
    "        if revs < min_total_reviews:\n",
    "            # too few reviews, doesn't make sense to proceed with this attraction\n",
    "            print(f'only {revs:,} reviews, skipping..')\n",
    "            return None\n",
    "        \n",
    "        # save total reviews for this attraction after filtering\n",
    "        nreviews_filtered = self.select_filters()\n",
    "        \n",
    "        print(f'filtered reviews: {nreviews_filtered:,}')\n",
    "\n",
    "        if not nreviews_filtered:\n",
    "            print('skipping..')\n",
    "            return None\n",
    "\n",
    "        try:\n",
    "            attr_details['total_reviews'] = self.driver.find_element_by_css_selector('div.ratingContainer').text.lower()\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "        try:\n",
    "            attr_details['category'] = self.driver.find_element_by_css_selector('span.attractionCategories').text\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "        try:\n",
    "            attr_details['rating_chart'] = [tuple(l.strip().split('\\n')) for l in self.driver.find_element_by_css_selector('ul.ratings_chart').text.split('%') if l.strip()]\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "        # reviews for THIS ATTRACTION\n",
    "        reviews = defaultdict(lambda: defaultdict())\n",
    "        reviews_on_page = [0]\n",
    "        \n",
    "        # keep going until total collected reviews reaches total filtered reviews\n",
    "        while len(reviews) < nreviews_filtered:\n",
    "\n",
    "            try:\n",
    "                reviews_this_page = int(WebDriverWait(self.driver, 10) \\\n",
    "                    .until(EC.visibility_of_element_located((By.CSS_SELECTOR, \n",
    "                            'div[data-contextchoice=\"DETAIL\"]>div.pagination-details'))).text.split('-')[1].strip().split()[0]) \n",
    "            except:\n",
    "                if nreviews_filtered <= 10:\n",
    "                    reviews_this_page = nreviews_filtered\n",
    "                else:\n",
    "                    try:\n",
    "                        # just count rating timestamps if any\n",
    "                        reviews_this_page = len(self.driver.find_elements_by_css_selector('span.ratingDate'))\n",
    "                    except:\n",
    "                        raise Exception('failed to pick the number of reviews on this page!') \n",
    "            \n",
    "            reviews_on_page.append(reviews_this_page)\n",
    "            \n",
    "            to_pick = reviews_on_page[-1] - reviews_on_page[-2]\n",
    "            \n",
    "            picked_reviews = set()\n",
    "\n",
    "            while len(picked_reviews) < to_pick:\n",
    "                \n",
    "                # first unfold all reviews on the page\n",
    "\n",
    "                for c in self.driver.find_elements_by_css_selector('div.entry>p.partial_entry>span[class~=\"ulBlueLinks\"][onclick]'):\n",
    "\n",
    "                    self.do_click(c)\n",
    "\n",
    "                # and now collect all full review texts\n",
    "                review_ids_this_page = set()\n",
    "        \n",
    "                n_review_blocks = len(self.driver.find_elements_by_css_selector('div[class=\"reviewSelector\"][id^=\"review\"]'))\n",
    "                \n",
    "                while len(review_ids_this_page) < n_review_blocks:\n",
    "                        \n",
    "                        for c in self.driver.find_elements_by_css_selector('div[class=\"reviewSelector\"][id^=\"review\"]'):\n",
    "                            \n",
    "                            try:\n",
    "                                _id = c.get_attribute('data-reviewid')\n",
    "                            except:\n",
    "                                continue\n",
    "                                \n",
    "                            if _id:\n",
    "                                review_ids_this_page.add(_id)\n",
    "                            else:\n",
    "                                try:\n",
    "                                    # id here looks like review_489766616\n",
    "                                    _id = c.get_attribute('id').split('_')[-1]\n",
    "                                except BaseException as e:\n",
    "                                    print(str(e))\n",
    "                \n",
    "                # a set of review ids to collect on this page\n",
    "                review_ids_to_collect_this_page = review_ids_this_page - set(reviews)\n",
    "\n",
    "                if review_ids_to_collect_this_page:\n",
    "\n",
    "                    tot_revs = len(review_ids_to_collect_this_page)\n",
    "\n",
    "                else:\n",
    "                    tot_revs = 0\n",
    "                    print('no new reviews on this page!')\n",
    "\n",
    "                p = 0\n",
    "\n",
    "                while p < tot_revs:\n",
    "\n",
    "                    for c in self.driver.find_elements_by_css_selector('div.reviewSelector'):        \n",
    "\n",
    "                        try:\n",
    "\n",
    "                            review_id = c.get_attribute('data-reviewid')\n",
    "                            \n",
    "                            if not review_id:\n",
    "                                continue\n",
    "\n",
    "                            if review_id in review_ids_to_collect_this_page:\n",
    "\n",
    "                                reviews[review_id]['text'] = c.find_element_by_css_selector('div>div>div.entry>p.partial_entry').text.strip()\n",
    "                                \n",
    "                                infotext_css = 'div.member_info>div>div.info_text'\n",
    "                                \n",
    "                                try:\n",
    "                                    # this is where a username should sit\n",
    "                                    username = c.find_element_by_css_selector(infotext_css).text.split('\\n')[0]\n",
    "                                except:\n",
    "                                    # it turns out that sometimes there are legacy anonymous users called\n",
    "                                    # A TripAdvisor Member; check if it's one of these - note a slightly different\n",
    "                                    # structure\n",
    "                                    try:\n",
    "                                        username = c.find_element_by_css_selector('div.member_info>div.info_text').text.split('\\n')[0]\n",
    "                                        if 'member' in username.lower():\n",
    "                                            print(f'found an anonymous user called {username}')\n",
    "                                    except:\n",
    "                                        break\n",
    "                                \n",
    "                                reviews[review_id]['user'] = username\n",
    "                                reviews[review_id]['user_profile_url'] = f'https://www.tripadvisor.com.au/Profile/{username}'\n",
    "                                \n",
    "                                try:\n",
    "                                    userloc = c.find_element_by_css_selector(infotext_css + '>div.userLoc').text\n",
    "                                    reviews[review_id]['user_loc'] = userloc\n",
    "                                except:\n",
    "                                    reviews[review_id]['user_loc'] = None\n",
    "                                    \n",
    "                                try:\n",
    "                                    reviews[review_id]['review_date'] = arrow.get(c.find_element_by_css_selector('div>div>div>span.ratingDate')\n",
    "                                                                                    .get_attribute('title'), 'D MMMM YYYY').format('YYYY-MM-DD')\n",
    "                                except:\n",
    "                                    reviews[review_id]['review_date'] = None\n",
    "                                    \n",
    "                                try:\n",
    "                                    reviews[review_id]['experience_date'] = arrow.get(c.find_element_by_css_selector('div>div>div>div.prw_reviews_stay_date_hsx').text, 'MMMM YYYY').format('YYYY-MM')\n",
    "                                except:\n",
    "                                    reviews[review_id]['experience_date'] = None\n",
    "                                \n",
    "                                try:\n",
    "                                    class_full = c.find_element_by_css_selector('div>div>div>span.ui_bubble_rating').get_attribute('class')\n",
    "                                    \n",
    "                                    reviews[review_id]['rating'] = int(re.search(r'(?<=_)\\d{1}', class_full).group(0))\n",
    "                                except:\n",
    "                                    reviews[review_id]['rating'] = None\n",
    "                                          \n",
    "                                reviews[review_id]['attr_name'] = attr_details['name']\n",
    "                                reviews[review_id]['attr_id'] = a_id\n",
    "                                reviews[review_id]['attr_loc'] = city_\n",
    "                                \n",
    "                                # remove this reviews id from the set of review ids to collct\n",
    "                                review_ids_to_collect_this_page -= {review_id}\n",
    "                                # and put this id into the set of already collected ids\n",
    "                                picked_reviews.add(review_id)\n",
    "                                # increment the total of collected reviews on this page\n",
    "                                p += 1\n",
    "\n",
    "                            else:\n",
    "                                continue\n",
    "                        except:\n",
    "                            continue\n",
    "        return reviews\n",
    "    \n",
    "    def _review_count_this_attr(self) -> int:\n",
    "        \n",
    "        \"\"\"\n",
    "        assuming you're on the attraction page, returns how many reviews there are in total for this attractions\n",
    "        \"\"\"\n",
    "        \n",
    "        revs = 0\n",
    "        \n",
    "        # if there's no rating (so no reviews) simply return 0 reviews right away\n",
    "        \n",
    "        try:\n",
    "            # if this one if present there are no reviews\n",
    "            self.driver.find_element_by_css_selector('div.section.rating>a.ui_bubble_rating.noReviewsBubbles')\n",
    "            return revs\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "        # otherwise, there have to be some reviews..\n",
    "        \n",
    "        try:\n",
    "            # the piece of text that says how many reviews looks like this: 21,121 Reviews\n",
    "            revs = int(self.driver.find_element_by_css_selector('div.ratingContainer>a>span.reviewCount') \\\n",
    "                            .text.replace(',','').split()[0])\n",
    "        except:\n",
    "            print('failed to find the total number of reviews!')\n",
    "        \n",
    "        return revs\n",
    "        \n",
    "            \n",
    "    def get_reviews_from_attraction_pages(self, min_total_reviews=50):\n",
    "        \n",
    "        # total number of attractions to check out\n",
    "        natt = len({a_id for state_ in self.collected_attractions\n",
    "                        for city_ in self.collected_attractions[state_]\n",
    "                             for a_id in self.collected_attractions[state_][city_]})\n",
    "        \n",
    "        # counter for processed attractions\n",
    "        catt = 0\n",
    "        \n",
    "        for state_ in self.collected_attractions:\n",
    "            for city_ in self.collected_attractions[state_]:\n",
    "                for a_id in self.collected_attractions[state_][city_]:\n",
    "                    \n",
    "                    catt += 1\n",
    "                        \n",
    "                    self.driver.get(self.collected_attractions[state_][city_][a_id]['url'])\n",
    "                    \n",
    "                    attr_details = defaultdict(name=None, total_reviews=None, category=None, rating_chart=None)\n",
    "                    \n",
    "                    try:\n",
    "                        attr_details['name'] = self.driver.find_element_by_css_selector('div.attractionsHeader>h1#HEADING').text\n",
    "                        self.collected_attractions[state_][city_][a_id]['attr_name'] = attr_details['name']\n",
    "                    except:\n",
    "                        try:\n",
    "                            # it's probably a tour provider\n",
    "                            tour_operatior_name = self.driver.find_element_by_css_selector('h1[id=\"HEADING\"][class|=\"attractions-supplier-profile-\"]').text.strip()\n",
    "                            print(f'looks like a tour operator: {tour_operatior_name}; skipping')\n",
    "                            continue\n",
    "                        except:\n",
    "                            print(f'failed to find name for attraction {a_id}, skipping..')\n",
    "                            continue\n",
    "                            \n",
    "                    print(f'attraction #{catt:,}/{natt:,}: [ID: {a_id}][{attr_details[\"name\"]}]...')\n",
    "                    \n",
    "                    # how many reviews does this attraction have?\n",
    "                    revs = self._review_count_this_attr()\n",
    "                    \n",
    "                    if revs < min_total_reviews:\n",
    "                        # too few reviews, doesn't make sense to proceed with this attraction\n",
    "                        print(f'only {revs:,} reviews, skipping..')\n",
    "                        continue\n",
    "                    \n",
    "                    # save total reviews for this attraction after filtering\n",
    "                    self.FILTREVS[a_id] = self.select_filters()\n",
    "                    \n",
    "                    print(f'filtered reviews: {self.FILTREVS[a_id]:,}')\n",
    "\n",
    "                    if not self.FILTREVS[a_id]:\n",
    "                        print('skipping..')\n",
    "                        continue\n",
    "\n",
    "                    try:\n",
    "                        attr_details['total_reviews'] = self.driver.find_element_by_css_selector('div.ratingContainer').text.lower()\n",
    "                    except:\n",
    "                        pass\n",
    "\n",
    "                    try:\n",
    "                        attr_details['category'] = self.driver.find_element_by_css_selector('span.attractionCategories').text\n",
    "                    except:\n",
    "                        pass\n",
    "\n",
    "                    try:\n",
    "                        attr_details['rating_chart'] = [tuple(l.strip().split('\\n')) for l in self.driver.find_element_by_css_selector('ul.ratings_chart').text.split('%') if l.strip()]\n",
    "                    except:\n",
    "                        pass\n",
    "\n",
    "                    # reviews for THIS ATTRACTION\n",
    "                    reviews = defaultdict(lambda: defaultdict())\n",
    "                    reviews_on_page = [0]\n",
    "\n",
    "                    while len(reviews) < self.FILTREVS[a_id]:\n",
    "\n",
    "                        try:\n",
    "                            reviews_this_page = int(WebDriverWait(self.driver, 10) \\\n",
    "                                .until(EC.visibility_of_element_located((By.CSS_SELECTOR, \n",
    "                                        'div[data-contextchoice=\"DETAIL\"]>div.pagination-details'))).text.split('-')[1].strip().split()[0]) \n",
    "                        except:\n",
    "                            if self.FILTREVS[a_id] <= 10:\n",
    "                                reviews_this_page = self.FILTREVS[a_id]\n",
    "                            else:\n",
    "                                try:\n",
    "                                    # just count rating timestamps if any\n",
    "                                    reviews_this_page = len(self.driver.find_elements_by_css_selector('span.ratingDate'))\n",
    "                                except:\n",
    "                                    raise Exception('failed to pick the number of reviews on this page!') \n",
    "                        \n",
    "                        reviews_on_page.append(reviews_this_page)\n",
    "                        \n",
    "                        to_pick = reviews_on_page[-1] - reviews_on_page[-2]\n",
    "                        \n",
    "                        picked_reviews = set()\n",
    "\n",
    "                        while len(picked_reviews) < to_pick:\n",
    "                            \n",
    "                            # first unfold all reviews on the page\n",
    "\n",
    "                            for c in self.driver.find_elements_by_css_selector('div.entry>p.partial_entry>span[class~=\"ulBlueLinks\"][onclick]'):\n",
    "\n",
    "                                self.do_click(c)\n",
    "\n",
    "                            # and now collect all full review texts\n",
    "                            review_ids_this_page = set()\n",
    "                \n",
    "                            n_review_blocks = len(self.driver.find_elements_by_css_selector('div[class=\"reviewSelector\"][id^=\"review\"]'))\n",
    "                            \n",
    "                            while len(review_ids_this_page) < n_review_blocks:\n",
    "                                    \n",
    "                                    for c in self.driver.find_elements_by_css_selector('div[class=\"reviewSelector\"][id^=\"review\"]'):\n",
    "                                        \n",
    "                                        try:\n",
    "                                            _id = c.get_attribute('data-reviewid')\n",
    "                                        except:\n",
    "                                            continue\n",
    "                                            \n",
    "                                        if _id:\n",
    "                                            review_ids_this_page.add(_id)\n",
    "                                        else:\n",
    "                                            try:\n",
    "                                                # id here looks like review_489766616\n",
    "                                                _id = c.get_attribute('id').split('_')[-1]\n",
    "                                            except BaseException as e:\n",
    "                                                print(str(e))\n",
    "                            \n",
    "                            # a set of review ids to collect on this page\n",
    "                            review_ids_to_collect_this_page = review_ids_this_page - set(reviews)\n",
    "\n",
    "                            if review_ids_to_collect_this_page:\n",
    "\n",
    "                                tot_revs = len(review_ids_to_collect_this_page)\n",
    "\n",
    "                            else:\n",
    "                                tot_revs = 0\n",
    "                                print('no new reviews on this page!')\n",
    "\n",
    "                            p = 0\n",
    "\n",
    "                            while p < tot_revs:\n",
    "\n",
    "                                for c in self.driver.find_elements_by_css_selector('div.reviewSelector'):        \n",
    "\n",
    "                                    try:\n",
    "\n",
    "                                        review_id = c.get_attribute('data-reviewid')\n",
    "                                        \n",
    "                                        if not review_id:\n",
    "                                            continue\n",
    "\n",
    "                                        if review_id in review_ids_to_collect_this_page:\n",
    "\n",
    "                                            reviews[review_id]['text'] = c.find_element_by_css_selector('div>div>div.entry>p.partial_entry').text.strip()\n",
    "                                            \n",
    "                                            infotext_css = 'div.member_info>div>div.info_text'\n",
    "                                            \n",
    "                                            try:\n",
    "                                                # this is where a username should sit\n",
    "                                                username = c.find_element_by_css_selector(infotext_css).text.split('\\n')[0]\n",
    "                                            except:\n",
    "                                                # it turns out that sometimes there are legacy anonymous users called\n",
    "                                                # A TripAdvisor Member; check if it's one of these - note a slightly different\n",
    "                                                # structure\n",
    "                                                try:\n",
    "                                                    username = c.find_element_by_css_selector('div.member_info>div.info_text').text.split('\\n')[0]\n",
    "                                                    if 'member' in username.lower():\n",
    "                                                        print(f'found an anonymous user called {username}')\n",
    "                                                except:\n",
    "                                                    break\n",
    "                                            \n",
    "                                            reviews[review_id]['user'] = username\n",
    "                                            reviews[review_id]['user_profile_url'] = f'https://www.tripadvisor.com.au/Profile/{username}'\n",
    "                                            \n",
    "                                            try:\n",
    "                                                userloc = c.find_element_by_css_selector(infotext_css + '>div.userLoc').text\n",
    "                                                reviews[review_id]['user_loc'] = userloc\n",
    "                                            except:\n",
    "                                                reviews[review_id]['user_loc'] = None\n",
    "                                                \n",
    "                                            try:\n",
    "                                                reviews[review_id]['review_date'] = arrow.get(c.find_element_by_css_selector('div>div>div>span.ratingDate')\n",
    "                                                                                                .get_attribute('title'), 'D MMMM YYYY').format('YYYY-MM-DD')\n",
    "                                            except:\n",
    "                                                reviews[review_id]['review_date'] = None\n",
    "                                                \n",
    "                                            try:\n",
    "                                                reviews[review_id]['experience_date'] = arrow.get(c.find_element_by_css_selector('div>div>div>div.prw_reviews_stay_date_hsx').text, 'MMMM YYYY').format('YYYY-MM')\n",
    "                                            except:\n",
    "                                                reviews[review_id]['experience_date'] = None\n",
    "                                            \n",
    "                                            try:\n",
    "                                                class_full = c.find_element_by_css_selector('div>div>div>span.ui_bubble_rating').get_attribute('class')\n",
    "                                                \n",
    "                                                reviews[review_id]['rating'] = int(re.search(r'(?<=_)\\d{1}', class_full).group(0))\n",
    "                                            except:\n",
    "                                                reviews[review_id]['rating'] = None\n",
    "                                                      \n",
    "                                            reviews[review_id]['attr_name'] = attr_details['name']\n",
    "                                            reviews[review_id]['attr_id'] = a_id\n",
    "                                            reviews[review_id]['attr_loc'] = city_\n",
    "                                            \n",
    "                                            # remove this reviews id from the set of review ids to collct\n",
    "                                            review_ids_to_collect_this_page -= {review_id}\n",
    "                                            # and put this id into the set of already collected ids\n",
    "                                            picked_reviews.add(review_id)\n",
    "                                            # increment the total of collected reviews on this page\n",
    "                                            p += 1\n",
    "\n",
    "                                        else:\n",
    "                                            continue\n",
    "                                    except:\n",
    "                                        continue\n",
    "\n",
    "                        # now try to click Next\n",
    "                        npage_url = None\n",
    "\n",
    "                        if self.FILTREVS[a_id] <= 10:\n",
    "                            last_page_url = self.driver.current_url\n",
    "                        else:\n",
    "                            try:\n",
    "                                last_page_url = list(self.driver.find_elements_by_css_selector('div.mobile-more>div>div.unified.ui_pagination>div.pageNumbers>a[href]'))[-1].get_attribute('href')\n",
    "                            except:\n",
    "                                last_page_url = self.driver.current_url \n",
    "\n",
    "                        if self.driver.current_url != last_page_url:\n",
    "\n",
    "                            # https://www.tripadvisor.com.au/Attraction_Review-g255097-d1063162-Reviews-or20-Mount_Wellington-Hobart_Greater_Hobart_Tasmania.html\n",
    "\n",
    "                            try:\n",
    "                                pref = int(re.search(r'(?<=-Reviews-or)\\d+', self.driver.current_url).group(0))\n",
    "                            except:\n",
    "                                pref = None\n",
    "\n",
    "                            if pref:\n",
    "                                next_page_url = self.driver.current_url.replace('or' + str(pref), 'or' + str(pref+10))\n",
    "                            else:\n",
    "                                next_page_url = self.driver.current_url.replace('Reviews-', 'Reviews-' + 'or' + str(10) + '-')\n",
    "\n",
    "                            if next_page_url != self.driver.current_url:\n",
    "                                self.driver.get(next_page_url)\n",
    "\n",
    "                        # add reviews for THIS attraction to the dictionary of ALL reviews\n",
    "                        self.REVIEWS.update(reviews)\n",
    "        \n",
    "        self.driver.close()\n",
    "        \n",
    "        return self\n",
    "        \n",
    "    def save_reviews(self):\n",
    "        \n",
    "        if not len(self.REVIEWS):\n",
    "            print('no reviews so nothing to save...')\n",
    "            return self\n",
    "            \n",
    "        file = '-'.join(['reviews', self.MAIN_LOCATION.replace(\" \",\"_\").upper(), \n",
    "                         self.FILTERS['traveller_type'], self.FILTERS['traveller_rating'], \n",
    "                         self.FILTERS['time_of_year']]) + '.json'\n",
    "            \n",
    "        json.dump(self.REVIEWS, open(os.path.join(self.COLLECT_DIR, file), 'w'))\n",
    "        \n",
    "        print(f'saved {len(self.REVIEWS):,} reviews')\n",
    "            \n",
    "        return self\n",
    "    \n",
    "    def save_attractions(self):\n",
    "    \n",
    "        json.dump(self.collected_attractions, \n",
    "                  open(os.path.join(self.COLLECT_DIR, \n",
    "                                    f'attractions-{self.MAIN_LOCATION.replace(\" \",\"_\").upper()}.json'), 'w'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    " class CountryDetector:\n",
    "        \n",
    "    def __init__(self):\n",
    "        \n",
    "        self.DATA_DIR = 'data'\n",
    "        \n",
    "        self.us_states = pd.read_csv(os.path.join(self.DATA_DIR, 'usa_states.csv'))\n",
    "        self.us_cities = set(pd.read_csv(os.path.join(self.DATA_DIR, 'usa_cities.csv'))['city'])\n",
    "        self.uk_counties = set(pd.read_csv(os.path.join(self.DATA_DIR, 'uk_counties.csv'))['county'])\n",
    "        self.uk_cities = set(pd.read_csv(os.path.join(self.DATA_DIR, 'uk_cities.csv'))['city'])\n",
    "        \n",
    "        self.countries = pd.read_csv('data/country_abbrs.csv')\n",
    "        \n",
    "        self.reviews_as_df = pd.DataFrame()\n",
    "    \n",
    "    def ukus(self, loc_str: str) -> str:\n",
    "        \n",
    "        \"\"\"\n",
    "        return 'UK' or 'USA' depending on what's been found in the string loc_str\n",
    "        \"\"\"\n",
    "        \n",
    "        if not isinstance(loc_str, str):\n",
    "            return None\n",
    "    \n",
    "        st =  ' ' + re.sub(r'[,.:;]', ' ', re.sub(r'\\s+', ' ', loc_str.lower().strip())) + ' '\n",
    "\n",
    "        sp = lambda x: ' ' + x + ' '\n",
    "        \n",
    "        uk_versions = {'united kingdom', 'uk'}\n",
    "        us_versions = {'united states', 'us'}\n",
    "\n",
    "        if any([sp('united kingdom') in st, sp('uk') in st]):\n",
    "            return 'UK'\n",
    "        elif any([sp('usa') in st, sp('united states') in st, sp('us') in st, sp('nyc') in st]):\n",
    "            return 'USA'\n",
    "\n",
    "        _us_states = set()\n",
    "        _us_cities = set()\n",
    "        _uk_counties = set()\n",
    "        _uk_cities = set()\n",
    "\n",
    "        for row in self.us_states.iterrows():\n",
    "            if (sp(row[1][0]) in st)  or (sp(row[1][1]) in st):\n",
    "                _us_states.add(row[1][0])\n",
    "\n",
    "        for c in self.us_cities:\n",
    "            if  sp(c) in st:\n",
    "                _us_cities.add(c)\n",
    "\n",
    "        for c in self.uk_counties:\n",
    "            if  sp(c) in st:\n",
    "                _uk_counties.add(c)\n",
    "\n",
    "        for c in self.uk_cities:\n",
    "            if  sp(c) in st:\n",
    "                _uk_cities.add(c)\n",
    "        \n",
    "        other_countries = sum(sp(c) in st for c in set(self.countries['country']) - set({'united kingdom', 'united states'}))\n",
    "        \n",
    "        if other_countries:\n",
    "            return None\n",
    "        \n",
    "        if _us_states:\n",
    "            return 'USA'\n",
    "        elif _uk_counties:\n",
    "            return 'UK'\n",
    "        if _us_cities and (not _us_cities & _uk_cities):\n",
    "            return 'USA'\n",
    "        if _uk_cities and (not _uk_cities & _us_cities):\n",
    "            return 'UK'\n",
    "        \n",
    "    def proc_review_files(self):\n",
    "        \n",
    "        ukus_df_list = []\n",
    "        rev_dict = defaultdict()\n",
    "        \n",
    "        for f in os.listdir('data-collected/'):\n",
    "            \n",
    "            if ('.json' in f) and ('reviews' in f):\n",
    "                \n",
    "                try:\n",
    "                    state_, type_ = f.split('-')[1:3]\n",
    "                    \n",
    "                    revs = json.load(open('data-collected/' + f))\n",
    "                    \n",
    "                    _ = pd.DataFrame.from_dict(revs, orient='index')\n",
    "                    _['type'] = 'friends' if 'friends' in f.lower() else 'solo' if 'solo' in f.lower() else None\n",
    "                    \n",
    "                    ukus_df_list.append(_)\n",
    "                    \n",
    "                except:\n",
    "                    pass\n",
    "                \n",
    "        # collected all reviews in a single dictionary; not let's find the UK/US ones\n",
    "        \n",
    "        self.reviews_as_df = pd.concat(ukus_df_list)\n",
    "        \n",
    "        self.reviews_as_df['ukus'] = self.reviews_as_df['user_loc'].apply(self.ukus)\n",
    "            \n",
    "        print(f'{len(self.reviews_as_df.index):,} reviews')\n",
    "            \n",
    "        return self\n",
    "    \n",
    "    def create_corpus(self, traveller_type, only_nouns=True):\n",
    "        \n",
    "        df = self.reviews_as_df[self.reviews_as_df['ukus'].isin(['UK', 'USA']) & (self.reviews_as_df['type'] == traveller_type)]\n",
    "        \n",
    "        if only_nouns:\n",
    "            df['text'] = df['text'].apply(lambda x: ' '.join([w.lemma_ for w in nlp(x.lower()) if w.pos_ == 'NOUN']))\n",
    "            \n",
    "        corpus = st.CorpusFromPandas(df, category_col='ukus', text_col='text', nlp=nlp).build()\n",
    "        \n",
    "        html = st.produce_scattertext_explorer(corpus, \n",
    "                                       category='UK',  # actual column name\n",
    "                                       category_name='UK' + ' ' + traveller_type.title(),  # extended name for the category\n",
    "                                       not_category_name='USA' + ' ' + traveller_type.title(),  # extended name for the OTHER category\n",
    "                                       width_in_pixels=1000)\n",
    "        \n",
    "        if not os.path.exists('analysis'):\n",
    "            os.mkdir('analysis')\n",
    "            \n",
    "        open(f'analysis/{traveller_type}.html', 'wb').write(html.encode('utf-8'))\n",
    "        \n",
    "        return self"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "filter: traveller_rating:Excellent | traveller_type:Friends | time_of_year:Jun-Aug | language:English\n",
      "collecting attractions for HOBART, TASMANIA...\n",
      "visiting attraction pages..\n",
      "page 1/5..ok\n",
      "page 2/5..ok\n",
      "page 3/5..ok\n",
      "page 4/5..ok\n",
      "page 5/5..ok\n",
      "collecting attractions for LAUNCESTON, TASMANIA...\n",
      "visiting attraction pages..\n",
      "page 1/3..ok\n",
      "page 2/3..ok\n",
      "page 3/3..ok\n",
      "collecting attractions for SWANSEA, TASMANIA...\n",
      "visiting attraction pages..\n",
      "page 1/1..ok\n",
      "collecting attractions for PORT ARTHUR, TASMANIA...\n",
      "visiting attraction pages..\n",
      "page 1/2..ok\n",
      "page 2/2..ok\n",
      "collecting attractions for GEORGE TOWN, TASMANIA...\n",
      "visiting attraction pages..\n",
      "page 1/1..ok\n",
      "collecting attractions for CRADLE MOUNTAIN LAKE ST CLAIR NP, TASMANIA...\n",
      "visiting attraction pages..\n",
      "page 1/1..ok\n",
      "collecting attractions for COLES BAY, TASMANIA...\n",
      "visiting attraction pages..\n",
      "page 1/1..ok\n",
      "collecting attractions for BICHENO, TASMANIA...\n",
      "visiting attraction pages..\n",
      "page 1/1..ok\n",
      "collecting attractions for RICHMOND, TASMANIA...\n",
      "visiting attraction pages..\n",
      "page 1/1..ok\n",
      "attraction #1/330: [ID: d1063162][Mount Wellington]...\n",
      "filtered reviews: 178\n",
      "attraction #2/330: [ID: d256538][Bonorong Wildlife Sanctuary]...\n",
      "filtered reviews: 39\n",
      "attraction #3/330: [ID: d256543][Cascade Brewery]...\n",
      "filtered reviews: 77\n",
      "attraction #4/330: [ID: d256545][Royal Tasmanian Botanical Gardens]...\n",
      "filtered reviews: 40\n",
      "attraction #5/330: [ID: d312416][Salamanca Market]...\n",
      "filtered reviews: 82\n",
      "attraction #6/330: [ID: d10332522][Mona Ferry]...\n",
      "filtered reviews: 35\n",
      "attraction #7/330: [ID: d5605486][Mawson's Hut Replica Museum]...\n",
      "filtered reviews: 18\n",
      "attraction #8/330: [ID: d2355787][Hobart Convict Penitentiary]...\n",
      "filtered reviews: 22\n",
      "attraction #9/330: [ID: d256546][Tasmanian Museum and Art Gallery]...\n",
      "filtered reviews: 30\n",
      "attraction #10/330: [ID: d300271][Battery Point Sculpture Trail]...\n",
      "filtered reviews: 17\n",
      "attraction #11/330: [ID: d1725936][Cascades Female Factory Historic Site]...\n",
      "filtered reviews: 30\n",
      "attraction #12/330: [ID: d3369810][Farm Gate Market]...\n",
      "filtered reviews: 9\n",
      "attraction #13/330: [ID: d8525587][Constitution Dock]...\n",
      "filtered reviews: 10\n",
      "attraction #14/330: [ID: d592952][Lark Distillery]...\n",
      "filtered reviews: 15\n",
      "failed to find name for attraction d591100, skipping..\n",
      "attraction #16/330: [ID: d2355453][Maritime Museum of Tasmania]...\n",
      "filtered reviews: 6\n",
      "attraction #17/330: [ID: d590655][Sullivans Cove]...\n",
      "filtered reviews: 5\n",
      "attraction #18/330: [ID: d3140095][Narryna Heritage Museum]...\n",
      "only 114 reviews, skipping..\n",
      "attraction #19/330: [ID: d592974][Sandy Bay]...\n",
      "filtered reviews: 2\n",
      "attraction #20/330: [ID: d2416570][Myrtle Forest]...\n",
      "only 40 reviews, skipping..\n",
      "attraction #21/330: [ID: d592982][Runnymede]...\n",
      "only 134 reviews, skipping..\n",
      "attraction #22/330: [ID: d590652][Tasman Bridge]...\n",
      "filtered reviews: 7\n",
      "attraction #23/330: [ID: d592948][Sub-Antarctic Plant House]...\n",
      "only 124 reviews, skipping..\n",
      "attraction #24/330: [ID: d592978][Salamanca Arts Centre]...\n",
      "filtered reviews: 6\n",
      "attraction #25/330: [ID: d8747569][Brooke Street Pier]...\n",
      "only 166 reviews, skipping..\n",
      "attraction #26/330: [ID: d9865625][St. David's Park]...\n",
      "only 63 reviews, skipping..\n",
      "attraction #27/330: [ID: d591874][Long Beach]...\n",
      "only 60 reviews, skipping..\n",
      "attraction #28/330: [ID: d7157559][Rosny Point Lookout]...\n",
      "only 108 reviews, skipping..\n",
      "attraction #29/330: [ID: d590645][Theatre Royal]...\n",
      "filtered reviews: 5\n",
      "attraction #30/330: [ID: d592969][St. David's Cathedral]...\n",
      "filtered reviews: 5\n",
      "attraction #31/330: [ID: d592946][Train Park]...\n",
      "only 58 reviews, skipping..\n",
      "attraction #32/330: [ID: d592534][North Hobart]...\n",
      "filtered reviews: 7\n",
      "attraction #33/330: [ID: d9814538][Waterworks Reserve]...\n",
      "only 28 reviews, skipping..\n",
      "attraction #34/330: [ID: d9601301][Wrest Point Casino]...\n",
      "filtered reviews: 1\n",
      "attraction #35/330: [ID: d9707072][Cenotaph]...\n",
      "only 32 reviews, skipping..\n",
      "attraction #36/330: [ID: d590592][South Hobart]...\n",
      "only 75 reviews, skipping..\n",
      "attraction #37/330: [ID: d592967][St Joseph's Catholic Church]...\n",
      "only 15 reviews, skipping..\n",
      "attraction #38/330: [ID: d3453875][Henry Jones Design Gallery]...\n",
      "only 78 reviews, skipping..\n",
      "attraction #39/330: [ID: d12918446][Salamanca Square]...\n",
      "only 30 reviews, skipping..\n",
      "attraction #40/330: [ID: d2625790][Hobart Synagogue]...\n",
      "only 20 reviews, skipping..\n",
      "attraction #41/330: [ID: d592958][Tasmanian Transport Museum]...\n",
      "only 55 reviews, skipping..\n",
      "attraction #42/330: [ID: d6019301][Army Museum of Tasmania]...\n",
      "only 29 reviews, skipping..\n",
      "attraction #43/330: [ID: d11688716][Government House]...\n",
      "only 10 reviews, skipping..\n",
      "attraction #44/330: [ID: d13126194][The Pipeline Track]...\n",
      "only 8 reviews, skipping..\n",
      "attraction #45/330: [ID: d7733252][Knocklofty Reserve]...\n",
      "only 26 reviews, skipping..\n",
      "attraction #46/330: [ID: d14101218][Bernacchi Tribute Sculptures]...\n",
      "only 10 reviews, skipping..\n",
      "attraction #47/330: [ID: d592990][Parliament House]...\n",
      "only 43 reviews, skipping..\n",
      "attraction #48/330: [ID: d2614565][Markree House Museum & Garden]...\n",
      "only 26 reviews, skipping..\n",
      "attraction #49/330: [ID: d14142758][Secret Falls]...\n",
      "only 3 reviews, skipping..\n",
      "attraction #50/330: [ID: d14077514][Tasmanian Travel & Information Centre]...\n",
      "only 11 reviews, skipping..\n",
      "attraction #51/330: [ID: d12400159][Hobart Town Hall]...\n",
      "only 18 reviews, skipping..\n",
      "attraction #52/330: [ID: d15557600][Elizabeth Street Mall]...\n",
      "only 7 reviews, skipping..\n",
      "attraction #53/330: [ID: d14101936][Elizabeth Street Pier]...\n",
      "only 8 reviews, skipping..\n",
      "attraction #54/330: [ID: d592941][University of Tasmania - Sandy Bay campus]...\n",
      "only 14 reviews, skipping..\n",
      "attraction #55/330: [ID: d10000590][Nutgrove Beach]...\n",
      "only 7 reviews, skipping..\n",
      "attraction #56/330: [ID: d15533965][Franklin Square]...\n",
      "only 8 reviews, skipping..\n",
      "attraction #57/330: [ID: d10447534][Cathedral Rock Wellington Park]...\n",
      "only 7 reviews, skipping..\n",
      "attraction #58/330: [ID: d10587680][Captain Blighs Brewery]...\n",
      "only 8 reviews, skipping..\n",
      "attraction #59/330: [ID: d4757191][Lady Franklin Gallery]...\n",
      "only 17 reviews, skipping..\n",
      "attraction #60/330: [ID: d8697255][The Hobart Aquatic Centre]...\n",
      "only 19 reviews, skipping..\n",
      "attraction #61/330: [ID: d592988][Queens Domain]...\n",
      "only 23 reviews, skipping..\n",
      "attraction #62/330: [ID: d5001694][Handmark Galleries]...\n",
      "only 29 reviews, skipping..\n",
      "attraction #63/330: [ID: d14194000][The Tasman Fountain]...\n",
      "only 7 reviews, skipping..\n",
      "attraction #64/330: [ID: d590651][St George's Anglican Church]...\n",
      "only 14 reviews, skipping..\n",
      "attraction #65/330: [ID: d8639747][Art Mob]...\n",
      "only 13 reviews, skipping..\n",
      "attraction #66/330: [ID: d590644][Tasmanian Hockey Centre]...\n",
      "only 9 reviews, skipping..\n",
      "attraction #67/330: [ID: d10467000][Cat and Fiddle Arcade]...\n",
      "only 20 reviews, skipping..\n",
      "attraction #68/330: [ID: d591103][Allport Library and Museum of Fine Arts]...\n",
      "only 26 reviews, skipping..\n",
      "attraction #69/330: [ID: d14059924][May Queen]...\n",
      "only 5 reviews, skipping..\n",
      "attraction #70/330: [ID: d592965][St Mary's Cathedral]...\n",
      "only 25 reviews, skipping..\n",
      "attraction #71/330: [ID: d4047599][The Hobart Real Tennis Club]...\n",
      "only 8 reviews, skipping..\n",
      "attraction #72/330: [ID: d15597666][Cascade Gardens]...\n",
      "only 5 reviews, skipping..\n",
      "attraction #73/330: [ID: d12950312][O'Grady Falls]...\n",
      "only 5 reviews, skipping..\n",
      "attraction #74/330: [ID: d592564][Eaglehawk Hangliding Lookout]...\n",
      "only 25 reviews, skipping..\n",
      "attraction #75/330: [ID: d14093990][Kelly's Steps]...\n",
      "only 9 reviews, skipping..\n",
      "attraction #76/330: [ID: d14721059][Princes Park]...\n",
      "only 7 reviews, skipping..\n",
      "attraction #77/330: [ID: d12420170][Convict Trail]...\n",
      "only 4 reviews, skipping..\n",
      "attraction #78/330: [ID: d8638580][Wild Island Tasmania]...\n",
      "only 9 reviews, skipping..\n",
      "attraction #79/330: [ID: d10088766][Archive Antiques]...\n",
      "only 2 reviews, skipping..\n",
      "attraction #80/330: [ID: d15595977][Arthur Circus Park]...\n",
      "only 3 reviews, skipping..\n",
      "attraction #81/330: [ID: d12856581][The Rare and Beautiful]...\n",
      "only 3 reviews, skipping..\n",
      "attraction #82/330: [ID: d15594690][Soundy Park]...\n",
      "only 3 reviews, skipping..\n",
      "attraction #83/330: [ID: d14050707][Hillsong Hobart]...\n",
      "only 1 reviews, skipping..\n",
      "attraction #84/330: [ID: d8141037][International Wall of Friendship]...\n",
      "only 8 reviews, skipping..\n",
      "attraction #85/330: [ID: d14919779][Treasury Building]...\n",
      "only 2 reviews, skipping..\n",
      "attraction #86/330: [ID: d13433633][Gallery Salamanca]...\n",
      "only 3 reviews, skipping..\n",
      "attraction #87/330: [ID: d8830596][Antiques Warehouse]...\n",
      "only 4 reviews, skipping..\n",
      "attraction #88/330: [ID: d15598513][Hobart Rivulet Park]...\n",
      "only 3 reviews, skipping..\n",
      "attraction #89/330: [ID: d2406579][Nolan Art Gallery & School]...\n",
      "only 5 reviews, skipping..\n",
      "attraction #90/330: [ID: d15598493][Railway Roundabout]...\n",
      "only 2 reviews, skipping..\n",
      "attraction #91/330: [ID: d14888341][General Post Office]...\n",
      "only 4 reviews, skipping..\n",
      "attraction #92/330: [ID: d15598509][University Rose Garden]...\n",
      "only 2 reviews, skipping..\n",
      "attraction #93/330: [ID: d14085055][St. John's Presbyterian Church]...\n",
      "only 2 reviews, skipping..\n",
      "attraction #94/330: [ID: d10480176][Miss Blackbird]...\n",
      "only 2 reviews, skipping..\n",
      "attraction #95/330: [ID: d15594700][Long Beach Reserve]...\n",
      "only 1 reviews, skipping..\n",
      "attraction #96/330: [ID: d14217023][Mount Nelson Oval and Playground]...\n",
      "only 2 reviews, skipping..\n",
      "attraction #97/330: [ID: d5607957][Peter Murrell Nature Reserve]...\n",
      "only 2 reviews, skipping..\n",
      "attraction #98/330: [ID: d13998275][The Anglican Parish of All Saints South Hobart]...\n",
      "only 1 reviews, skipping..\n",
      "attraction #99/330: [ID: d14215292][Fitzroy Gardens]...\n",
      "only 2 reviews, skipping..\n",
      "attraction #100/330: [ID: d13478969][Glaetzer Dixon Family Winemakers]...\n",
      "only 2 reviews, skipping..\n",
      "attraction #101/330: [ID: d15533960][Lieutenant William Eltham]...\n",
      "only 2 reviews, skipping..\n",
      "attraction #102/330: [ID: d13996646][Canadian Exiles Memorial]...\n",
      "only 4 reviews, skipping..\n",
      "attraction #103/330: [ID: d15529176][Visit of U.S.S. Enterprise]...\n",
      "only 2 reviews, skipping..\n",
      "attraction #104/330: [ID: d8541136][Despard Gallery]...\n",
      "only 4 reviews, skipping..\n",
      "attraction #105/330: [ID: d15581840][Wellington Park]...\n",
      "only 2 reviews, skipping..\n",
      "attraction #106/330: [ID: d15528228][South African (Boer) War Memorial]...\n",
      "only 1 reviews, skipping..\n",
      "attraction #107/330: [ID: d14215371][TCA Ground]...\n",
      "only 1 reviews, skipping..\n",
      "attraction #108/330: [ID: d15594619][New Town Rivulet Park]...\n",
      "only 1 reviews, skipping..\n",
      "attraction #109/330: [ID: d15555466][C3 Church]...\n",
      "only 1 reviews, skipping..\n",
      "attraction #110/330: [ID: d14784410][Hobart Full Gospel Central Church]...\n",
      "only 2 reviews, skipping..\n",
      "attraction #111/330: [ID: d15594667][John Turnbull Reserve]...\n",
      "only 1 reviews, skipping..\n",
      "attraction #112/330: [ID: d591096][Wapping]...\n",
      "only 4 reviews, skipping..\n",
      "attraction #113/330: [ID: d593381][Rosedown Gardens]...\n",
      "only 1 reviews, skipping..\n",
      "attraction #114/330: [ID: d14120549][Albert George Ogilvie]...\n",
      "only 3 reviews, skipping..\n",
      "attraction #115/330: [ID: d14215358][Caldew Park]...\n",
      "only 1 reviews, skipping..\n",
      "attraction #116/330: [ID: d11775320][Cornelian Bay Cemetery]...\n",
      "only 1 reviews, skipping..\n",
      "attraction #117/330: [ID: d15594666][John Doggett Park]...\n",
      "only 1 reviews, skipping..\n",
      "attraction #118/330: [ID: d11825115][Wingaroo Nature Reserve]...\n",
      "only 1 reviews, skipping..\n",
      "attraction #119/330: [ID: d11863698][Contemporary Art Tasmania]...\n",
      "only 1 reviews, skipping..\n",
      "attraction #120/330: [ID: d15594741][The Springs]...\n",
      "only 2 reviews, skipping..\n",
      "attraction #121/330: [ID: d15594745][Wellesley Park]...\n",
      "only 1 reviews, skipping..\n",
      "attraction #122/330: [ID: d15594580][Aberdeen Street Reserve]...\n",
      "only 1 reviews, skipping..\n",
      "attraction #123/330: [ID: d15594678][Parliament Reserve]...\n",
      "only 1 reviews, skipping..\n",
      "attraction #124/330: [ID: d15596425][Powder Magazine]...\n",
      "only 1 reviews, skipping..\n",
      "attraction #125/330: [ID: d15594749][St Andrew Park]...\n",
      "only 1 reviews, skipping..\n",
      "attraction #126/330: [ID: d15594704][South Hobart Oval and Playground]...\n",
      "only 1 reviews, skipping..\n",
      "attraction #127/330: [ID: d15594687][Soldiers Memoral Reserve]...\n",
      "only 1 reviews, skipping..\n",
      "attraction #128/330: [ID: d15594573][AJ White Park]...\n",
      "only 1 reviews, skipping..\n",
      "attraction #129/330: [ID: d7241521][Hobart Repertory Theatre Society]...\n",
      "only 1 reviews, skipping..\n",
      "attraction #130/330: [ID: d17168689][Organ Pipes Circuit Trail]...\n",
      "only 1 reviews, skipping..\n",
      "attraction #131/330: [ID: d17451573][Bridge of Remembrance]...\n",
      "only 2 reviews, skipping..\n",
      "attraction #132/330: [ID: d592964][St Peter's Lutheran Church]...\n",
      "only 1 reviews, skipping..\n",
      "attraction #133/330: [ID: d15949301][Community Hub]...\n",
      "only 1 reviews, skipping..\n",
      "attraction #134/330: [ID: d15618385][The Soilders Walk]...\n",
      "only 1 reviews, skipping..\n",
      "attraction #135/330: [ID: d15520795][Charles Meredith]...\n",
      "only 2 reviews, skipping..\n",
      "attraction #136/330: [ID: d9705610][Intercity Cycleway]...\n",
      "only 1 reviews, skipping..\n",
      "attraction #137/330: [ID: d14215341][Friends Park]...\n",
      "only 1 reviews, skipping..\n",
      "attraction #138/330: [ID: d15598505][Fern Tree Playground]...\n",
      "only 1 reviews, skipping..\n",
      "attraction #139/330: [ID: d15674233][Cactus Collection]...\n",
      "only 1 reviews, skipping..\n",
      "attraction #140/330: [ID: d14200294][Memorial to the 99th Foot]...\n",
      "only 1 reviews, skipping..\n",
      "attraction #141/330: [ID: d10467139][Inka Gallery]...\n",
      "only 1 reviews, skipping..\n",
      "attraction #142/330: [ID: d10230437][Eagleneck Point Semaphore]...\n",
      "only 1 reviews, skipping..\n",
      "attraction #143/330: [ID: d17767003][Kunanyi]...\n",
      "only 0 reviews, skipping..\n",
      "attraction #144/330: [ID: d15656059][The Playhouse Theatre]...\n",
      "only 0 reviews, skipping..\n",
      "attraction #145/330: [ID: d14215287][Princes Park]...\n",
      "only 0 reviews, skipping..\n",
      "attraction #146/330: [ID: d14215285][Parliament Square]...\n",
      "only 0 reviews, skipping..\n",
      "attraction #147/330: [ID: d11751457][Mount mawson]...\n",
      "only 0 reviews, skipping..\n",
      "attraction #148/330: [ID: d4563197][146 ArtSpace]...\n",
      "only 0 reviews, skipping..\n",
      "attraction #149/330: [ID: d258124][Cataract Gorge Reserve]...\n",
      "filtered reviews: 93\n",
      "attraction #150/330: [ID: d522988][The Tamar Valley]...\n",
      "filtered reviews: 14\n",
      "attraction #151/330: [ID: d283243][James Boag Brewery Experience]...\n",
      "filtered reviews: 12\n",
      "attraction #152/330: [ID: d12152696][Cataract Gorge Scenic Chairlift]...\n",
      "filtered reviews: 7\n",
      "attraction #153/330: [ID: d544805][City Park]...\n",
      "filtered reviews: 24\n",
      "attraction #154/330: [ID: d2536333][Harvest Launceston, Community Farmers’ Market]...\n",
      "only 160 reviews, skipping..\n",
      "attraction #155/330: [ID: d3669335][National Automobile Museum of Tasmania]...\n",
      "filtered reviews: 9\n",
      "attraction #156/330: [ID: d3932843][Tamar Island Wetlands]...\n",
      "filtered reviews: 5\n",
      "attraction #157/330: [ID: d256550][Queen Victoria Museum & Art Gallery]...\n",
      "filtered reviews: 10\n",
      "attraction #158/330: [ID: d8424527][Lilydale Falls]...\n",
      "only 112 reviews, skipping..\n",
      "attraction #159/330: [ID: d11815697][Penny Royal Adventures]...\n",
      "filtered reviews: 4\n",
      "attraction #160/330: [ID: d7855399][Launceston Visitor Information Centre]...\n",
      "only 132 reviews, skipping..\n",
      "attraction #161/330: [ID: d12386500][Alexandra Suspension Bridge]...\n",
      "only 80 reviews, skipping..\n",
      "attraction #162/330: [ID: d2549256][Franklin House]...\n",
      "only 128 reviews, skipping..\n",
      "attraction #163/330: [ID: d2005211][Josef Chromy Cellar Door]...\n",
      "filtered reviews: 7\n",
      "attraction #164/330: [ID: d2433076][Design Centre Tasmania]...\n",
      "only 124 reviews, skipping..\n",
      "attraction #165/330: [ID: d14109071][Cataract Gorge]...\n",
      "only 49 reviews, skipping..\n",
      "attraction #166/330: [ID: d2035195][Tasmania Zoo]...\n",
      "filtered reviews: 5\n",
      "attraction #167/330: [ID: d6855947][University of Tasmania Stadium]...\n",
      "only 65 reviews, skipping..\n",
      "attraction #168/330: [ID: d1155472][Tamar River]...\n",
      "filtered reviews: 3\n",
      "attraction #169/330: [ID: d1520872][Entally House]...\n",
      "only 76 reviews, skipping..\n",
      "attraction #170/330: [ID: d13127431][Annex Theatre]...\n",
      "only 1 reviews, skipping..\n",
      "attraction #171/330: [ID: d6019299][Launceston Tramway Museum]...\n",
      "only 86 reviews, skipping..\n",
      "attraction #172/330: [ID: d3806455][City Park Radio Museum]...\n",
      "only 59 reviews, skipping..\n",
      "attraction #173/330: [ID: d4727855][Country Club Tasmania Casino]...\n",
      "filtered reviews: 2\n",
      "attraction #174/330: [ID: d7714881][Sharmans Wines]...\n",
      "only 42 reviews, skipping..\n",
      "attraction #175/330: [ID: d4749670][The Town Clock]...\n",
      "only 94 reviews, skipping..\n",
      "attraction #176/330: [ID: d12070983][Prince's Square]...\n",
      "only 26 reviews, skipping..\n",
      "attraction #177/330: [ID: d10004821][Red Brick Road Ciderhouse]...\n",
      "only 24 reviews, skipping..\n",
      "attraction #178/330: [ID: d5951672][Jinglers Creek Vineyard]...\n",
      "only 7 reviews, skipping..\n",
      "attraction #179/330: [ID: d13346790][Greenoaks Gallery]...\n",
      "only 10 reviews, skipping..\n",
      "attraction #180/330: [ID: d9864720][Heritage Forest]...\n",
      "only 9 reviews, skipping..\n",
      "attraction #181/330: [ID: d14070196][City of Launceston Town Hall]...\n",
      "only 8 reviews, skipping..\n",
      "attraction #182/330: [ID: d11907888][Art Gallery at Royal Park]...\n",
      "only 13 reviews, skipping..\n",
      "attraction #183/330: [ID: d14089770][Holy Trinity Anglican Church]...\n",
      "only 5 reviews, skipping..\n",
      "attraction #184/330: [ID: d15096620][Albert Hall]...\n",
      "only 9 reviews, skipping..\n",
      "attraction #185/330: [ID: d15779718][Duck Reach Power Station]...\n",
      "only 4 reviews, skipping..\n",
      "attraction #186/330: [ID: d12070934][Trevallyn Dam]...\n",
      "only 8 reviews, skipping..\n",
      "attraction #187/330: [ID: d12058217][Lake Trevallyn]...\n",
      "only 4 reviews, skipping..\n",
      "attraction #188/330: [ID: d14097088][Punchbowl Reserve]...\n",
      "only 4 reviews, skipping..\n",
      "attraction #189/330: [ID: d6861321][Waverly Woolen Mills Factory Outlet]...\n",
      "only 4 reviews, skipping..\n",
      "attraction #190/330: [ID: d9810356][The Pinot Shop]...\n",
      "only 7 reviews, skipping..\n",
      "attraction #191/330: [ID: d1735293][Tassie Tiger Mini Golf]...\n",
      "only 18 reviews, skipping..\n",
      "attraction #192/330: [ID: d10520845][Lilydale Village Market]...\n",
      "only 4 reviews, skipping..\n",
      "attraction #193/330: [ID: d14037308][The Pilgrim Uniting Church]...\n",
      "only 2 reviews, skipping..\n",
      "attraction #194/330: [ID: d14055761][St. Andrews Presbyterian Church of Australia]...\n",
      "only 2 reviews, skipping..\n",
      "attraction #195/330: [ID: d13447334][Launceston Leisure and Aquatic Centre]...\n",
      "only 3 reviews, skipping..\n",
      "attraction #196/330: [ID: d13109347][Princess Theatre]...\n",
      "only 4 reviews, skipping..\n",
      "attraction #197/330: [ID: d14169770][King Edward VII]...\n",
      "only 2 reviews, skipping..\n",
      "attraction #198/330: [ID: d11704842][Freelands Lookout]...\n",
      "only 5 reviews, skipping..\n",
      "attraction #199/330: [ID: d14096951][Hadspen Lions Park Reserve]...\n",
      "only 1 reviews, skipping..\n",
      "attraction #200/330: [ID: d2482970][Providence Vineyards]...\n",
      "only 3 reviews, skipping..\n",
      "attraction #201/330: [ID: d1759007][1842 Gallery]...\n",
      "only 29 reviews, skipping..\n",
      "attraction #202/330: [ID: d1735294][Indoor Sports Center]...\n",
      "only 18 reviews, skipping..\n",
      "attraction #203/330: [ID: d15578961][Launceston Distillery]...\n",
      "only 1 reviews, skipping..\n",
      "attraction #204/330: [ID: d14096976][Kate Reed Nature Recreation Area]...\n",
      "only 1 reviews, skipping..\n",
      "attraction #205/330: [ID: d14892796][Zig Zag Reserve]...\n",
      "only 1 reviews, skipping..\n",
      "attraction #206/330: [ID: d14097008][Silverdome]...\n",
      "only 1 reviews, skipping..\n",
      "attraction #207/330: [ID: d17793951][Tulloch's Auctions]...\n",
      "only 0 reviews, skipping..\n",
      "attraction #208/330: [ID: d14892795][Arbour Park]...\n",
      "only 0 reviews, skipping..\n",
      "attraction #209/330: [ID: d14892794][Kings Park]...\n",
      "only 0 reviews, skipping..\n",
      "attraction #210/330: [ID: d4371703][Kate's Berry Farm]...\n",
      "filtered reviews: 1\n",
      "attraction #211/330: [ID: d2508348][Spiky Bridge]...\n",
      "filtered reviews: 3\n",
      "attraction #212/330: [ID: d7809453][Milton Vineyard]...\n",
      "only 98 reviews, skipping..\n",
      "attraction #213/330: [ID: d13093796][Spiky Beach Conservation Area]...\n",
      "only 11 reviews, skipping..\n",
      "attraction #214/330: [ID: d6424459][East Coast Heritage Museum]...\n",
      "only 51 reviews, skipping..\n",
      "attraction #215/330: [ID: d15280194][Swansea Visitor Information Centre]...\n",
      "only 8 reviews, skipping..\n",
      "attraction #216/330: [ID: d13287114][Bark Mill Museum]...\n",
      "only 9 reviews, skipping..\n",
      "failed to find name for attraction d9719115, skipping..\n",
      "failed to find name for attraction d18276230, skipping..\n",
      "attraction #219/330: [ID: d258126][Port Arthur Historic Site]...\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    \n",
    "    t = Trip(filter={'traveller_rating': 'Excellent', \n",
    "                      'traveller_type':'Friends', \n",
    "                       'time_of_year': 'Jun-Aug',  # note that this refers to review date (and NOT experience date)\n",
    "                       'language':'English'}) \\\n",
    "                    .get_attraction_pages('tasmania') \\\n",
    "                        .get_reviews_from_attraction_pages(min_total_reviews=170) \\\n",
    "                            .save_reviews() \\\n",
    "                                .save_attractions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "country_det = CountryDetector().proc_review_files().create_corpus(traveller_type='friends')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
