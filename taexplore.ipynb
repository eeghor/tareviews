{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "import pandas as pd\n",
    "import spacy\n",
    "\n",
    "from collections import Counter, defaultdict\n",
    "from itertools import chain\n",
    "import re\n",
    "\n",
    "import arrow \n",
    "\n",
    "import googlemaps\n",
    "\n",
    "from plotly import __version__\n",
    "from plotly.offline import download_plotlyjs, init_notebook_mode, plot, iplot\n",
    "import plotly.figure_factory as ff\n",
    "import plotly.graph_objs as go\n",
    "\n",
    "import cufflinks as cf\n",
    "\n",
    "import scattertext as st\n",
    "from scattertext import word_similarity_explorer\n",
    "\n",
    "from gender import GenderDetector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('en')\n",
    "\n",
    "nlp.Defaults.stop_words |= {'probably'}\n",
    "STOPWORDS = nlp.Defaults.stop_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script><script type=\"text/javascript\">if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script><script>requirejs.config({paths: { 'plotly': ['https://cdn.plot.ly/plotly-latest.min']},});if(!window._Plotly) {require(['plotly'],function(plotly) {window._Plotly=plotly;});}</script>"
      ],
      "text/vnd.plotly.v1+html": [
       "<script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script><script type=\"text/javascript\">if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script><script>requirejs.config({paths: { 'plotly': ['https://cdn.plot.ly/plotly-latest.min']},});if(!window._Plotly) {require(['plotly'],function(plotly) {window._Plotly=plotly;});}</script>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "init_notebook_mode(connected=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class T:\n",
    "    \n",
    "    def __init__(self, review_file, users_file, attract_file, impute_country=False, impute_gender=False):\n",
    "        \n",
    "        \"\"\"\n",
    "        collected TripAdvisor data comes as JSONs; this class does some data processing including imputation\n",
    "        \"\"\"\n",
    "\n",
    "        self.r = json.load(open(review_file))\n",
    "        self.u = json.load(open(users_file))\n",
    "        self.a = json.load(open(attract_file))  \n",
    "\n",
    "        # convert everything to pandas\n",
    "        self.u_df = pd.DataFrame(self.u).dropna(subset=['name'])\n",
    "        \n",
    "        self.r_df = pd.DataFrame(self.r).dropna(subset=['attr_id'])\n",
    "\n",
    "        self.tag_cols = list(set([tg for tg in chain.from_iterable(self.u_df['tags'])]))\n",
    "        \n",
    "        if impute_country:\n",
    "            self.gmaps = googlemaps.Client(key=open('creds/geocoding_api.key').readline().strip())\n",
    "        if impute_gender:\n",
    "            self.gd = GenderDetector()\n",
    "    \n",
    "    def stats(self):\n",
    "        \n",
    "        self.user_stats = defaultdict(list)\n",
    "        \n",
    "        self.review_ids = set()\n",
    "        self.attr_ids = set()\n",
    "        self.user_names = set()\n",
    "        self.dates_exp = set()\n",
    "        \n",
    "        for r in self.r:\n",
    "            \n",
    "            self.review_ids.add(r['id'])\n",
    "            self.attr_ids.add(r['attr_id'])\n",
    "            self.user_names.add(r['by_user'])\n",
    "            \n",
    "            if r['date_of_experience']:\n",
    "                self.dates_exp.add(arrow.get(r['date_of_experience'], 'MM/YYYY'))\n",
    "        \n",
    "        print(f'DATA\\n{\"\".join([\"-\"]*4)}')\n",
    "        print('{:,} reviews written between {} and {} for {:,} attractions by {:,} users' \\\n",
    "                  .format(len(self.review_ids), \n",
    "                          min(self.dates_exp).format(\"MM/YYYY\"), \n",
    "                          max(self.dates_exp).format(\"MM/YYYY\"), \n",
    "                          len(self.attr_ids), \n",
    "                          len(self.user_names)))\n",
    "        \n",
    "        for u in self.u:\n",
    "            for attr in 'tags age gender name'.split():   \n",
    "                if u[attr]:\n",
    "                    self.user_stats[attr].append(u[attr])\n",
    "        \n",
    "        print('user attribute availability:')\n",
    "        print(' ~ '.join(['{}: {:,} ({:.1f})%'.format(attr, \n",
    "                                                    len(self.user_stats[attr]), \n",
    "                                                    100*len(self.user_stats[attr])/len(self.user_stats['name'])) \n",
    "                                                       for attr in 'tags age gender'.split()]))\n",
    "              \n",
    "        return self\n",
    "        \n",
    "    def _tags_to_cols(self, tag_list):\n",
    "        \n",
    "        if not tag_list:\n",
    "            return [None]*len(self.tag_cols)\n",
    "        \n",
    "        return ['yes' if tag in tag_list else 'no' for tag in self.tag_cols]\n",
    "    \n",
    "    def tags_to_cols(self):\n",
    "        \n",
    "        self.u_df = pd.concat([self.u_df, \n",
    "                            pd.DataFrame(self.u_df['tags'].apply(self._tags_to_cols).to_list(), \n",
    "                                         columns=self.tag_cols)], axis=1).drop('tags', axis=1)\n",
    "        \n",
    "        return self\n",
    "\n",
    "              \n",
    "    def _fix_location(self, s):\n",
    "              \n",
    "        \"\"\"\n",
    "        using Google Geocoding API to clarify users location\n",
    "        \"\"\"\n",
    "        \n",
    "        loc = dict()\n",
    "        \n",
    "        if not (isinstance(s, str) and s.strip()):\n",
    "            print('geocoding API needs a string argument!')\n",
    "            return loc\n",
    "        \n",
    "        geocode_result = self.gmaps.geocode(s)\n",
    "        \n",
    "        # take only the top result\n",
    "        if geocode_result:\n",
    "            res = geocode_result[0]\n",
    "        else:\n",
    "            print(f'geocoding api can\\'t find this location: {s}!')\n",
    "            return loc\n",
    "        \n",
    "        if 'address_components' in res:\n",
    "            for _ in res['address_components']:\n",
    "                if 'country' in _['types']:\n",
    "                    loc.update({'country': _['long_name']})\n",
    "                if 'locality' in _['types']:\n",
    "                    loc.update({'locality': _['long_name']})\n",
    "        if 'formatted_address' in res:\n",
    "            loc.update({'location': res['formatted_address']})\n",
    "        \n",
    "        try:\n",
    "            loc.update({'coordinates': res['geometry']['location']})\n",
    "        except:\n",
    "            pass\n",
    "        \n",
    "        if not loc:\n",
    "            print('locationd fields couldn\\'t be retrieved from geocoding result!')\n",
    "                               \n",
    "        return loc\n",
    "\n",
    "    \n",
    "    def impute_location(self):\n",
    "        \n",
    "        self.countries = {_['name'].lower() for _ in json.load(open('data/countries.json'))}\n",
    "              \n",
    "        localities = []\n",
    "        countries = []\n",
    "    \n",
    "        c_geo = 0\n",
    "              \n",
    "        in_str = lambda s1, s2: ' ' + s1 + ' ' in ' ' + s2 + ' '\n",
    "        \n",
    "        for i, row in enumerate(self.u_df.iterrows(), 1):\n",
    "                               \n",
    "            users_country = None\n",
    "              \n",
    "            if isinstance(row[1].location, str):\n",
    "              \n",
    "                loc_str = ' '.join(re.sub(r'[\\-\\_]', ' ', row[1].location).split()).lower()\n",
    "\n",
    "                _found_countries = set()\n",
    "\n",
    "                for country in self.countries:\n",
    "                    if in_str(country, loc_str):\n",
    "                        _found_countries.add(country.title())\n",
    "\n",
    "                if len(_found_countries) == 1:\n",
    "                    users_country = _found_countries.pop()\n",
    "                else:\n",
    "                  # run geolocation\n",
    "                  r = self._fix_location(loc_str)\n",
    "                  c_geo += 1\n",
    "              \n",
    "                  if 'country' in r:\n",
    "                     users_country = r['country']\n",
    "            \n",
    "            print(f'#{i}: location: {row[1].location} -> country: {users_country}')\n",
    "            \n",
    "            countries.append(users_country)\n",
    "                               \n",
    "        self.u_df['country'] = countries\n",
    "              \n",
    "        print(f'ran geolocation {c_geo} times ({100*c_geo/len(self.u_df):.1f}%)')\n",
    "        \n",
    "        return self\n",
    "    \n",
    "    def _impute_gender(self, s):\n",
    "        \n",
    "        # separate nicknames like TrevorJ into trevor J; or Mike23 into Mike 23\n",
    "        s = re.sub(r'([a-z]{1})([A-Z0-9]+)', r'\\1 \\2', s)\n",
    "        \n",
    "        return self.gd.gender(s)\n",
    "    \n",
    "    def impute_gender(self):\n",
    "        \n",
    "        self.u_df['gender'] = self.u_df['gender'] \\\n",
    "                                .apply(lambda s: s if str(s) in 'm f'.split() else self._impute_gender(str(s)))\n",
    "        return self\n",
    "    \n",
    "    def merge_data(self):\n",
    "        \n",
    "        self.data = self.r_df.join(self.u_df.set_index('name'), on='by_user', how='inner')\n",
    "        \n",
    "        return self\n",
    "    \n",
    "    def selector(self, req_dict):\n",
    "\n",
    "        \"\"\"\n",
    "        return a data frame obtained from the original one (df) by filtering out all rows that don't match\n",
    "        the required values provided in the dictionary req_dict which looks like, for example, \n",
    "        {'age': '13-17', 'gender': 'f',...}\n",
    "\n",
    "        what if after all the filtering all that's left is an empty data frame? then just return that empty data frame\n",
    "        \"\"\"\n",
    "\n",
    "        if self.data.empty:\n",
    "            print('dataframe you\\'re trying to select from is empty!')\n",
    "            return self\n",
    "\n",
    "        actual_cols = set(self.data.columns) | {'tourist_type'}\n",
    "        required_cols = set(req_dict)\n",
    "\n",
    "        if not (required_cols <= actual_cols):\n",
    "            cols_na = ', '.join(required_cols - actual_cols)\n",
    "            raise Exception(f'column(s) {cols_na} you\\'re asking for are not available!')\n",
    "\n",
    "        out = self.data\n",
    "\n",
    "        for col in required_cols:\n",
    "\n",
    "            if req_dict[col] != 'all':\n",
    "\n",
    "                if col != 'tourist_type':\n",
    "                    out = out[out[col].astype(str) == req_dict[col]]\n",
    "                else:\n",
    "                    out = out[out[req_dict[col]] == 'yes']\n",
    "                if out.empty:\n",
    "                    print('dataframe you\\'re trying to select from became empty!')\n",
    "                    break\n",
    "\n",
    "        return out\n",
    "              \n",
    "    def prepr_(self, review_text):\n",
    "    \n",
    "        review_ = defaultdict(list)\n",
    "        review_['original'] = review_text\n",
    "        \n",
    "        doc = nlp(review_text)\n",
    "              \n",
    "        review_['ents'] = [e.text for e in doc.ents]\n",
    "        review_['labels'] = [e.label_ for e in doc.ents]\n",
    "              \n",
    "        review_text = review_text.lower()\n",
    "        doc = nlp(review_text)\n",
    "              \n",
    "        review_['lemmatised'] = ['$' if w.is_currency else w.lemma_ for w in doc if not any([w.is_stop, w.is_punct, len(w.lemma_) < 1])]\n",
    "        review_['nouns'] = [w.lemma_ for w in doc if w.pos_ == 'NOUN']\n",
    "        review_['verbs'] = [w.lemma_ for w in doc if w.pos_ == 'VERB']\n",
    "        \n",
    "        return review_\n",
    "              \n",
    "    def get_textdata(self, seg1_dict, seg2_dict):\n",
    "               \n",
    "        seg1_df = self.selector(seg1_dict)\n",
    "        seg1_df['segment'] = 'seg1'\n",
    "              \n",
    "        seg1_df['lemmatised'] = seg1_df.text.apply(lambda x: ' '.join(self.prepr_(x)['lemmatised']))\n",
    "              \n",
    "        seg2_df = self.selector(seg2_dict)\n",
    "        seg2_df['segment'] = 'seg2'\n",
    "              \n",
    "        seg2_df['lemmatised'] = seg2_df.text.apply(lambda x: ' '.join(self.prepr_(x)['lemmatised']))\n",
    "              \n",
    "        self.text_data = pd.concat([seg1_df[['lemmatised', 'segment']], seg2_df[['lemmatised', 'segment']]])\n",
    "        \n",
    "        return self\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DATA\n",
      "----\n",
      "13,017 reviews written between 12/2010 and 03/2019 for 50 attractions by 8,749 users\n",
      "user attribute availability:\n",
      "tags: 2,179 (24.9)% ~ age: 3,152 (36.0)% ~ gender: 4,031 (46.1)%\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    \n",
    "    t = T(review_file='data/reviews_mel.json',\n",
    "         users_file='data/reviewers_mel.json',\n",
    "         attract_file='data/attractions_melbourne.json').stats().tags_to_cols().merge_data().get_textdata(seg1_dict={'gender': 'm'}, \n",
    "                                                                                                         seg2_dict={'gender': 'f'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lemmatised</th>\n",
       "      <th>segment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>interesting collection old new varied mix art ...</td>\n",
       "      <td>seg1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>340</th>\n",
       "      <td>immigration museum show illustrate variety peo...</td>\n",
       "      <td>seg1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>572</th>\n",
       "      <td>good insect exhibit planet varied collection p...</td>\n",
       "      <td>seg1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>surprising european art interesting display ex...</td>\n",
       "      <td>seg1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2715</th>\n",
       "      <td>great meet hang wander screen show stuff excel...</td>\n",
       "      <td>seg1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             lemmatised segment\n",
       "1     interesting collection old new varied mix art ...    seg1\n",
       "340   immigration museum show illustrate variety peo...    seg1\n",
       "572   good insect exhibit planet varied collection p...    seg1\n",
       "8     surprising european art interesting display ex...    seg1\n",
       "2715  great meet hang wander screen show stuff excel...    seg1"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.text_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = st.CorpusFromPandas(t.text_data, category_col='segment', text_col='lemmatised', nlp=nlp).build()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# term frequency data frame; note that terms become index!\n",
    "term_freq_df = corpus.get_term_freq_df()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>seg1 freq</th>\n",
       "      <th>seg2 freq</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>term</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>interesting</th>\n",
       "      <td>269</td>\n",
       "      <td>201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>collection</th>\n",
       "      <td>64</td>\n",
       "      <td>70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>old</th>\n",
       "      <td>316</td>\n",
       "      <td>233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>new</th>\n",
       "      <td>148</td>\n",
       "      <td>79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>varied</th>\n",
       "      <td>14</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             seg1 freq  seg2 freq\n",
       "term                             \n",
       "interesting        269        201\n",
       "collection          64         70\n",
       "old                316        233\n",
       "new                148         79\n",
       "varied              14          4"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "term_freq_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get scaled f-scores for each term and place in new column\n",
    "term_freq_df['s1_score'] = corpus.get_scaled_f_scores('seg1')\n",
    "term_freq_df['s2_score'] = corpus.get_scaled_f_scores('seg2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>seg1 freq</th>\n",
       "      <th>seg2 freq</th>\n",
       "      <th>s1_score</th>\n",
       "      <th>s2_score</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>term</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [seg1 freq, seg2 freq, s1_score, s2_score]\n",
       "Index: []"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "term_freq_df[term_freq_df.s2_score < 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/scattertext/frequencyreaders/DefaultBackgroundFrequencies.py:30: FutureWarning:\n",
      "\n",
      "read_table is deprecated, use read_csv instead, passing sep='\\t'.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "html = st.produce_scattertext_explorer(corpus,\n",
    "category='seg1',\n",
    "category_name='Foodies',\n",
    "not_category_name='Hist Buffs',\n",
    "width_in_pixels=1000,\n",
    "metadata=t.text_data['segment'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1891159"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "open(\"hz.html\", 'wb').write(html.encode('utf-8'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "html = st.produce_scattertext_explorer(corpus, category='1', \n",
    "                                       category_name='Segment 1',  # for presentation only\n",
    "                                       not_category_name='2',\n",
    "                                       width_in_pixels=1000, \n",
    "                                       metadata=df['segment'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "open(\"segs.html\", 'wb').write(html.encode('utf-8'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_builder = st.FeatsFromOnlyEmpath()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "empath_corpus = st.CorpusFromParsedDocuments(df, \n",
    "                                             category_col='segment', \n",
    "                                             feats_from_spacy_doc=feat_builder, \n",
    "                                             parsed_col='text').build()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "html = st.produce_scattertext_explorer(empath_corpus, \n",
    "                                       category='1', \n",
    "                                       category_name='Segment 1',\n",
    "                                       not_category_name='Segment 2',\n",
    "                                       width_in_pixels=1000,\n",
    "                                       metadata=df['segment'],\n",
    "                                       use_non_text_features=True,\n",
    "                                       use_full_doc=True,\n",
    "                                       topic_model_term_lists=feat_builder.get_top_model_term_lists())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "open(\"segs_empath.html\", 'wb').write(html.encode('utf-8'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_min = term_freq_df.male_score.min()\n",
    "x_max = term_freq_df.male_score.max()\n",
    "x_mean = term_freq_df.male_score.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_min = term_freq_df.female_score.min()\n",
    "y_max = term_freq_df.female_score.max()\n",
    "y_mean = term_freq_df.female_score.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trace0 = go.Scatter(\n",
    "    x = term_freq_df.iloc[:1000].male_score,\n",
    "    y = term_freq_df.iloc[:1000].female_score,\n",
    "    mode = 'markers',\n",
    "    name = 'markers',\n",
    "    text= term_freq_df.iloc[:1000].index\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [trace0]\n",
    "iplot(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = pd.read_csv('word_freq.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
