{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.common.action_chains import ActionChains\n",
    "\n",
    "from collections import defaultdict\n",
    "import re\n",
    "import json\n",
    "import os\n",
    "import time\n",
    "import arrow\n",
    "import random\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import subprocess\n",
    "import zipfile\n",
    "\n",
    "from attraction import Attraction\n",
    "from review import Review\n",
    "from user import User"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " class Trip:\n",
    "    \n",
    "    def __init__(self, filter):\n",
    "        \n",
    "        options = webdriver.ChromeOptions()\n",
    "        options.add_argument('--ignore-certificate-errors')\n",
    "        options.add_argument('--ignore-ssl-errors')\n",
    "        options.add_argument('--incognito')\n",
    "        options.add_argument('--start-maximized')\n",
    "        prefs = {\"profile.default_content_setting_values.notifications\" : 2}\n",
    "        options.add_experimental_option(\"prefs\",prefs)\n",
    "\n",
    "        options.add_argument('--headless')\n",
    "        \n",
    "        self.driver = webdriver.Chrome('webdriver/chromedriver', options=options)\n",
    "        \n",
    "        self.FILTREVS = defaultdict()\n",
    "        self.REVIEWS = defaultdict()\n",
    "        \n",
    "        # counter to see how many annoying things get killed\n",
    "        self.KILLED = defaultdict(int)\n",
    "        \n",
    "        self.FILTERS = filter\n",
    "        \n",
    "        print(f'filter: {\" | \".join([k + \":\" + str(v) for k, v in self.FILTERS.items() if v])}')\n",
    "        \n",
    "        self.DATA_DIR = 'data'\n",
    "        self.COLLECT_DIR = 'data-collected'\n",
    "        \n",
    "        if not os.path.exists(self.DATA_DIR):\n",
    "            os.mkdir(self.DATA_DIR)\n",
    "            \n",
    "        if not os.path.exists(self.COLLECT_DIR):\n",
    "            os.mkdir(self.COLLECT_DIR)\n",
    "        \n",
    "        self.LOCATION_IDS = json.load(open(os.path.join(self.DATA_DIR, 'tradvisor_location_ids.json')))\n",
    "            \n",
    "    def do_click(self, e, max_=3):\n",
    "        \n",
    "        \"\"\"\n",
    "        try to click on element e and return True if it worked or False otherwise\n",
    "        \"\"\"\n",
    "        \n",
    "        # assume not click\n",
    "        _clicked = False\n",
    "        _c = 0\n",
    "\n",
    "        while (not _clicked) and (_c < max_):\n",
    "\n",
    "            try:\n",
    "                e.click()\n",
    "                _clicked = True\n",
    "            except:\n",
    "                try:\n",
    "                    self.driver.find_element_by_css_selector('span.ui_overlay>div.ui_close_x').click()\n",
    "                    self.KILLED['overlay'] += 1\n",
    "                except:\n",
    "                    # try to catch and close all sliders\n",
    "                    els = list(self.driver.find_elements_by_css_selector('div[class^=\"QSISlider\"]>div'))\n",
    "                    for i, d in enumerate(els):\n",
    "                        if d.text.strip().lower() == 'Not right now, thanks.'.strip().lower():\n",
    "                            try:\n",
    "                                els[i-1].click()\n",
    "                                self.KILLED['slide'] += 1\n",
    "                                break\n",
    "                            except:\n",
    "                                continue\n",
    "                    for _ in self.driver.find_elements_by_css_selector('div.sbx_close[onclick]'):\n",
    "                        try:\n",
    "                            _.click()\n",
    "                            self.KILLED['infobar'] += 1\n",
    "                        except:\n",
    "                            pass        \n",
    "            _c += 1\n",
    "\n",
    "        return _clicked\n",
    "    \n",
    "    def process_paginator(self, pg, off=30, pref='oa'):\n",
    "        \n",
    "        p_numbers = [int(s.text.strip()) for s in pg.find_elements_by_css_selector('div') if s.text.strip().isdigit()]\n",
    "        \n",
    "        if p_numbers:\n",
    "            total_pages = p_numbers[-1]\n",
    "        else:\n",
    "            raise Exception('no pages in paginator!')\n",
    "        \n",
    "        current_page_url = self.driver.current_url\n",
    "        last_page_url = self.driver.current_url\n",
    "        \n",
    "        page_urls = [current_page_url]\n",
    "        \n",
    "        for _ in pg.find_elements_by_css_selector('div>a'):\n",
    "            if _.text.isdigit():\n",
    "                last_page_url = _.get_attribute('href')\n",
    "                \n",
    "        if total_pages > 1:\n",
    "            for i in range(1, total_pages):\n",
    "                # starts from page 2 (page 1 has no -oa[number]- part)\n",
    "                page_urls.append(re.sub('Activities-', 'Activities-' + pref + str(off*i) + '-', current_page_url))\n",
    "                \n",
    "        return total_pages, page_urls\n",
    "        \n",
    "    def get_attraction_pages(self, loc):\n",
    "        \n",
    "        \"\"\"\n",
    "        go to the home page for location loc and collect all attractions; if loc is a state, collect attractions\n",
    "        for every location in that state\n",
    "        \n",
    "        \"\"\"\n",
    "        \n",
    "        self.MAIN_LOCATION = loc\n",
    "        \n",
    "        # home_urls will be a list of tuples like \n",
    "        # [('tasmania', 'hobart', 'https://www.tripadvisor.com.au/Home-g255097'), \n",
    "        #  ('tasmania', 'launceston', 'https://www.tripadvisor.com.au/Home-g255344')...\n",
    "        \n",
    "        home_urls = []\n",
    "        \n",
    "        self.collected_attractions = defaultdict(lambda: defaultdict(lambda: defaultdict()))\n",
    "        \n",
    "        \"\"\"\n",
    "        {'tasmania': {'hobart': {attr_id: {name: market,\n",
    "                                            url: 'https:/www...'}}}\n",
    "        \"\"\"\n",
    "        \n",
    "        # if loc is state\n",
    "        if self.MAIN_LOCATION in self.LOCATION_IDS:\n",
    "            for city in self.LOCATION_IDS[loc]:\n",
    "                home_urls.append((self.MAIN_LOCATION, city, f'https://www.tripadvisor.com.au/Home-{self.LOCATION_IDS[loc][city]}'))\n",
    "        else:\n",
    "            for state_ in self.LOCATION_IDS:\n",
    "                if self.MAIN_LOCATION in self.LOCATION_IDS[state_]:\n",
    "                    home_urls.append((state_, self.MAIN_LOCATION, f'https://www.tripadvisor.com.au/Home-{self.LOCATION_IDS[state_][loc]}'))\n",
    "                    \n",
    "        if not home_urls:\n",
    "            print(f'no attractions to pick for {loc.upper()}!')\n",
    "            return self\n",
    "        \n",
    "        for state_, city_, homeurl in home_urls:\n",
    "            \n",
    "            print(f'collecting attractions for {city_.upper()}, {state_.upper()}...')\n",
    "            \n",
    "            self.driver.get(homeurl)\n",
    "            \n",
    "            # ---- find and click the Things to Do icon; assume it MUST be there\n",
    "            \n",
    "            thingstodo_clicked = False\n",
    "            \n",
    "            while not thingstodo_clicked:\n",
    "                \n",
    "                try:\n",
    "                    things_to_do_icon = WebDriverWait(self.driver, 10) \\\n",
    "                                .until(EC.presence_of_element_located((By.CSS_SELECTOR, 'span.ui_icon.attractions + span')))\n",
    "                except:\n",
    "                    raise Exception('failed to find Things to do icon!')\n",
    "                \n",
    "                if things_to_do_icon.text.strip().lower() != 'Things to do'.strip().lower():\n",
    "                    continue\n",
    "                    \n",
    "                res = self.do_click(things_to_do_icon)\n",
    "                    \n",
    "                if not res:\n",
    "                    print('failed to click Things to do icon! retrying..')\n",
    "                else:\n",
    "                    thingstodo_clicked = True\n",
    "                \n",
    "            # ------- ok, so clicked the icon; now the question is whether there are many 'top' things to \n",
    "            # do or just a few; the latter means no need to look for the See More button\n",
    "            \n",
    "            moveon = False\n",
    "            few_attractions = False\n",
    "            \n",
    "            # try to click See More first\n",
    "            \n",
    "            while 1:\n",
    "                \n",
    "                try:\n",
    "                    c_mo = WebDriverWait(self.driver, 10) \\\n",
    "                            .until(EC.element_to_be_clickable((By.CSS_SELECTOR, \n",
    "                                    'div[class|=\"attractions-attraction-overview-main-TopPOIs__see_more\"]')))\n",
    "                except:\n",
    "                    # if there's no See More it's just 1 page with attractions\n",
    "                    page_urls = [self.driver.current_url]\n",
    "                    few_attractions = True\n",
    "                    break\n",
    "                \n",
    "                seeless = False\n",
    "                \n",
    "                while not seeless:\n",
    "                    \n",
    "                    res = self.do_click(c_mo)\n",
    "                    \n",
    "                    # didn't click..\n",
    "                    if not res:\n",
    "\n",
    "                        try:\n",
    "                            # there is this See More button but still folded, so apparently we didn't click properly\n",
    "                            self.driver.find_element_by_css_selector('span.ui_icon.single-chevron-down')\n",
    "                        except:\n",
    "                            seeless = True\n",
    "                    # look like clicked See More..\n",
    "                    else:\n",
    "                        try:\n",
    "                            WebDriverWait(self.driver, 10) \\\n",
    "                                .until(EC.presence_of_element_located((By.CSS_SELECTOR, \n",
    "                                    'span.ui_icon.single-chevron-up')))\n",
    "\n",
    "                            seeless = True\n",
    "                        except:\n",
    "                            print('no See Less, need to click See more again')\n",
    "                break                \n",
    "            \n",
    "            # paginator only available if there are many attractions; however, there may be no paginator if See More\n",
    "            # was clicked but there are still too few attractions\n",
    "            \n",
    "            if not few_attractions:\n",
    "                \n",
    "                try:\n",
    "                    pg = WebDriverWait(self.driver, 10) \\\n",
    "                            .until(EC.presence_of_element_located((By.CSS_SELECTOR, \n",
    "                                    'div[class|=\"attractions-attraction-overview-main-Pagination__container\"]')))\n",
    "                except:\n",
    "                    pg = None\n",
    "                \n",
    "                if pg:\n",
    "                    total_pages, page_urls = self.process_paginator(pg) \n",
    "                else:\n",
    "                    page_urls = [self.driver.current_url]\n",
    "\n",
    "            print('visiting attraction pages..')\n",
    "\n",
    "            for i, attr_page_url in enumerate(page_urls, 1):\n",
    "                \n",
    "                print(f'page {i}/{len(page_urls)}..', end='')\n",
    "\n",
    "                if attr_page_url != self.driver.current_url:\n",
    "                    self.driver.get(attr_page_url)\n",
    "                \n",
    "                if i == 1:\n",
    "                    \n",
    "                    attr_topick_css = 'div[class|=\"attractions-attraction-overview-pois-PoiGrid__wrapper\"]' + \\\n",
    "                                      '>li[class^=\"attractions-attraction-overview-pois-PoiCard__item\"]' + \\\n",
    "                                      '>div[class|=\"attractions-attraction-overview-pois-PoiCard__card_info\"]'\n",
    "                            \n",
    "                    attr_topick = len(self.driver.find_elements_by_css_selector(attr_topick_css))\n",
    "                    \n",
    "                    while attr_topick:\n",
    "                        \n",
    "                        for attr_card in self.driver.find_elements_by_css_selector(attr_topick_css):\n",
    "\n",
    "                            try:\n",
    "                                url_ = attr_card.find_element_by_css_selector('div>a[class|=\"attractions-attraction-overview-pois-PoiInfo__name\"]') \\\n",
    "                                                        .get_attribute('href')\n",
    "                            except:\n",
    "                                print('didn\\'t get attraction url! moving on to next attraction card..')\n",
    "                                continue\n",
    "                            \n",
    "                            try:\n",
    "                                id_ = re.search(r'(?<=-)d\\d+(?=-)', url_).group(0)\n",
    "                            except:\n",
    "                                print('failed to extract attraction id!')\n",
    "                                continue\n",
    "                            \n",
    "                            try:\n",
    "                                self.collected_attractions[state_][city_][id_] = {'url': url_}\n",
    "                                attr_topick -= 1\n",
    "                            except:\n",
    "                                pass\n",
    "\n",
    "                elif i > 1:\n",
    "                    \n",
    "                    attr_topick_css = 'div.attraction_list>div' + \\\n",
    "                                      '>div>div.listing>div.listing_details>div.listing_info'\n",
    "                        \n",
    "                    attr_topick = len(self.driver.find_elements_by_css_selector(attr_topick_css))\n",
    "                    \n",
    "                    while attr_topick:\n",
    "                        \n",
    "                        for attr_card in self.driver.find_elements_by_css_selector(attr_topick_css):\n",
    "\n",
    "                            try:\n",
    "                                url_ = attr_card.find_element_by_css_selector('div.tracking_attraction_title.listing_title>a').get_attribute('href')\n",
    "                            except:\n",
    "                                print('didn\\'t get attraction url! moving on to next attraction card..')\n",
    "                                continue\n",
    "                                \n",
    "                            try:\n",
    "                                id_ = re.search(r'(?<=-)d\\d+(?=-)', url_).group(0)\n",
    "                            except:\n",
    "                                print('failed to extract attraction id!')\n",
    "                                continue\n",
    "                            \n",
    "                            try:\n",
    "                                self.collected_attractions[state_][city_][id_] = {'url': url_}\n",
    "                                attr_topick -= 1\n",
    "                            except:\n",
    "                                pass\n",
    "            \n",
    "                print('ok')\n",
    "    \n",
    "        return self\n",
    "\n",
    "    def select_filters(self):\n",
    "        \n",
    "        \"\"\"\n",
    "        apply filter on the attraction page and return the number of reviews available\n",
    "        after the filter has been applied\n",
    "        \"\"\"\n",
    "        \n",
    "        d = {'traveller_rating': {'data-name': 'ta_rating',\n",
    "                                  'input-values': {'Excellent': '5',\n",
    "                                                   'Very good': '4',\n",
    "                                                   'Average': '3',\n",
    "                                                   'Poor': '2',\n",
    "                                                   'Terrible': '1'},\n",
    "                                 'pick': self.FILTERS['traveller_rating']},\n",
    "            'traveller_type': {'data-name': 'traveler_filter',\n",
    "                               'input-values': {'Families': '3',\n",
    "                                                'Couples': '2',\n",
    "                                                'Solo': '5',\n",
    "                                                'Business': '1',\n",
    "                                                'Friends': '4'},\n",
    "                              'pick': self.FILTERS['traveller_type']},\n",
    "            'time_of_year': {'data-name': 'season',\n",
    "                             'input-values': {'Mar-May': '1',\n",
    "                                              'Jun-Aug': '2',\n",
    "                                              'Sep-Nov': '3',\n",
    "                                              'Dec-Feb': '4'},\n",
    "                            'pick': self.FILTERS['time_of_year']},\n",
    "            'language': {'data-name': 'language',\n",
    "                         'input-values': {'English': 'en',\n",
    "                                          'Japanese': 'ja'},\n",
    "                         'pick': self.FILTERS['language']}}\n",
    "\n",
    "        def is_selected(css_selector_st):\n",
    "\n",
    "            try:\n",
    "                WebDriverWait(self.driver, 5) \\\n",
    "                            .until(EC.presence_of_element_located((By.CSS_SELECTOR, \n",
    "                                                                   css_selector_st + '>input[checked=\"checked\"]')))\n",
    "                return True\n",
    "\n",
    "            except:\n",
    "                return False\n",
    "\n",
    "        def _click(css_selector_st, max_attempts=3):\n",
    "\n",
    "            times_tried = 0\n",
    "\n",
    "            flag_before = is_selected(css_selector_st)\n",
    "            flag_after = flag_before\n",
    "\n",
    "            while (times_tried <= max_attempts) and (flag_after == flag_before):\n",
    "\n",
    "                times_tried += 1   \n",
    "\n",
    "                try:\n",
    "                    e = WebDriverWait(self.driver, 20) \\\n",
    "                            .until(EC.element_to_be_clickable((By.CSS_SELECTOR, css_selector_st)))\n",
    "                except:\n",
    "                    e = None\n",
    "                    print(f'failed to find {css_selector_st}!')\n",
    "                \n",
    "                if e:\n",
    "                    res = self.do_click(e)\n",
    "\n",
    "                flag_after = is_selected(css_selector_st)    \n",
    "\n",
    "            return (flag_after != flag_before)\n",
    "\n",
    "\n",
    "        for filt in d:\n",
    "\n",
    "            value = d[filt]['pick']\n",
    "\n",
    "            # uncheck everything else\n",
    "            to_uncheck = [other_value for other_value in d[filt]['input-values'] if other_value != value]\n",
    "\n",
    "            if to_uncheck:\n",
    "\n",
    "                for other_value in to_uncheck:\n",
    "\n",
    "                    tr_pick = d[filt]['input-values'][other_value]\n",
    "                    dname = d[filt]['data-name']\n",
    "                    st = f'div.choices[data-name=\"{dname}\"]>div[data-value=\"{tr_pick}\"]'\n",
    "\n",
    "                    if is_selected(st):\n",
    "                        res = _click(st)\n",
    "\n",
    "            if value:\n",
    "\n",
    "                tr_pick = d[filt]['input-values'][value]\n",
    "                dname = d[filt]['data-name']\n",
    "                st = f'div.choices[data-name=\"{dname}\"]>div[data-value=\"{tr_pick}\"]'\n",
    "\n",
    "                if is_selected(st):\n",
    "                    continue\n",
    "                else:\n",
    "                    _selected =  _click(st)\n",
    "\n",
    "        try:\n",
    "            lang_code = d['language']['input-values'][d['language']['pick']] \n",
    "            css_count = f'div.choices[data-name=\"language\"]>div[data-value=\"{lang_code}\"]>label.label>span.count'\n",
    "            c_txt = WebDriverWait(self.driver, 6) \\\n",
    "                            .until(EC.presence_of_element_located((By.CSS_SELECTOR, css_count))).text.strip()\n",
    "            c = int(re.sub(r'[(,)]','',c_txt))\n",
    "        except:\n",
    "            # if no review count it's because there are not reviews left after filtering\n",
    "            return 0\n",
    "            \n",
    "        return int(c)\n",
    "            \n",
    "    def get_reviews_from_attraction_pages(self, min_total_reviews=50):\n",
    "        \n",
    "        # total number of attractions to check out\n",
    "        natt = len({a_id for state_ in self.collected_attractions\n",
    "                        for city_ in self.collected_attractions[state_]\n",
    "                             for a_id in self.collected_attractions[state_][city_]})\n",
    "        \n",
    "        # counter for processed attractions\n",
    "        catt = 0\n",
    "        \n",
    "        for state_ in self.collected_attractions:\n",
    "            for city_ in self.collected_attractions[state_]:\n",
    "                for a_id in self.collected_attractions[state_][city_]:\n",
    "                    \n",
    "                    catt += 1\n",
    "                    print(f'attraction #{catt:,}/{natt:,}..')\n",
    "                        \n",
    "                    self.driver.get(self.collected_attractions[state_][city_][a_id]['url'])\n",
    "                    \n",
    "                    attr_details = defaultdict(name=None, total_reviews=None, category=None, rating_chart=None)\n",
    "                    \n",
    "                    try:\n",
    "                        attr_details['name'] = self.driver.find_element_by_css_selector('div.attractionsHeader>h1#HEADING').text\n",
    "                        self.collected_attractions[state_][city_][a_id]['attr_name'] = attr_details['name']\n",
    "                    except:\n",
    "                        try:\n",
    "                            # it's probably a tour privider\n",
    "                            tour_operatior_name = self.driver.find_element_by_css_selector('h1[id=\"HEADING\"][class|=\"attractions-supplier-profile-\"]').text.strip()\n",
    "                            print(f'looks like a tour operator: {tour_operatior_name}; skipping')\n",
    "                            continue\n",
    "                        except:\n",
    "                            print(f'failed to find name for attraction {a_id}, skipping..')\n",
    "                            continue\n",
    "                        \n",
    "                    print(f'{a_id}: {attr_details[\"name\"]}...')\n",
    "                    \n",
    "                    # how namy reviews does this attractio have?\n",
    "                    # if there's no rating (so no reviews) simply return 0 reviews right away\n",
    "                    try:\n",
    "                        self.driver.find_element_by_css_selector('div.section.rating>a.ui_bubble_rating.noReviewsBubbles')\n",
    "                        revs = 0\n",
    "                    except BaseException as e:\n",
    "                        # so there are some reviews..\n",
    "                        try:\n",
    "                            # 21,121 Reviews\n",
    "                            revs = int(self.driver.find_element_by_css_selector('div.ratingContainer>a>span.reviewCount') \\\n",
    "                                        .text.replace(',','').split()[0])\n",
    "                        except:\n",
    "                            print('failed to find the total number of reviews!')\n",
    "                            revs = 0\n",
    "                    \n",
    "                    if revs < min_total_reviews:\n",
    "                        # too few reviews, doesn't make sense to proceed with this attraction\n",
    "                        print(f'only {revs:,} reviews, skipping..')\n",
    "                        continue\n",
    "                        \n",
    "                    self.FILTREVS[a_id] = self.select_filters()\n",
    "                    \n",
    "                    print(f'filtered reviews: {self.FILTREVS[a_id]:,}')\n",
    "\n",
    "                    if not self.FILTREVS[a_id]:\n",
    "                        print('skipping..')\n",
    "                        continue\n",
    "\n",
    "                    try:\n",
    "                        attr_details['total_reviews'] = self.driver.find_element_by_css_selector('div.ratingContainer').text.lower()\n",
    "                    except:\n",
    "                        pass\n",
    "\n",
    "                    try:\n",
    "                        attr_details['category'] = self.driver.find_element_by_css_selector('span.attractionCategories').text\n",
    "                    except:\n",
    "                        pass\n",
    "\n",
    "                    try:\n",
    "                        attr_details['rating_chart'] = [tuple(l.strip().split('\\n')) for l in self.driver.find_element_by_css_selector('ul.ratings_chart').text.split('%') if l.strip()]\n",
    "                    except:\n",
    "                        pass\n",
    "\n",
    "                    # reviews for THIS ATTRACTION\n",
    "                    reviews = defaultdict(lambda: defaultdict())\n",
    "                    reviews_on_page = [0]\n",
    "\n",
    "                    while len(reviews) < self.FILTREVS[a_id]:\n",
    "\n",
    "                        try:\n",
    "                            reviews_this_page = int(WebDriverWait(self.driver, 10) \\\n",
    "                                .until(EC.visibility_of_element_located((By.CSS_SELECTOR, \n",
    "                                        'div[data-contextchoice=\"DETAIL\"]>div.pagination-details'))).text.split('-')[1].strip().split()[0]) \n",
    "                        except:\n",
    "                            if self.FILTREVS[a_id] <= 10:\n",
    "                                reviews_this_page = self.FILTREVS[a_id]\n",
    "                            else:\n",
    "                                try:\n",
    "                                    # just count rating timestamps if any\n",
    "                                    reviews_this_page = len(self.driver.find_elements_by_css_selector('span.ratingDate'))\n",
    "                                except:\n",
    "                                    raise Exception('failed to pick the number of reviews on this page!') \n",
    "                        \n",
    "                        reviews_on_page.append(reviews_this_page)\n",
    "                        \n",
    "                        to_pick = reviews_on_page[-1] - reviews_on_page[-2]\n",
    "                        \n",
    "                        picked_reviews = set()\n",
    "\n",
    "                        while len(picked_reviews) < to_pick:\n",
    "                            \n",
    "                            # first unfold all reviews on the page\n",
    "\n",
    "                            for c in self.driver.find_elements_by_css_selector('div.entry>p.partial_entry>span[class~=\"ulBlueLinks\"][onclick]'):\n",
    "\n",
    "                                self.do_click(c)\n",
    "\n",
    "                            # and now collect all full review texts\n",
    "                            review_ids_this_page = set()\n",
    "                \n",
    "                            n_review_blocks = len(self.driver.find_elements_by_css_selector('div.reviewSelector'))\n",
    "                                    \n",
    "                            while len(review_ids_this_page) < n_review_blocks:\n",
    "                                    \n",
    "                                    for c in self.driver.find_elements_by_css_selector('div.reviewSelector'):\n",
    "                                        _id = c.get_attribute('data-reviewid')\n",
    "                                        if _id:\n",
    "                                            review_ids_this_page.add(_id)\n",
    "                            \n",
    "                            # a set of review ids to collect on this page\n",
    "                            review_ids_to_collect_this_page = review_ids_this_page - set(reviews)\n",
    "\n",
    "                            if review_ids_to_collect_this_page:\n",
    "\n",
    "                                tot_revs = len(review_ids_to_collect_this_page)\n",
    "\n",
    "                            else:\n",
    "                                tot_revs = 0\n",
    "                                print('no new reviews on this page!')\n",
    "\n",
    "                            p = 0\n",
    "\n",
    "                            while p < tot_revs:\n",
    "                                \n",
    "                                print(f'{len(review_ids_to_collect_this_page)} ids to collect: {review_ids_to_collect_this_page}')\n",
    "\n",
    "                                for c in self.driver.find_elements_by_css_selector('div.reviewSelector'):        \n",
    "\n",
    "                                    try:\n",
    "\n",
    "                                        review_id = c.get_attribute('data-reviewid')\n",
    "\n",
    "                                        if review_id in review_ids_to_collect_this_page:\n",
    "\n",
    "                                            reviews[review_id]['text'] = c.find_element_by_css_selector('div>div>div.entry>p.partial_entry').text.strip()\n",
    "                                            \n",
    "                                            infotext_css = 'div.member_info>div>div.info_text'\n",
    "                                            \n",
    "                                            try:\n",
    "                                                username = c.find_element_by_css_selector(infotext_css).text.split('\\n')[0]\n",
    "                                            except:\n",
    "                                                break\n",
    "                                            \n",
    "                                            reviews[review_id]['user'] = username\n",
    "                                            \n",
    "                                            try:\n",
    "                                                userloc = c.find_element_by_css_selector(infotext_css + '>div.userLoc').text\n",
    "                                                reviews[review_id]['user_loc'] = userloc\n",
    "                                            except:\n",
    "                                                reviews[review_id]['user_loc'] = None\n",
    "                                                      \n",
    "                                            reviews[review_id]['attr_name'] = attr_details['name']\n",
    "                                            reviews[review_id]['attr_id'] = a_id\n",
    "                                            reviews[review_id]['attr_loc'] = city_\n",
    "                                            \n",
    "                                            # remove this reviews id from the set of review ids to collct\n",
    "                                            review_ids_to_collect_this_page -= {review_id}\n",
    "                                            # and put this id into the set of already collected ids\n",
    "                                            picked_reviews.add(review_id)\n",
    "                                            # increment the total of collected reviews on this page\n",
    "                                            p += 1\n",
    "\n",
    "                                        else:\n",
    "                                            continue\n",
    "                                    except:\n",
    "                                        continue\n",
    "\n",
    "                        # now try to click Next\n",
    "                        npage_url = None\n",
    "\n",
    "                        if self.FILTREVS[a_id] <= 10:\n",
    "                            last_page_url = self.driver.current_url\n",
    "                        else:\n",
    "                            try:\n",
    "                                last_page_url = list(self.driver.find_elements_by_css_selector('div.mobile-more>div>div.unified.ui_pagination>div.pageNumbers>a[href]'))[-1].get_attribute('href')\n",
    "                            except:\n",
    "                                last_page_url = self.driver.current_url \n",
    "\n",
    "                        if self.driver.current_url != last_page_url:\n",
    "\n",
    "                            # https://www.tripadvisor.com.au/Attraction_Review-g255097-d1063162-Reviews-or20-Mount_Wellington-Hobart_Greater_Hobart_Tasmania.html\n",
    "\n",
    "                            try:\n",
    "                                pref = int(re.search(r'(?<=-Reviews-or)\\d+', self.driver.current_url).group(0))\n",
    "                            except:\n",
    "                                pref = None\n",
    "\n",
    "                            if pref:\n",
    "                                next_page_url = self.driver.current_url.replace('or' + str(pref), 'or' + str(pref+10))\n",
    "                            else:\n",
    "                                next_page_url = self.driver.current_url.replace('Reviews-', 'Reviews-' + 'or' + str(10) + '-')\n",
    "\n",
    "                            if next_page_url != self.driver.current_url:\n",
    "                                self.driver.get(next_page_url)\n",
    "\n",
    "                        # add reviews for THIS attraction to the dictionary of ALL reviews\n",
    "                        self.REVIEWS.update(reviews)\n",
    "        \n",
    "        self.driver.close()\n",
    "        \n",
    "        return self\n",
    "        \n",
    "    def save_reviews(self):\n",
    "        \n",
    "        if not len(self.REVIEWS):\n",
    "            print('no reviews so nothing to save...')\n",
    "            return self\n",
    "            \n",
    "        file = '-'.join(['reviews', self.MAIN_LOCATION.replace(\" \",\"_\").upper(), \n",
    "                         self.FILTERS['traveller_type'], self.FILTERS['traveller_rating'], \n",
    "                         self.FILTERS['time_of_year']]) + '.json'\n",
    "            \n",
    "        json.dump(self.REVIEWS, open(os.path.join(self.COLLECT_DIR, file), 'w'))\n",
    "        \n",
    "        print(f'saved {len(self.REVIEWS):,} reviews')\n",
    "            \n",
    "        return self\n",
    "    \n",
    "    def save_attractions(self):\n",
    "    \n",
    "        json.dump(self.collected_attractions, \n",
    "                  open(os.path.join(self.COLLECT_DIR, \n",
    "                                    f'attractions-{self.MAIN_LOCATION.replace(\" \",\"_\").upper()}.json'), 'w'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " class CountryDetector:\n",
    "        \n",
    "    def __init__(self):\n",
    "        \n",
    "        self.DATA_DIR = 'data'\n",
    "        \n",
    "        self.us_states = pd.read_csv(os.path.join(self.DATA_DIR, 'usa_states.csv'))\n",
    "        self.us_cities = set(pd.read_csv(os.path.join(self.DATA_DIR, 'usa_cities.csv'))['city'])\n",
    "        self.uk_counties = set(pd.read_csv(os.path.join(self.DATA_DIR, 'uk_counties.csv'))['county'])\n",
    "        self.uk_cities = set(pd.read_csv(os.path.join(self.DATA_DIR, 'uk_cities.csv'))['city'])\n",
    "        \n",
    "        self.countries = pd.read_csv('data/country_abbrs.csv')\n",
    "    \n",
    "    def ukus(self, loc_str: str) -> str:\n",
    "        \n",
    "        \"\"\"\n",
    "        return 'UK' or 'USA' depending on what's been found in the string loc_str\n",
    "        \"\"\"\n",
    "        \n",
    "        if not isinstance(loc_str, str):\n",
    "            return None\n",
    "    \n",
    "        st =  ' ' + re.sub(r'[,.:;]', ' ', re.sub(r'\\s+', ' ', loc_str.lower().strip())) + ' '\n",
    "\n",
    "        sp = lambda x: ' ' + x + ' '\n",
    "        \n",
    "        uk_versions = {'united kingdom', 'uk'}\n",
    "        us_versions = {'united states', 'us'}\n",
    "\n",
    "        if any([sp('united kingdom') in st, sp('uk') in st]):\n",
    "            return 'UK'\n",
    "        elif any([sp('usa') in st, sp('united states') in st, sp('us') in st, sp('nyc') in st]):\n",
    "            return 'USA'\n",
    "\n",
    "        _us_states = set()\n",
    "        _us_cities = set()\n",
    "        _uk_counties = set()\n",
    "        _uk_cities = set()\n",
    "\n",
    "        for row in self.us_states.iterrows():\n",
    "            if (sp(row[1][0]) in st)  or (sp(row[1][1]) in st):\n",
    "                _us_states.add(row[1][0])\n",
    "\n",
    "        for c in self.us_cities:\n",
    "            if  sp(c) in st:\n",
    "                _us_cities.add(c)\n",
    "\n",
    "        for c in self.uk_counties:\n",
    "            if  sp(c) in st:\n",
    "                _uk_counties.add(c)\n",
    "\n",
    "        for c in self.uk_cities:\n",
    "            if  sp(c) in st:\n",
    "                _uk_cities.add(c)\n",
    "        \n",
    "        other_countries = sum(sp(c) in st for c in set(self.countries['country']) - set({'united kingdom', 'united states'}))\n",
    "        \n",
    "        if other_countries:\n",
    "            return None\n",
    "        \n",
    "        if _us_states:\n",
    "            return 'USA'\n",
    "        elif _uk_counties:\n",
    "            return 'UK'\n",
    "        if _us_cities and (not _us_cities & _uk_cities):\n",
    "            return 'USA'\n",
    "        if _uk_cities and (not _uk_cities & _us_cities):\n",
    "            return 'UK'\n",
    "        \n",
    "    def proc_review_files(self):\n",
    "        \n",
    "        for f in os.listdir('data-collected/'):\n",
    "            \n",
    "            if ('.json' in f) and ('reviews' in f):\n",
    "                try:\n",
    "                    state_, type_ = f.split('-')[1:3]\n",
    "                    \n",
    "                    cn = defaultdict(int)\n",
    "                    \n",
    "                    revs = json.load(open('data-collected/' + f))\n",
    "                    \n",
    "                    for rev_id in revs:\n",
    "                        \n",
    "                        cnt = self.ukus(revs[rev_id]['user_loc'])\n",
    "                        \n",
    "                        if cnt == 'UK':\n",
    "                            cn['UK'] += 1\n",
    "#                             print(f'{revs[rev_id][\"user_loc\"]} is {cnt}')\n",
    "                        elif cnt == 'USA':\n",
    "                            cn['USA'] += 1\n",
    "#                             print(f'{revs[rev_id][\"user_loc\"]} is {cnt}')\n",
    "                    \n",
    "                    print('\\n')\n",
    "                    print(f'{state_}/{type_} ###')\n",
    "                    print(f'USA: {cn[\"USA\"]:,}/{len(revs):,} ({100*cn[\"USA\"]/len(revs):.1f}%)')\n",
    "                    print(f'UK: {cn[\"UK\"]:,}/{len(revs):,} ({100*cn[\"UK\"]/len(revs):.1f}%)')\n",
    "                    \n",
    "                except:\n",
    "                    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    \n",
    "    t = Trip(filter={'traveller_rating': 'Excellent', \n",
    "                      'traveller_type':'Friends', \n",
    "                       'time_of_year': 'Jun-Aug',  \n",
    "                       'language':'English'}) \\\n",
    "                    .get_attraction_pages('western australia') \\\n",
    "                        .get_reviews_from_attraction_pages(min_total_reviews=100) \\\n",
    "                            .save_reviews() \\\n",
    "                                .save_attractions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "country_det = CountryDetector()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "country_det.proc_review_files()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
