{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "import pandas as pd\n",
    "import spacy\n",
    "\n",
    "import time\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from collections import Counter, defaultdict\n",
    "from itertools import chain\n",
    "import re\n",
    "\n",
    "import arrow \n",
    "\n",
    "import googlemaps\n",
    "\n",
    "from plotly import __version__\n",
    "from plotly.offline import download_plotlyjs, init_notebook_mode, plot, iplot\n",
    "import plotly.figure_factory as ff\n",
    "import plotly.graph_objs as go\n",
    "\n",
    "import cufflinks as cf\n",
    "\n",
    "import scattertext as st\n",
    "from scattertext import word_similarity_explorer\n",
    "\n",
    "from gender import GenderDetector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('en')\n",
    "\n",
    "nlp.Defaults.stop_words |= {'probably'}\n",
    "STOPWORDS = nlp.Defaults.stop_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script><script type=\"text/javascript\">if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script><script>requirejs.config({paths: { 'plotly': ['https://cdn.plot.ly/plotly-latest.min']},});if(!window._Plotly) {require(['plotly'],function(plotly) {window._Plotly=plotly;});}</script>"
      ],
      "text/vnd.plotly.v1+html": [
       "<script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script><script type=\"text/javascript\">if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script><script>requirejs.config({paths: { 'plotly': ['https://cdn.plot.ly/plotly-latest.min']},});if(!window._Plotly) {require(['plotly'],function(plotly) {window._Plotly=plotly;});}</script>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "init_notebook_mode(connected=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "class T:\n",
    "    \n",
    "    def __init__(self, review_file, users_file, attract_file):\n",
    "        \n",
    "        \"\"\"\n",
    "        collected TripAdvisor data comes as JSONs; this class does some data processing including imputation\n",
    "        \"\"\"\n",
    "\n",
    "        self.r = json.load(open(review_file))\n",
    "        self.u = json.load(open(users_file))\n",
    "        self.a = json.load(open(attract_file))  \n",
    "\n",
    "        # convert everything to pandas\n",
    "        self.u_df = pd.DataFrame(self.u).dropna(subset=['name'])\n",
    "        self.r_df = pd.DataFrame(self.r).dropna(subset=['attr_id']).dropna(subset=['text'])\n",
    "        \n",
    "        self.attribute_encodings = json.load(open('data/attribute_encodings.json'))\n",
    "        \n",
    "        self.attribute_encodings_rev = defaultdict(lambda: defaultdict(str))\n",
    "        \n",
    "        for attr in self.attribute_encodings:\n",
    "            self.attribute_encodings_rev[attr] = {s: i for i, s in self.attribute_encodings[attr].items()}\n",
    "            \n",
    "        self.countries = json.load(open('data/countries.json'))\n",
    "        self.KEY_COUNTRIES = [line.lower().strip() for line in open('data/key_countries.txt').readlines() \n",
    "                                              if line.lower().strip()]\n",
    "        \n",
    "        self.gmaps = googlemaps.Client(key=open('creds/geocoding_api.key').readline().strip())\n",
    "        \n",
    "        self.gd = GenderDetector()\n",
    "        \n",
    "    \n",
    "    def drop_unusable(self, subs=['text']):\n",
    "        \n",
    "        self.r_df = self.r_df.dropna(subset=subs)\n",
    "        \n",
    "        return self\n",
    "    \n",
    "    def review_attributes(self):\n",
    "        \n",
    "        \n",
    "        self.genders = ['all'] + [_.lower() for _ in set(self.u_df['gender']) if _.lower() in 'm f'.split()]\n",
    "        self.age_groups = ['all'] + sorted([ag for ag in set(self.u_df['age']) if '-' in str(ag)], \n",
    "                                               key=lambda x: int(str(x).split('-')[0]))\n",
    "        \n",
    "        self.tags = list(set([tg for tg in chain.from_iterable(self.u_df['tags'])]))\n",
    "        \n",
    "        self.tourist_types = ['all'] + sorted(self.tags)\n",
    "        \n",
    "        return self\n",
    "    \n",
    "    \n",
    "    def stats(self):\n",
    "        \n",
    "        self.user_stats = defaultdict(list)\n",
    "        \n",
    "        self.review_ids = set()\n",
    "        self.attr_ids = set()\n",
    "        self.user_names = set()\n",
    "        self.dates_exp = set()\n",
    "        \n",
    "        for r in self.r:\n",
    "            \n",
    "            self.review_ids.add(r['id'])\n",
    "            self.attr_ids.add(r['attr_id'])\n",
    "            self.user_names.add(r['by_user'])\n",
    "            \n",
    "            if r['date_of_experience']:\n",
    "                self.dates_exp.add(arrow.get(r['date_of_experience'], 'MM/YYYY'))\n",
    "        \n",
    "        print(f'DATA\\n{\"\".join([\"-\"]*4)}')\n",
    "        print('{:,} reviews written between {} and {} for {:,} attractions by {:,} users' \\\n",
    "                  .format(len(self.review_ids), \n",
    "                          min(self.dates_exp).format(\"MM/YYYY\"), \n",
    "                          max(self.dates_exp).format(\"MM/YYYY\"), \n",
    "                          len(self.attr_ids), \n",
    "                          len(self.user_names)))\n",
    "        \n",
    "        for u in self.u:\n",
    "            for attr in 'tags age gender name'.split():   \n",
    "                if u[attr]:\n",
    "                    self.user_stats[attr].append(u[attr])\n",
    "        \n",
    "        print('user attribute availability:')\n",
    "        print(' ~ '.join(['{}: {:,} ({:.1f})%'.format(attr, \n",
    "                                                    len(self.user_stats[attr]), \n",
    "                                                    100*len(self.user_stats[attr])/len(self.user_stats['name'])) \n",
    "                                                       for attr in 'tags age gender'.split()]))\n",
    "              \n",
    "        return self\n",
    "        \n",
    "    def _tags_to_cols(self, tag_list):\n",
    "        \n",
    "        if not tag_list:\n",
    "            return [None]*len(self.tag_cols)\n",
    "        \n",
    "        return ['yes' if tag in tag_list else 'no' for tag in self.tag_cols]\n",
    "    \n",
    "    def tags_to_cols(self):\n",
    "        \n",
    "        self.u_df = pd.concat([self.u_df, \n",
    "                            pd.DataFrame(self.u_df['tags'].apply(self._tags_to_cols).to_list(), \n",
    "                                         columns=self.tag_cols)], axis=1).drop('tags', axis=1)\n",
    "        \n",
    "        return self\n",
    "\n",
    "              \n",
    "    def _fix_location(self, s):\n",
    "              \n",
    "        \"\"\"\n",
    "        using Google Geocoding API to clarify users location\n",
    "        \"\"\"\n",
    "        \n",
    "        loc = dict()\n",
    "        \n",
    "        if not (isinstance(s, str) and s.strip()):\n",
    "            print('geocoding API needs a string argument!')\n",
    "            return loc\n",
    "        \n",
    "        geocode_result = self.gmaps.geocode(s)\n",
    "        \n",
    "        # take only the top result\n",
    "        if geocode_result:\n",
    "            res = geocode_result[0]\n",
    "        else:\n",
    "            print(f'geocoding api can\\'t find this location: {s}!')\n",
    "            return loc\n",
    "        \n",
    "        if 'address_components' in res:\n",
    "            for _ in res['address_components']:\n",
    "                if 'country' in _['types']:\n",
    "                    loc.update({'country': _['long_name']})\n",
    "                if 'locality' in _['types']:\n",
    "                    loc.update({'locality': _['long_name']})\n",
    "        if 'formatted_address' in res:\n",
    "            loc.update({'location': res['formatted_address']})\n",
    "        \n",
    "        try:\n",
    "            loc.update({'coordinates': res['geometry']['location']})\n",
    "        except:\n",
    "            pass\n",
    "        \n",
    "        if not loc:\n",
    "            print('locationd fields couldn\\'t be retrieved from geocoding result!')\n",
    "                               \n",
    "        return loc\n",
    "\n",
    "    \n",
    "    def impute_location(self):\n",
    "        \n",
    "        print('imputing country...', end=' ')\n",
    "              \n",
    "        t0 = time.time()\n",
    "              \n",
    "        localities = []\n",
    "        countries = []\n",
    "    \n",
    "        c_geo = 0\n",
    "              \n",
    "        in_str = lambda s1, s2: ' ' + s1 + ' ' in ' ' + s2 + ' '\n",
    "        \n",
    "        for i, row in enumerate(self.u_df.iterrows(), 1):\n",
    "                               \n",
    "            users_country = None\n",
    "              \n",
    "            if isinstance(row[1].location, str):\n",
    "              \n",
    "                loc_str = ' '.join(re.sub(r'[\\-\\_]', ' ', row[1].location).split()).lower()\n",
    "\n",
    "                _found_countries = set()\n",
    "\n",
    "                for country in self.countries:\n",
    "              \n",
    "                    if in_str(country['name'].lower(), loc_str):\n",
    "                        _found_countries.add(country['name'].lower())\n",
    "              \n",
    "                    alt_names = country.get('other_names', None)\n",
    "              \n",
    "                    if alt_names:\n",
    "                          for alt_name in alt_names:\n",
    "                              if in_str(alt_name, loc_str):\n",
    "                                  _found_countries.add(alt_name.lower())\n",
    "\n",
    "                if len(_found_countries) == 1:\n",
    "                    users_country = _found_countries.pop()\n",
    "                else:\n",
    "#                   # run geolocation\n",
    "#                   r = self._fix_location(loc_str)\n",
    "#                   c_geo += 1\n",
    "              \n",
    "#                   if 'country' in r:\n",
    "#                      users_country = r['country'].lower()\n",
    "              \n",
    "                  users_country = None\n",
    "            \n",
    "#             print(f'#{i}: location: {row[1].location} -> country: {users_country}')\n",
    "            \n",
    "            countries.append(users_country)\n",
    "                               \n",
    "        self.u_df['country'] = [c if (not c) or (c in self.KEY_COUNTRIES) else 'other' for c in countries]\n",
    "        \n",
    "        m, s = divmod(time.time() - t0, 60)\n",
    "              \n",
    "        print(f'done. elapsed time: {m:.0f}:{s:.0f}')\n",
    "              \n",
    "#         print(f'ran geolocation {c_geo} times ({100*c_geo/len(self.u_df):.1f}%)')\n",
    "        \n",
    "        return self\n",
    "    \n",
    "    def _impute_gender(self, s):\n",
    "        \n",
    "        if not isinstance(s, str):\n",
    "              return None\n",
    "              \n",
    "        # separate nicknames like TrevorJ into trevor J; or Mike23 into Mike 23\n",
    "        s = re.sub(r'([a-z]{1})([A-Z0-9]+)', r'\\1 \\2', s)\n",
    "        \n",
    "        return self.gd.gender(s)\n",
    "    \n",
    "    def impute_gender(self):\n",
    "        \n",
    "        print('imputing gender...', end=' ')\n",
    "              \n",
    "        t0 = time.time()\n",
    "        \n",
    "        avail_msk = self.u_df['gender'].str.lower().isin(self.genders)\n",
    "        \n",
    "        tot_users = len(set(self.u_df['name']))\n",
    "              \n",
    "        g_avail_bf = len(set(self.u_df[avail_msk]['name']))\n",
    "        \n",
    "        av = self.u_df[avail_msk]\n",
    "        nav = self.u_df[~avail_msk]\n",
    "        \n",
    "        nav['gender'] = nav['name'].apply(self._impute_gender)\n",
    "              \n",
    "        self.u_df = pd.concat([av, nav])\n",
    "              \n",
    "        m, s = divmod(time.time() - t0, 60)\n",
    "              \n",
    "        print(f'done. elapsed time: {m:.0f}:{s:.0f}')\n",
    "              \n",
    "        g_avail_af = len(set(self.u_df[self.u_df['gender'].str.lower().isin(self.genders)]['name']))\n",
    "              \n",
    "        print(f'availability +{100*g_avail_af/g_avail_bf - 100:.1f}%: now {g_avail_af:,} users ({100*g_avail_af/tot_users:.1f}%) was {g_avail_bf:,} ({100*g_avail_bf/tot_users:.1f}%)')\n",
    "              \n",
    "        return self\n",
    "    \n",
    "    def merge_data(self):\n",
    "        \n",
    "        self.data = self.r_df.join(self.u_df.set_index('name'), on='by_user', how='inner')\n",
    "        \n",
    "        return self\n",
    "    \n",
    "    def selector(self, req_dict):\n",
    "\n",
    "        \"\"\"\n",
    "        return a data frame obtained from the original one (df) by filtering out all rows that don't match\n",
    "        the required values provided in the dictionary req_dict which looks like, for example, \n",
    "        {'age': '13-17', 'gender': 'f',...}\n",
    "\n",
    "        what if after all the filtering all that's left is an empty data frame? then just return that empty data frame\n",
    "        \"\"\"\n",
    "\n",
    "        if self.data.empty:\n",
    "            print('dataframe you\\'re trying to select from is empty!')\n",
    "            return self\n",
    "\n",
    "        actual_cols = set(self.data.columns) | {'tourist_type'}\n",
    "        required_cols = set(req_dict)\n",
    "\n",
    "        if not (required_cols <= actual_cols):\n",
    "            cols_na = ', '.join(required_cols - actual_cols)\n",
    "            raise Exception(f'column(s) {cols_na} you\\'re asking for are not available!')\n",
    "\n",
    "        out = self.data\n",
    "\n",
    "        for col in required_cols:\n",
    "\n",
    "            if req_dict[col] != 'all':\n",
    "\n",
    "                if col != 'tourist_type':\n",
    "                    out = out[out[col].astype(str) == req_dict[col]]\n",
    "                else:\n",
    "                    out = out[out[req_dict[col]] == 'yes']\n",
    "                if out.empty:\n",
    "                    print('dataframe you\\'re trying to select from became empty!')\n",
    "                    break\n",
    "\n",
    "        return out\n",
    "              \n",
    "    def prepr_(self, review_text):\n",
    "              \n",
    "        if not review_text.strip():\n",
    "              return None\n",
    "              \n",
    "        review_ = defaultdict(list)\n",
    "              \n",
    "        review_['original'] = review_text\n",
    "        \n",
    "        doc = nlp(review_text)\n",
    "              \n",
    "        review_['ents'] = [e.text for e in doc.ents]\n",
    "        review_['labels'] = [e.label_ for e in doc.ents]\n",
    "              \n",
    "        doc = nlp(review_text.lower())\n",
    "        \n",
    "        review_['lemmatised'] = [v for v in ['$' if w.is_currency else w.lemma_ for w in doc] if v.isalpha() and (len(v) > 1)]\n",
    "\n",
    "        review_['nouns'] = [w.lemma_ for w in doc if w.pos_ == 'NOUN']\n",
    "        review_['verbs'] = [w.lemma_ for w in doc if w.pos_ == 'VERB']\n",
    "        \n",
    "        return review_\n",
    "              \n",
    "    def get_textdata(self, seg1_dict, seg2_dict, min_frq=5):\n",
    "        \n",
    "        t0 = time.time()\n",
    "              \n",
    "        print('s1=', seg1_dict)\n",
    "        print('s2=', seg2_dict)\n",
    "        \n",
    "        eligible = []\n",
    "        seg_dfs = []\n",
    "              \n",
    "        for i, s in enumerate([seg1_dict, seg2_dict], 1):\n",
    "              \n",
    "              s_df = self.selector(s)\n",
    "              \n",
    "              if s_df.empty or (len(set(s_df['by_user'])) < 50):\n",
    "                  print(f'not enough data for segment {i}')\n",
    "                  eligible.append(0)\n",
    "              else:\n",
    "                  seg_dfs.append(s_df)\n",
    "                  eligible.append(1)\n",
    "        \n",
    "        print(eligible)\n",
    "              \n",
    "        if not all(eligible):\n",
    "              return self\n",
    "        else:\n",
    "              print('both good')\n",
    "        \n",
    "        t = []\n",
    "              \n",
    "        for i, df in enumerate(seg_dfs, 1):\n",
    "              \n",
    "            t_ = df['text'].apply(lambda x: ' '.join(self.prepr_(x)['lemmatised']))\n",
    "\n",
    "            t.append(\n",
    "                pd.concat(\n",
    "                    [\n",
    "                        pd.Series(['seg' + str(i)]*len(df)),\n",
    "                        df['text'].apply(lambda x: ' '.join(self.prepr_(x)['lemmatised']))\n",
    "                    ], axis=1, ignore_index=True\n",
    "                    )\n",
    "                  ).rename(columns={0: 'segment', 1: 'text'})\n",
    "              \n",
    "        print(t[0].head(3))\n",
    "\n",
    "            \n",
    "              \n",
    "              \n",
    "#         self.text_data = pd.concat([seg1_df[['lemmatised', 'segment']], \n",
    "#                                     seg2_df[['lemmatised', 'segment']]])\n",
    "        \n",
    "#         corpus = st.CorpusFromPandas(self.text_data, \n",
    "#                                      category_col='segment', \n",
    "#                                      text_col='lemmatised', \n",
    "#                                      nlp=nlp).build()\n",
    "              \n",
    "#         self.freq_data = corpus.get_term_freq_df().rename(columns={'seg1 freq': 'seg1_frq', 'seg2 freq': 'seg2_frq'})\n",
    "#         self.freq_data['s1_score'] = corpus.get_scaled_f_scores('seg1')\n",
    "#         self.freq_data['s2_score'] = corpus.get_scaled_f_scores('seg2')\n",
    "              \n",
    "#         # impose min frequency\n",
    "#         self.freq_data = self.freq_data[(self.freq_data['seg1_frq'] >= min_frq) & (self.freq_data['seg2_frq'] >= min_frq)]\n",
    "#         print(f'{len(self.freq_data):,} words occur at least {min_frq} times')\n",
    "              \n",
    "#         sc = np.vectorize(lambda s1, s2: 2*(-0.5+(s1 if s1>s2 else 1-s2 if s2>s1 else 0)))\n",
    "              \n",
    "#         self.freq_data['nfsc'] = sc(self.freq_data['s1_score'], self.freq_data['s2_score'])\n",
    "              \n",
    "#         # scale frequencies\n",
    "#         seg1_frq_min, seg1_frq_max = self.freq_data['seg1_frq'].min(), self.freq_data['seg1_frq'].max()\n",
    "#         seg2_frq_min, seg2_frq_max = self.freq_data['seg2_frq'].min(), self.freq_data['seg2_frq'].max()\n",
    "              \n",
    "#         self.freq_data['seg1_frq_sc'] = (self.freq_data['seg1_frq'] - seg1_frq_min)/(seg1_frq_max - seg1_frq_min)\n",
    "#         self.freq_data['seg2_frq_sc'] = (self.freq_data['seg2_frq'] - seg2_frq_min)/(seg2_frq_max - seg2_frq_min)\n",
    "              \n",
    "#         # filename to save as .csv\n",
    "#         fn_ = ['tdf']\n",
    "        \n",
    "#         for i, sdik in enumerate([seg1_dict, seg2_dict], 1):\n",
    "              \n",
    "#               fn_.append('-seg' + str(i) + '-')  # so now ['textdf', '-seg1-']\n",
    "            \n",
    "#               for attr in 'age gender tourist_type country'.split():\n",
    "                    \n",
    "#                    fn_.append(attr[0]) # so now ['textdf', 'seg1', 'a']\n",
    "#                    # self.attribute_encodings_rev is like 'age': {'13-17': '1'},..\n",
    "#                    fn_.append(self.attribute_encodings_rev[attr].get(sdik.get(attr, 'all'), 'all'))  # ['textdf', '-seg1-', 'a', '2']\n",
    "        \n",
    "#         fn = 'data/' + ''.join(fn_) + '.csv'\n",
    "\n",
    "#         self.freq_data.to_csv(fn)\n",
    "              \n",
    "#         m, s = divmod(time.time() - t0, 60)\n",
    "              \n",
    "#         print(f'done. savet to {fn}. elapsed time: {m:.0f}:{s:.0f}')\n",
    "        \n",
    "        return self\n",
    "    \n",
    "    def generate_text_data(self):\n",
    "        \n",
    "        s1s = [{'age': ag, 'gender': g} for g in self.genders for ag in self.age_groups]\n",
    "        s2s = [{'age': ag, 'gender': g} for g in self.genders for ag in self.age_groups]\n",
    "        \n",
    "        for s1 in s1s:\n",
    "              for s2 in s2s:\n",
    "                  self.get_textdata(s1, s2)\n",
    "              \n",
    "        return self\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DATA\n",
      "----\n",
      "22,264 reviews written between 01/2013 and 03/2019 for 67 attractions by 13,813 users\n",
      "user attribute availability:\n",
      "tags: 3,148 (22.8)% ~ age: 4,851 (35.1)% ~ gender: 6,261 (45.3)%\n",
      "s1= {'age': 'all', 'gender': 'all'}\n",
      "s2= {'age': 'all', 'gender': 'all'}\n",
      "[1, 1]\n",
      "both good\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    \n",
    "    t = T(review_file='mlb/revs.json',\n",
    "         users_file='mlb/usrs.json',\n",
    "         attract_file='mlb/attractions_melbourne.json').drop_unusable().review_attributes() \\\n",
    "                .stats().tags_to_cols().merge_data().generate_text_data()\n",
    "#                 .impute_location() \\\n",
    "#                 .impute_gender() \\\n",
    "#                 .merge_data() \\\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['all',\n",
       " '60+ traveller',\n",
       " 'art and architecture lover',\n",
       " 'backpacker',\n",
       " 'beach goer',\n",
       " 'eco-tourist',\n",
       " 'family holiday maker',\n",
       " 'foodie',\n",
       " 'history buff',\n",
       " 'like a local',\n",
       " 'luxury traveller',\n",
       " 'nature lover',\n",
       " 'nightlife seeker',\n",
       " 'peace and quiet seeker',\n",
       " 'shopping fanatic',\n",
       " 'thrifty traveller',\n",
       " 'thrill seeker',\n",
       " 'trendsetter',\n",
       " 'urban explorer',\n",
       " 'vegetarian']"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.tourist_types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'T' object has no attribute 'freq_data'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-44-2ef05b4b8d15>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mTAKE\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m300\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfreq_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msort_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'seg1_frq'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mascending\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0ms1_tb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms1_tu\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'seg1_frq_sc'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mquantile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mq\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0.20\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.95\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'T' object has no attribute 'freq_data'"
     ]
    }
   ],
   "source": [
    "TAKE = 300\n",
    "\n",
    "df = t.freq_data.sort_values('seg1_frq', ascending=False)\n",
    "\n",
    "s1_tb, s1_tu = df['seg1_frq_sc'].quantile(q=[0.20, 0.95])\n",
    "s2_tb, s2_tu = df['seg2_frq_sc'].quantile(q=[0.20, 0.95])\n",
    "\n",
    "df = df[((df['seg1_frq_sc'] < s1_tu) & (df['seg1_frq_sc'] > s1_tb)) & \n",
    "        ((df['seg2_frq_sc'] < s2_tu) & (df['seg2_frq_sc'] > s2_tb))].iloc[:TAKE]\n",
    "\n",
    "colorscale=[[0, 'orange'], [1, '#2C72EC']]\n",
    "\n",
    "layout= go.Layout(\n",
    "#     title= 'Characteristic Words',\n",
    "    hovermode= 'closest',\n",
    "    xaxis= dict(\n",
    "        title='Frequency in Reviews by Seg 1',\n",
    "        ticklen= 5,\n",
    "        tickmode='array',\n",
    "        tickvals=np.linspace(df['seg1_frq_sc'].min(), df['seg1_frq_sc'].max(), num=5),\n",
    "        ticktext=['low', '', 'medium', '', 'high'],\n",
    "        zeroline= False,\n",
    "        gridwidth= 2,\n",
    "        showticklabels=True,\n",
    "        showgrid=True,\n",
    "    ),\n",
    "    yaxis=dict(\n",
    "        ticklen= 5,\n",
    "        tickmode='array',\n",
    "        tickvals=np.linspace(df['seg2_frq_sc'].min(), df['seg2_frq_sc'].max(), num=5),\n",
    "        ticktext=['low', '', 'medium', '', 'high'],\n",
    "        gridwidth= 2,\n",
    "        zeroline=False,\n",
    "        showticklabels=True,\n",
    "        showgrid=True,\n",
    "        tickangle=-90,\n",
    "        title='Frequency in Reviews by Seg 2',\n",
    "    ),\n",
    "    legend=dict(orientation=\"h\", x=0.5, y=1.1, yanchor=\"top\"),\n",
    "    annotations=[dict(text='Stronger Association with ', x=0.41, y=1.08, \n",
    "            showarrow=False, \n",
    "            xref=\"paper\",\n",
    "            yref=\"paper\",\n",
    "            yanchor=\"top\"\n",
    "                     )],\n",
    "    showlegend= True\n",
    ")\n",
    "\n",
    "df_neg = df[df['nfsc']<0]\n",
    "df_pos = df[df['nfsc']>0]\n",
    "\n",
    "trace0 = go.Scatter(\n",
    "    name='Seg1',\n",
    "    x = df_neg['seg1_frq_sc'],\n",
    "    y = df_neg['seg2_frq_sc'],\n",
    "    mode = 'markers',\n",
    "    hoverinfo='text', \n",
    "    marker=dict(\n",
    "                color='orange', \n",
    "                size=10,\n",
    "                opacity=0.85,\n",
    "               ),\n",
    "    text= df_neg.index)\n",
    "\n",
    "trace1 = go.Scatter(\n",
    "    name='Seg2',\n",
    "    x = df_pos['seg1_frq_sc'],\n",
    "    y = df_pos['seg2_frq_sc'],\n",
    "    mode = 'markers',\n",
    "    hoverinfo='text', \n",
    "    marker=dict(\n",
    "                color='#2C72EC', \n",
    "                size=10, \n",
    "                opacity=0.85,\n",
    "               ),\n",
    "    text= df_pos.index)\n",
    "\n",
    "\n",
    "fig= go.Figure(data=[trace0, trace1], layout=layout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iplot(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 22264 entries, 0 to 22262\n",
      "Data columns (total 32 columns):\n",
      "attr_id                       22264 non-null object\n",
      "by_user                       22261 non-null object\n",
      "date_of_experience            22160 non-null object\n",
      "date_of_writing               22264 non-null object\n",
      "id                            22264 non-null object\n",
      "rating                        22264 non-null float64\n",
      "text                          22263 non-null object\n",
      "title                         22264 non-null object\n",
      "age                           8442 non-null object\n",
      "gender                        16569 non-null object\n",
      "location                      19374 non-null object\n",
      "real_name                     21565 non-null object\n",
      "like a local                  6560 non-null object\n",
      "family holiday maker          6560 non-null object\n",
      "thrill seeker                 6560 non-null object\n",
      "shopping fanatic              6560 non-null object\n",
      "nature lover                  6560 non-null object\n",
      "art and architecture lover    6560 non-null object\n",
      "vegetarian                    6560 non-null object\n",
      "backpacker                    6560 non-null object\n",
      "history buff                  6560 non-null object\n",
      "peace and quiet seeker        6560 non-null object\n",
      "nightlife seeker              6560 non-null object\n",
      "trendsetter                   6560 non-null object\n",
      "beach goer                    6560 non-null object\n",
      "60+ traveller                 6560 non-null object\n",
      "thrifty traveller             6560 non-null object\n",
      "luxury traveller              6560 non-null object\n",
      "foodie                        6560 non-null object\n",
      "urban explorer                6560 non-null object\n",
      "eco-tourist                   6560 non-null object\n",
      "country                       14784 non-null object\n",
      "dtypes: float64(1), object(31)\n",
      "memory usage: 5.6+ MB\n"
     ]
    }
   ],
   "source": [
    "t.data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = st.CorpusFromPandas(t.data, \n",
    "...                              category_col='gender', \n",
    "...                              text_col='text',\n",
    "...                              nlp=nlp).build()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/scattertext/frequencyreaders/DefaultBackgroundFrequencies.py:30: FutureWarning:\n",
      "\n",
      "read_table is deprecated, use read_csv instead, passing sep='\\t'.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "term_freq_df = corpus.get_term_freq_df()\n",
    "\n",
    "html = st.produce_scattertext_explorer(corpus, category='m', category_name='m', not_category_name='f', width_in_pixels=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7184955"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "open(\"melb.html\", 'wb').write(html.encode('utf-8'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
