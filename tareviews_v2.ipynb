{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.common.action_chains import ActionChains\n",
    "\n",
    "from collections import defaultdict\n",
    "import re\n",
    "import json\n",
    "import os\n",
    "import time\n",
    "import arrow\n",
    "import random\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import subprocess\n",
    "import zipfile\n",
    "\n",
    "from attraction import Attraction\n",
    "from review import Review\n",
    "from user import User\n",
    "\n",
    "import scattertext as st\n",
    "import spacy\n",
    "\n",
    "from unidecode import unidecode\n",
    "\n",
    "nlp = spacy.load('en')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    " class CountryDetector:\n",
    "        \n",
    "    def __init__(self, data_dir='data'):\n",
    "        \n",
    "        self.DATA_DIR = data_dir\n",
    "        \n",
    "        try:\n",
    "            self.COUNTRIES = json.load(open(os.path.join(self.DATA_DIR, 'countries.json')))\n",
    "        except:\n",
    "            raise Exception(f'error! no counry file in {data_dir}!')\n",
    "            \n",
    "        try:\n",
    "            self.COUNTRY_ABBRS = json.load(open(os.path.join(self.DATA_DIR, 'country_abbrs.json')))\n",
    "        except:\n",
    "            raise Exception(f'error! no counry abbreviation file in {data_dir}!')\n",
    "            \n",
    "        try:\n",
    "            self.STATES = json.load(open(os.path.join(self.DATA_DIR, 'states.json')))\n",
    "        except:\n",
    "            raise Exception(f'error! no state file in {data_dir}!')\n",
    "            \n",
    "        try:\n",
    "            self.STATE_ABBRS = json.load(open(os.path.join(self.DATA_DIR, 'state_abbrs.json')))\n",
    "        except:\n",
    "            raise Exception(f'error! no state abbreviation file in {data_dir}!')\n",
    "            \n",
    "        try:\n",
    "            self.CITIES = json.load(open(os.path.join(self.DATA_DIR, 'cities.json')))\n",
    "        except:\n",
    "            raise Exception(f'error! no city file in {data_dir}!')\n",
    "            \n",
    "    def _normalize(self, st: str) -> str:\n",
    "        \n",
    "        \"\"\"\n",
    "        return normalized string st\n",
    "        \"\"\"\n",
    "        \n",
    "        return re.sub(r'\\s+', ' ', re.sub(r'[,\\-\\'\\\"\\_\\!\\@\\?]', '', unidecode(st)).lower().strip())\n",
    "            \n",
    "    def get_country(self, st) -> str:\n",
    "        \n",
    "        \"\"\"\n",
    "        figure out a country from a string st; return None if no country found or a atring with all candidate\n",
    "        country names\n",
    "        \"\"\"\n",
    "        \n",
    "        locations = [_.lower().strip() for _ in st.split(',') if _.strip()]\n",
    "        \n",
    "        if not locations:\n",
    "            return None    \n",
    "        \n",
    "        # first try to find a country\n",
    "        for l in locations:\n",
    "            first_letter = l[0]\n",
    "            found_countries = {self._normalize(l)} & {self._normalize(c) for c in self.COUNTRIES[first_letter]}\n",
    "            if found_countries:\n",
    "                return found_countries.pop()\n",
    "            \n",
    "        # since we are here, no country has been found; try to find country by abbreviation\n",
    "        for l in locations:\n",
    "            found_abbrs = {self._normalize(l)} & set(self.COUNTRY_ABBRS)\n",
    "            if found_abbrs:\n",
    "                return self.COUNTRY_ABBRS[found_abbrs.pop()]\n",
    "            \n",
    "        # no country abbreviation has been found and we are looking for states\n",
    "        for l in locations:\n",
    "            found_states = {self._normalize(l)} & set(self.STATES)\n",
    "            if found_states:\n",
    "                return self.STATES[found_states.pop()]\n",
    "            \n",
    "        # time to find state abbreviations\n",
    "        for l in locations:\n",
    "            found_states = {self._normalize(l)} & set(self.STATE_ABBRS)\n",
    "            if found_states:\n",
    "                return self.STATE_ABBRS[found_states.pop()]\n",
    "            \n",
    "        # no states; now look for cities\n",
    "        for l in locations:\n",
    "            first_letter = l[0]\n",
    "            for c in self.CITIES[first_letter]:\n",
    "                if self._normalize(c) == self._normalize(l):\n",
    "                    found_countries = set(self.CITIES[first_letter][c])\n",
    "                    return ' | '.join(found_countries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    " class Trip(CountryDetector):\n",
    "    \n",
    "    def __init__(self, filter):\n",
    "        \n",
    "        options = webdriver.ChromeOptions()\n",
    "        options.add_argument('--ignore-certificate-errors')\n",
    "        options.add_argument('--ignore-ssl-errors')\n",
    "        options.add_argument('--incognito')\n",
    "        options.add_argument('--start-maximized')\n",
    "        prefs = {\"profile.default_content_setting_values.notifications\" : 2}\n",
    "        options.add_experimental_option(\"prefs\",prefs)\n",
    "\n",
    "#         options.add_argument('--headless')\n",
    "        \n",
    "        super().__init__()\n",
    "        \n",
    "        self.driver = webdriver.Chrome('webdriver/chromedriver', options=options)\n",
    "        \n",
    "        self.FILTREVS = defaultdict()\n",
    "        self.REVIEWS = defaultdict()\n",
    "        \n",
    "        # counter to see how many annoying things get killed\n",
    "        self.KILLED = defaultdict(int)\n",
    "        \n",
    "        self.FILTERS = filter\n",
    "        \n",
    "        print(f'\\n[FILTER]: {\" | \".join([k + \": \" + str(v) for k, v in self.FILTERS.items() if v])}\\n')\n",
    "        \n",
    "        self.DATA_DIR = 'data'\n",
    "        self.COLLECT_DIR = 'data-collected'\n",
    "        \n",
    "        if not os.path.exists(self.DATA_DIR):\n",
    "            os.mkdir(self.DATA_DIR)\n",
    "            \n",
    "        if not os.path.exists(self.COLLECT_DIR):\n",
    "            os.mkdir(self.COLLECT_DIR)\n",
    "        \n",
    "        self.LOCATION_IDS = json.load(open(os.path.join(self.DATA_DIR, 'tradvisor_location_ids.json')))\n",
    "        \n",
    "    def attr_id_from_url(self, url_):\n",
    "        \n",
    "        \"\"\"\n",
    "        extract attraction ID from attraction URL\n",
    "        \"\"\"\n",
    "        \n",
    "        try:\n",
    "            id_ = re.search(r'(?<=-)d\\d+(?=-)', url_).group(0)\n",
    "        except:\n",
    "            id_ = None\n",
    "            \n",
    "        return id_\n",
    "            \n",
    "    def do_click(self, e, max_=3) -> bool:\n",
    "        \n",
    "        \"\"\"\n",
    "        try to click on element e and return True if it worked or False otherwise\n",
    "        \"\"\"\n",
    "        \n",
    "        # assume not click\n",
    "        _clicked = False\n",
    "        _c = 0\n",
    "\n",
    "        while (not _clicked) and (_c < max_):\n",
    "\n",
    "            try:\n",
    "                e.click()\n",
    "                _clicked = True\n",
    "            except:\n",
    "                try:\n",
    "                    self.driver.find_element_by_css_selector('span.ui_overlay>div.ui_close_x').click()\n",
    "                    self.KILLED['overlay'] += 1\n",
    "                except:\n",
    "                    # try to catch and close all sliders\n",
    "                    els = list(self.driver.find_elements_by_css_selector('div[class^=\"QSISlider\"]>div'))\n",
    "                    for i, d in enumerate(els):\n",
    "                        if d.text.strip().lower() == 'Not right now, thanks.'.strip().lower():\n",
    "                            try:\n",
    "                                els[i-1].click()\n",
    "                                self.KILLED['slide'] += 1\n",
    "                                break\n",
    "                            except:\n",
    "                                continue\n",
    "                    for _ in self.driver.find_elements_by_css_selector('div.sbx_close[onclick]'):\n",
    "                        try:\n",
    "                            _.click()\n",
    "                            self.KILLED['infobar'] += 1\n",
    "                        except:\n",
    "                            pass        \n",
    "            _c += 1\n",
    "\n",
    "        return _clicked\n",
    "    \n",
    "    def process_paginator(self, pg, off=30, pref='oa'):\n",
    "        \n",
    "        p_numbers = [int(s.text.strip()) for s in pg.find_elements_by_css_selector('div') if s.text.strip().isdigit()]\n",
    "        \n",
    "        if p_numbers:\n",
    "            total_pages = p_numbers[-1]\n",
    "        else:\n",
    "            raise Exception('no pages in paginator!')\n",
    "        \n",
    "        current_page_url = self.driver.current_url\n",
    "        last_page_url = self.driver.current_url\n",
    "        \n",
    "        page_urls = [current_page_url]\n",
    "        \n",
    "        for _ in pg.find_elements_by_css_selector('div>a'):\n",
    "            if _.text.isdigit():\n",
    "                last_page_url = _.get_attribute('href')\n",
    "                \n",
    "        if total_pages > 1:\n",
    "            for i in range(1, total_pages):\n",
    "                # starts from page 2 (page 1 has no -oa[number]- part)\n",
    "                page_urls.append(re.sub('Activities-', 'Activities-' + pref + str(off*i) + '-', current_page_url))\n",
    "                \n",
    "        return total_pages, page_urls\n",
    "        \n",
    "    def get_attraction_pages(self, loc):\n",
    "        \n",
    "        \"\"\"\n",
    "        go to the home page for location loc and collect all attractions; if loc is a state, collect attractions\n",
    "        for every location in that state; \n",
    "        note that we only collect attraction ID and URL this time.\n",
    "        \n",
    "        \"\"\"\n",
    "        \n",
    "        self.MAIN_LOCATION = loc\n",
    "        \n",
    "        # home_urls will be a list of tuples like \n",
    "        # [('tasmania', 'hobart', 'https://www.tripadvisor.com.au/Home-g255097'), \n",
    "        #  ('tasmania', 'launceston', 'https://www.tripadvisor.com.au/Home-g255344')...\n",
    "        \n",
    "        home_urls = []\n",
    "        \n",
    "        self.collected_attractions = defaultdict(lambda: defaultdict(lambda: defaultdict()))\n",
    "        \n",
    "        \"\"\"\n",
    "        {'tasmania': {'hobart': {attr_id: {url: 'https:/www...'}}}\n",
    "        \"\"\"\n",
    "        \n",
    "        # if loc is state\n",
    "        if self.MAIN_LOCATION in self.LOCATION_IDS:\n",
    "            for city in self.LOCATION_IDS[loc]:\n",
    "                home_urls.append((self.MAIN_LOCATION, city, f'https://www.tripadvisor.com.au/Home-{self.LOCATION_IDS[loc][city]}'))\n",
    "        else:\n",
    "            for state_ in self.LOCATION_IDS:\n",
    "                if self.MAIN_LOCATION in self.LOCATION_IDS[state_]:\n",
    "                    home_urls.append((state_, self.MAIN_LOCATION, f'https://www.tripadvisor.com.au/Home-{self.LOCATION_IDS[state_][loc]}'))\n",
    "                    \n",
    "        if not home_urls:\n",
    "            print(f'no attractions to pick for {loc.upper()}!')\n",
    "            return self\n",
    "        \n",
    "        for state_, city_, homeurl in home_urls:\n",
    "            \n",
    "            print(f'collecting attractions for {city_.upper()}, {state_.upper()}...')\n",
    "            \n",
    "            self.driver.get(homeurl)\n",
    "            \n",
    "            # ---- find and click the Things to Do icon; assume it MUST be there\n",
    "            \n",
    "            thingstodo_clicked = False\n",
    "            \n",
    "            while not thingstodo_clicked:\n",
    "                \n",
    "                try:\n",
    "                    things_to_do_icon = WebDriverWait(self.driver, 10) \\\n",
    "                                .until(EC.presence_of_element_located((By.CSS_SELECTOR, 'span.ui_icon.attractions + span')))\n",
    "                except:\n",
    "                    raise Exception('failed to find Things to do icon!')\n",
    "                \n",
    "                if things_to_do_icon.text.strip().lower() != 'Things to do'.strip().lower():\n",
    "                    continue\n",
    "                    \n",
    "                res = self.do_click(things_to_do_icon)\n",
    "                    \n",
    "                if not res:\n",
    "                    print('failed to click Things to do icon! retrying..')\n",
    "                else:\n",
    "                    thingstodo_clicked = True\n",
    "                \n",
    "            # ------- ok, so clicked the icon; now the question is whether there are many 'top' things to \n",
    "            # do or just a few; the latter means no need to look for the See More button\n",
    "            \n",
    "            moveon = False\n",
    "            few_attractions = False\n",
    "            \n",
    "            # try to click See More first\n",
    "            \n",
    "            while 1:\n",
    "                \n",
    "                try:\n",
    "                    c_mo = WebDriverWait(self.driver, 10) \\\n",
    "                            .until(EC.element_to_be_clickable((By.CSS_SELECTOR, \n",
    "                                    'div[class|=\"attractions-attraction-overview-main-TopPOIs__see_more\"]')))\n",
    "                except:\n",
    "                    # if there's no See More it's just 1 page with attractions\n",
    "                    page_urls = [self.driver.current_url]\n",
    "                    few_attractions = True\n",
    "                    break\n",
    "                \n",
    "                seeless = False\n",
    "                \n",
    "                while not seeless:\n",
    "                    \n",
    "                    res = self.do_click(c_mo)\n",
    "                    \n",
    "                    # didn't click..\n",
    "                    if not res:\n",
    "\n",
    "                        try:\n",
    "                            # there is this See More button but still folded, so apparently we didn't click properly\n",
    "                            self.driver.find_element_by_css_selector('span.ui_icon.single-chevron-down')\n",
    "                        except:\n",
    "                            seeless = True\n",
    "                    # look like clicked See More..\n",
    "                    else:\n",
    "                        try:\n",
    "                            WebDriverWait(self.driver, 10) \\\n",
    "                                .until(EC.presence_of_element_located((By.CSS_SELECTOR, \n",
    "                                    'span.ui_icon.single-chevron-up')))\n",
    "\n",
    "                            seeless = True\n",
    "                        except:\n",
    "                            print('no See Less, need to click See more again')\n",
    "                break                \n",
    "            \n",
    "            # paginator only available if there are many attractions; however, there may be no paginator if See More\n",
    "            # was clicked but there are still too few attractions\n",
    "            \n",
    "            if not few_attractions:\n",
    "                \n",
    "                try:\n",
    "                    pg = WebDriverWait(self.driver, 10) \\\n",
    "                            .until(EC.presence_of_element_located((By.CSS_SELECTOR, \n",
    "                                    'div[class|=\"attractions-attraction-overview-main-Pagination__container\"]')))\n",
    "                except:\n",
    "                    pg = None\n",
    "                \n",
    "                if pg:\n",
    "                    total_pages, page_urls = self.process_paginator(pg) \n",
    "                else:\n",
    "                    page_urls = [self.driver.current_url]\n",
    "\n",
    "            print('visiting attraction pages..')\n",
    "\n",
    "            for i, attr_page_url in enumerate(page_urls, 1):\n",
    "                \n",
    "                print(f'page {i}/{len(page_urls)}..', end='')\n",
    "\n",
    "                if attr_page_url != self.driver.current_url:\n",
    "                    self.driver.get(attr_page_url)\n",
    "                \n",
    "                if i == 1:\n",
    "                    \n",
    "                    attr_topick_css = 'div[class|=\"attractions-attraction-overview-pois-PoiGrid__wrapper\"]' + \\\n",
    "                                      '>li[class^=\"attractions-attraction-overview-pois-PoiCard__item\"]' + \\\n",
    "                                      '>div[class|=\"attractions-attraction-overview-pois-PoiCard__card_info\"]'\n",
    "                            \n",
    "                    attr_topick = len(self.driver.find_elements_by_css_selector(attr_topick_css))\n",
    "                    \n",
    "                    while attr_topick:\n",
    "                        \n",
    "                        for attr_card in self.driver.find_elements_by_css_selector(attr_topick_css):\n",
    "\n",
    "                            try:\n",
    "                                url_ = attr_card.find_element_by_css_selector('div>a[class|=\"attractions-attraction-overview-pois-PoiInfo__name\"]') \\\n",
    "                                                        .get_attribute('href')\n",
    "                            except:\n",
    "                                print('didn\\'t get attraction url! moving on to next attraction card..')\n",
    "                                continue\n",
    "                            \n",
    "                            id_ = self.attr_id_from_url(url_)\n",
    "                            \n",
    "                            if not id_:\n",
    "                                print('failed to extract attraction id!')\n",
    "                                continue\n",
    "                            \n",
    "                            # here we add attraction URL to the dictionary\n",
    "                            try:\n",
    "                                self.collected_attractions[state_][city_][id_] = {'url': url_}\n",
    "                                attr_topick -= 1\n",
    "                            except:\n",
    "                                pass\n",
    "\n",
    "                elif i > 1:\n",
    "                    \n",
    "                    attr_topick_css = 'div.attraction_list>div' + \\\n",
    "                                      '>div>div.listing>div.listing_details>div.listing_info'\n",
    "                        \n",
    "                    attr_topick = len(self.driver.find_elements_by_css_selector(attr_topick_css))\n",
    "                    \n",
    "                    while attr_topick:\n",
    "                        \n",
    "                        for attr_card in self.driver.find_elements_by_css_selector(attr_topick_css):\n",
    "\n",
    "                            try:\n",
    "                                url_ = attr_card.find_element_by_css_selector('div.tracking_attraction_title.listing_title>a').get_attribute('href')\n",
    "                            except:\n",
    "                                print('didn\\'t get attraction url! moving on to next attraction card..')\n",
    "                                continue\n",
    "                                \n",
    "                            try:\n",
    "                                id_ = re.search(r'(?<=-)d\\d+(?=-)', url_).group(0)\n",
    "                            except:\n",
    "                                print('failed to extract attraction id!')\n",
    "                                continue\n",
    "                            \n",
    "                            try:\n",
    "                                self.collected_attractions[state_][city_][id_] = {'url': url_}\n",
    "                                attr_topick -= 1\n",
    "                            except:\n",
    "                                pass\n",
    "            \n",
    "                print('ok')\n",
    "    \n",
    "        return self\n",
    "\n",
    "    def select_filters(self) -> int:\n",
    "        \n",
    "        \"\"\"\n",
    "        apply filter on the attraction page and return the number of reviews available\n",
    "        after the filter has been applied\n",
    "        \"\"\"\n",
    "        \n",
    "        d = {'traveller_rating': {'data-name': 'ta_rating',\n",
    "                                  'input-values': {'Excellent': '5',\n",
    "                                                   'Very good': '4',\n",
    "                                                   'Average': '3',\n",
    "                                                   'Poor': '2',\n",
    "                                                   'Terrible': '1'},\n",
    "                                 'pick': self.FILTERS['traveller_rating']},\n",
    "            'traveller_type': {'data-name': 'traveler_filter',\n",
    "                               'input-values': {'Families': '3',\n",
    "                                                'Couples': '2',\n",
    "                                                'Solo': '5',\n",
    "                                                'Business': '1',\n",
    "                                                'Friends': '4'},\n",
    "                              'pick': self.FILTERS['traveller_type']},\n",
    "            'time_of_year': {'data-name': 'season',\n",
    "                             'input-values': {'Mar-May': '1',\n",
    "                                              'Jun-Aug': '2',\n",
    "                                              'Sep-Nov': '3',\n",
    "                                              'Dec-Feb': '4'},\n",
    "                            'pick': self.FILTERS['time_of_year']},\n",
    "            'language': {'data-name': 'language',\n",
    "                         'input-values': {'English': 'en',\n",
    "                                          'Japanese': 'ja'},\n",
    "                         'pick': self.FILTERS['language']}}\n",
    "\n",
    "        def is_selected(css_selector_st):\n",
    "\n",
    "            try:\n",
    "                WebDriverWait(self.driver, 5) \\\n",
    "                            .until(EC.presence_of_element_located((By.CSS_SELECTOR, \n",
    "                                                                   css_selector_st + '>input[checked=\"checked\"]')))\n",
    "                return True\n",
    "\n",
    "            except:\n",
    "                return False\n",
    "\n",
    "        def _click(css_selector_st, max_attempts=3):\n",
    "\n",
    "            times_tried = 0\n",
    "\n",
    "            flag_before = is_selected(css_selector_st)\n",
    "            flag_after = flag_before\n",
    "\n",
    "            while (times_tried <= max_attempts) and (flag_after == flag_before):\n",
    "\n",
    "                times_tried += 1   \n",
    "\n",
    "                try:\n",
    "                    e = WebDriverWait(self.driver, 20) \\\n",
    "                            .until(EC.element_to_be_clickable((By.CSS_SELECTOR, css_selector_st)))\n",
    "                except:\n",
    "                    e = None\n",
    "                    print(f'failed to find {css_selector_st}!')\n",
    "                \n",
    "                if e:\n",
    "                    res = self.do_click(e)\n",
    "\n",
    "                flag_after = is_selected(css_selector_st)    \n",
    "\n",
    "            return (flag_after != flag_before)\n",
    "\n",
    "        for filt in d:\n",
    "\n",
    "            value = d[filt]['pick']\n",
    "            \n",
    "            # note that even if value is None, attempt to uncheck everything that might be checked\n",
    "            to_uncheck = [other_value for other_value in d[filt]['input-values'] if other_value != value]\n",
    "\n",
    "            if to_uncheck:\n",
    "\n",
    "                for other_value in to_uncheck:\n",
    "\n",
    "                    tr_pick = d[filt]['input-values'][other_value]\n",
    "                    dname = d[filt]['data-name']\n",
    "                    st = f'div.choices[data-name=\"{dname}\"]>div[data-value=\"{tr_pick}\"]'\n",
    "\n",
    "                    if is_selected(st):\n",
    "                        res = _click(st)\n",
    "\n",
    "            if value:\n",
    "\n",
    "                tr_pick = d[filt]['input-values'][value]\n",
    "                dname = d[filt]['data-name']\n",
    "                st = f'div.choices[data-name=\"{dname}\"]>div[data-value=\"{tr_pick}\"]'\n",
    "\n",
    "                if is_selected(st):\n",
    "                    continue\n",
    "                else:\n",
    "                    _selected =  _click(st)\n",
    "\n",
    "        try:\n",
    "            lang_code = d['language']['input-values'][d['language']['pick']] \n",
    "            css_count = f'div.choices[data-name=\"language\"]>div[data-value=\"{lang_code}\"]>label.label>span.count'\n",
    "            c_txt = WebDriverWait(self.driver, 6) \\\n",
    "                            .until(EC.presence_of_element_located((By.CSS_SELECTOR, css_count))).text.strip()\n",
    "            c = int(re.sub(r'[(,)]','',c_txt))\n",
    "        except:\n",
    "            # if no review count it's because there are not reviews left after filtering\n",
    "            return 0\n",
    "            \n",
    "        return int(c)\n",
    "    \n",
    "    def process_user_profile(self, user_profile_url, get_info=True, get_reviews=True):\n",
    "        \n",
    "        self.driver.get(user_profile_url)\n",
    "        \n",
    "        user_info = defaultdict()\n",
    "        \n",
    "        if get_info:\n",
    "            \n",
    "            _st = 'social-member-common-MemberName'\n",
    "\n",
    "            try:\n",
    "                user_info['display_name'] = self.driver.find_element_by_css_selector(f'span[class^=\"{_st}__display_name\"]').text.strip()\n",
    "            except:\n",
    "                print('found no display name!')\n",
    "\n",
    "            try:\n",
    "                user_info['user_name'] = self.driver.find_element_by_css_selector(f'span[class^=\"{_st}__user_name\"]').text.strip()\n",
    "            except:\n",
    "                print('found no user name!')\n",
    "\n",
    "            _st = 'social-member-MemberStats__stat_item'\n",
    "\n",
    "            try:\n",
    "                for _ in self.driver.find_elements_by_css_selector(f'div[class^=\"{_st}\"]'):\n",
    "\n",
    "                    item_title = _.find_element_by_css_selector(f'span[class^=\"{_st}_title\"]').text\n",
    "\n",
    "                    item_count_a = _.find_element_by_css_selector(f'span[class^=\"{_st}_count\"]>a')\n",
    "                    item_count = int(item_count_a.text.replace(',',''))\n",
    "\n",
    "                    if item_title.strip().lower() == 'contributions':\n",
    "                        \n",
    "                        item_count_a.click()\n",
    "                        \n",
    "                        time.sleep(2)\n",
    "                        \n",
    "                        popup = WebDriverWait(self.driver, 10) \\\n",
    "                                .until(EC.visibility_of_element_located((By.CSS_SELECTOR, \n",
    "                                                                         'div#c_contributions')))\n",
    "                        \n",
    "                        for _a in self.driver.find_elements_by_css_selector('li>a'):\n",
    "\n",
    "                            try:\n",
    "                                _href = _a.get_attribute('href')\n",
    "                                print(_href)\n",
    "                                if 'reviews' in _href:\n",
    "                                    user_info['reviews'] = int([w for w in _a.text.replace(',','').split() if w.isdigit()][0])\n",
    "                                    break\n",
    "                            except:\n",
    "                                continue\n",
    "            except:\n",
    "                print('failed to collect reviewer stats!')\n",
    "\n",
    "            try:\n",
    "                user_info['location'] = self.driver.find_element_by_css_selector('span[class^=\"social-member-common-MemberHometown__member_info\"]').text\n",
    "            except:\n",
    "                print('failed to get reviewer location!')\n",
    "\n",
    "            try:\n",
    "                user_info['info'] = self.driver.find_element_by_css_selector('div[class^=\"social-member-MemberBio__member_info\"]').text\n",
    "            except:\n",
    "                print('failed to get reviewer info!')\n",
    "        \n",
    "        print(user_info)\n",
    "                \n",
    "        if get_reviews and user_info.get('reviews', None):\n",
    "            \n",
    "            print(f'collecting {user_info[\"reviews\"]:,} reviews by {user_info[\"user_name\"]}...')\n",
    "            \n",
    "            self.driver.get(user_profile_url + '?tab=reviews')\n",
    "            \n",
    "            while 1:\n",
    "                \n",
    "                \n",
    "                try:\n",
    "                \n",
    "                    bt = WebDriverWait(self.driver, 10) \\\n",
    "                                .until(EC.presence_of_element_located((By.CSS_SELECTOR, \n",
    "                                                                         'span.single-chevron-down')))\n",
    "                    print('found See More')\n",
    "                    time.sleep(3)\n",
    "                except:\n",
    "                    bt = None\n",
    "                    print('no See More')\n",
    "                    break\n",
    "                \n",
    "                if bt:\n",
    "                    print('trying to click..')\n",
    "                    if self.do_click(bt):\n",
    "                        time.sleep(3)\n",
    "                        break\n",
    "                \n",
    "            # scroll down to see all reviews\n",
    "            height = self.driver.execute_script(\"return document.body.scrollHeight\")\n",
    "            avail_reviews = len(self.driver.find_elements_by_css_selector('div[class^=\"social-sections-CardSection__card_section\"]'))\n",
    "            review_urls = set()\n",
    "            \n",
    "            while len(review_urls) < user_info['reviews']:\n",
    "                    \n",
    "#                 self.driver.execute_script('window.scrollTo(0, document.body.scrollHeight);')\n",
    "                self.driver.execute_script('window.scrollBy(0, 50)')\n",
    "                    \n",
    "                time.sleep(3)\n",
    "                \n",
    "                for _ in self.driver.find_elements_by_css_selector('div[class^=\"social-sections-CardSection__card_section\"]'):        \n",
    "                        review_urls.add(_.find_element_by_css_selector('div[class^=\"social-sections-ReviewSection__review_wrap\"]>a').get_attribute('href'))   \n",
    "                \n",
    "#                 self.driver.execute_script('window.scrollTo(0, document.body.scrollHeight);')\n",
    "                \n",
    "#                 height_now = self.driver.execute_script(\"return document.body.scrollHeight\")\n",
    "                \n",
    "#                 print('height_now=',height_now, 'height=', height)\n",
    "                \n",
    "#                 if height_now == height:\n",
    "#                     print('no more scroll, reviews ', len(review_urls))\n",
    "#                     break\n",
    "#                 else:\n",
    "#                     height = height_now\n",
    "\n",
    "            print('collected all review urls..')\n",
    "            print('now starting to collect reviews..')\n",
    "            \n",
    "            for i, url in enumerate(review_urls, 1):\n",
    "                \n",
    "                self.driver.get(url)\n",
    "                time.sleep(3)\n",
    "                \n",
    "                rc = self.driver.find_element_by_css_selector('div.review-container')\n",
    "                    \n",
    "                review_id = rc.get_attribute('data-reviewid')\n",
    "                    \n",
    "                print('review_id=',review_id)\n",
    "                    \n",
    "                try:\n",
    "                    review_date = rc.find_element_by_css_selector('span.ratingDate').get_attribute('title')\n",
    "                    \n",
    "                    print('review date: ', review_date)\n",
    "                except:\n",
    "                    print('no review date')\n",
    "                    \n",
    "                try:\n",
    "                    experience_date = rc.find_element_by_css_selector('div.prw_reviews_stay_date_hsx').text\n",
    "                    print('experience_date: ', experience_date)\n",
    "                except:\n",
    "                    print('no experience datew')\n",
    "                        \n",
    "                print('done: ', i)\n",
    "\n",
    "    \n",
    "    def get_reviews_this_attraction(self, attr_url, min_total_reviews):\n",
    "        \n",
    "        # first go to the attraction page\n",
    "        self.driver.get(attr_url)\n",
    "        \n",
    "        a_id = self.attr_id_from_url(attr_url)\n",
    "        \n",
    "        attr_details = defaultdict(name=None, total_reviews=None, category=None, rating_chart=None)\n",
    "                    \n",
    "        try:\n",
    "            attr_details['name'] = self.driver.find_element_by_css_selector('div.attractionsHeader>h1#HEADING').text\n",
    "        except:\n",
    "            try:\n",
    "                # it's probably a tour provider\n",
    "                tour_operator = self.driver.find_element_by_css_selector('h1[id=\"HEADING\"][class|=\"attractions-supplier-profile-\"]').text.strip()\n",
    "                print(f'looks like a tour operator: {tour_operator}')\n",
    "            except:\n",
    "                pass\n",
    "            \n",
    "        # if this is attraction without name, something is wrong and we are not collecting anything\n",
    "        if not attr_details['name']:\n",
    "            return None\n",
    "        \n",
    "        # how namy reviews does this attractio have?\n",
    "        # if there's no rating (so no reviews) simply return 0 reviews right away\n",
    "        try:\n",
    "            self.driver.find_element_by_css_selector('div.section.rating>a.ui_bubble_rating.noReviewsBubbles')\n",
    "            revs = 0\n",
    "        except BaseException as e:\n",
    "            # so there are some reviews..\n",
    "            try:\n",
    "                # 21,121 Reviews\n",
    "                revs = int(self.driver.find_element_by_css_selector('div.ratingContainer>a>span.reviewCount') \\\n",
    "                            .text.replace(',','').split()[0])\n",
    "            except:\n",
    "                print('failed to find the total number of reviews!')\n",
    "                revs = 0\n",
    "        \n",
    "        if revs < min_total_reviews:\n",
    "            # too few reviews, doesn't make sense to proceed with this attraction\n",
    "            print(f'only {revs:,} reviews, skipping..')\n",
    "            return None\n",
    "        \n",
    "        # save total reviews for this attraction after filtering\n",
    "        nreviews_filtered = self.select_filters()\n",
    "        \n",
    "        print(f'filtered reviews: {nreviews_filtered:,}')\n",
    "\n",
    "        if not nreviews_filtered:\n",
    "            print('skipping..')\n",
    "            return None\n",
    "\n",
    "        try:\n",
    "            attr_details['total_reviews'] = self.driver.find_element_by_css_selector('div.ratingContainer').text.lower()\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "        try:\n",
    "            attr_details['category'] = self.driver.find_element_by_css_selector('span.attractionCategories').text\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "        try:\n",
    "            attr_details['rating_chart'] = [tuple(l.strip().split('\\n')) for l in self.driver.find_element_by_css_selector('ul.ratings_chart').text.split('%') if l.strip()]\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "        # reviews for THIS ATTRACTION\n",
    "        reviews = defaultdict(lambda: defaultdict())\n",
    "        reviews_on_page = [0]\n",
    "        \n",
    "        # keep going until total collected reviews reaches total filtered reviews\n",
    "        while len(reviews) < nreviews_filtered:\n",
    "\n",
    "            try:\n",
    "                reviews_this_page = int(WebDriverWait(self.driver, 10) \\\n",
    "                    .until(EC.visibility_of_element_located((By.CSS_SELECTOR, \n",
    "                            'div[data-contextchoice=\"DETAIL\"]>div.pagination-details'))).text.split('-')[1].strip().split()[0]) \n",
    "            except:\n",
    "                if nreviews_filtered <= 10:\n",
    "                    reviews_this_page = nreviews_filtered\n",
    "                else:\n",
    "                    try:\n",
    "                        # just count rating timestamps if any\n",
    "                        reviews_this_page = len(self.driver.find_elements_by_css_selector('span.ratingDate'))\n",
    "                    except:\n",
    "                        raise Exception('failed to pick the number of reviews on this page!') \n",
    "            \n",
    "            reviews_on_page.append(reviews_this_page)\n",
    "            \n",
    "            to_pick = reviews_on_page[-1] - reviews_on_page[-2]\n",
    "            \n",
    "            picked_reviews = set()\n",
    "\n",
    "            while len(picked_reviews) < to_pick:\n",
    "                \n",
    "                # first unfold all reviews on the page\n",
    "\n",
    "                for c in self.driver.find_elements_by_css_selector('div.entry>p.partial_entry>span[class~=\"ulBlueLinks\"][onclick]'):\n",
    "\n",
    "                    self.do_click(c)\n",
    "\n",
    "                # and now collect all full review texts\n",
    "                review_ids_this_page = set()\n",
    "        \n",
    "                n_review_blocks = len(self.driver.find_elements_by_css_selector('div[class=\"reviewSelector\"][id^=\"review\"]'))\n",
    "                \n",
    "                while len(review_ids_this_page) < n_review_blocks:\n",
    "                        \n",
    "                        for c in self.driver.find_elements_by_css_selector('div[class=\"reviewSelector\"][id^=\"review\"]'):\n",
    "                            \n",
    "                            try:\n",
    "                                _id = c.get_attribute('data-reviewid')\n",
    "                            except:\n",
    "                                continue\n",
    "                                \n",
    "                            if _id:\n",
    "                                review_ids_this_page.add(_id)\n",
    "                            else:\n",
    "                                try:\n",
    "                                    # id here looks like review_489766616\n",
    "                                    _id = c.get_attribute('id').split('_')[-1]\n",
    "                                except BaseException as e:\n",
    "                                    print(str(e))\n",
    "                \n",
    "                # a set of review ids to collect on this page\n",
    "                review_ids_to_collect_this_page = review_ids_this_page - set(reviews)\n",
    "\n",
    "                if review_ids_to_collect_this_page:\n",
    "\n",
    "                    tot_revs = len(review_ids_to_collect_this_page)\n",
    "\n",
    "                else:\n",
    "                    tot_revs = 0\n",
    "                    print('no new reviews on this page!')\n",
    "\n",
    "                p = 0\n",
    "\n",
    "                while p < tot_revs:\n",
    "\n",
    "                    for c in self.driver.find_elements_by_css_selector('div.reviewSelector'):        \n",
    "\n",
    "                        try:\n",
    "\n",
    "                            review_id = c.get_attribute('data-reviewid')\n",
    "                            \n",
    "                            if not review_id:\n",
    "                                continue\n",
    "\n",
    "                            if review_id in review_ids_to_collect_this_page:\n",
    "\n",
    "                                reviews[review_id]['text'] = c.find_element_by_css_selector('div>div>div.entry>p.partial_entry').text.strip()\n",
    "                                \n",
    "                                infotext_css = 'div.member_info>div>div.info_text'\n",
    "                                \n",
    "                                try:\n",
    "                                    # this is where a username should sit\n",
    "                                    username = c.find_element_by_css_selector(infotext_css).text.split('\\n')[0]\n",
    "                                except:\n",
    "                                    # it turns out that sometimes there are legacy anonymous users called\n",
    "                                    # A TripAdvisor Member; check if it's one of these - note a slightly different\n",
    "                                    # structure\n",
    "                                    try:\n",
    "                                        username = c.find_element_by_css_selector('div.member_info>div.info_text').text.split('\\n')[0]\n",
    "                                        if 'member' in username.lower():\n",
    "                                            print(f'found an anonymous user called {username}')\n",
    "                                    except:\n",
    "                                        break\n",
    "                                \n",
    "                                reviews[review_id]['user'] = username\n",
    "                                reviews[review_id]['user_profile_url'] = f'https://www.tripadvisor.com.au/Profile/{username}'\n",
    "                                \n",
    "                                try:\n",
    "                                    userloc = c.find_element_by_css_selector(infotext_css + '>div.userLoc').text\n",
    "                                    reviews[review_id]['user_loc'] = userloc\n",
    "                                    # which country?\n",
    "                                    reviews[review_id]['user_country'] = self.get_country(userloc)\n",
    "                                except:\n",
    "                                    reviews[review_id]['user_loc'] = None\n",
    "                                    \n",
    "                                try:\n",
    "                                    reviews[review_id]['review_date'] = arrow.get(c.find_element_by_css_selector('div>div>div>span.ratingDate')\n",
    "                                                                                    .get_attribute('title'), 'D MMMM YYYY').format('YYYY-MM-DD')\n",
    "                                except:\n",
    "                                    reviews[review_id]['review_date'] = None\n",
    "                                    \n",
    "                                try:\n",
    "                                    reviews[review_id]['experience_date'] = arrow.get(c.find_element_by_css_selector('div>div>div>div.prw_reviews_stay_date_hsx').text, 'MMMM YYYY').format('YYYY-MM')\n",
    "                                except:\n",
    "                                    reviews[review_id]['experience_date'] = None\n",
    "                                \n",
    "                                try:\n",
    "                                    class_full = c.find_element_by_css_selector('div>div>div>span.ui_bubble_rating').get_attribute('class')\n",
    "                                    \n",
    "                                    reviews[review_id]['rating'] = int(re.search(r'(?<=_)\\d{1}', class_full).group(0))\n",
    "                                except:\n",
    "                                    reviews[review_id]['rating'] = None\n",
    "                                          \n",
    "                                reviews[review_id]['attr_name'] = attr_details['name']\n",
    "                                reviews[review_id]['attr_id'] = a_id\n",
    "                                reviews[review_id]['attr_loc'] = city_\n",
    "                                \n",
    "                                # remove this reviews id from the set of review ids to collct\n",
    "                                review_ids_to_collect_this_page -= {review_id}\n",
    "                                # and put this id into the set of already collected ids\n",
    "                                picked_reviews.add(review_id)\n",
    "                                # increment the total of collected reviews on this page\n",
    "                                p += 1\n",
    "\n",
    "                            else:\n",
    "                                continue\n",
    "                        except:\n",
    "                            continue\n",
    "        return reviews\n",
    "    \n",
    "    def _review_count_this_attr(self) -> int:\n",
    "        \n",
    "        \"\"\"\n",
    "        assuming you're on the attraction page, returns how many reviews there are in total for this attractions\n",
    "        \"\"\"\n",
    "        \n",
    "        revs = 0\n",
    "        \n",
    "        # if there's no rating (so no reviews) simply return 0 reviews right away\n",
    "        \n",
    "        try:\n",
    "            # if this one if present there are no reviews\n",
    "            self.driver.find_element_by_css_selector('div.section.rating>a.ui_bubble_rating.noReviewsBubbles')\n",
    "            return revs\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "        # otherwise, there have to be some reviews..\n",
    "        \n",
    "        try:\n",
    "            # the piece of text that says how many reviews looks like this: 21,121 Reviews\n",
    "            revs = int(self.driver.find_element_by_css_selector('div.ratingContainer>a>span.reviewCount') \\\n",
    "                            .text.replace(',','').split()[0])\n",
    "        except:\n",
    "            print('failed to find the total number of reviews!')\n",
    "        \n",
    "        return revs\n",
    "        \n",
    "            \n",
    "    def get_reviews_from_attraction_pages(self, min_total_reviews=50, max_attr=1000):\n",
    "        \n",
    "        \"\"\"\n",
    "        assuming that we already have attraction URLs in self.collected_attractions, visit every URL and \n",
    "        grab more details about the attraction as well as all reviews\n",
    "        \n",
    "        note: max_attr is useful for testing\n",
    "        \"\"\"\n",
    "        \n",
    "        # total number of attractions to check out based on the total of unique attaraction IDs \n",
    "        natt = len({a_id for state_ in self.collected_attractions\n",
    "                        for city_ in self.collected_attractions[state_]\n",
    "                             for a_id in self.collected_attractions[state_][city_]})\n",
    "        \n",
    "        # counter for processed attractions\n",
    "        catt = 0\n",
    "        \n",
    "        for state_ in self.collected_attractions:\n",
    "            for city_ in self.collected_attractions[state_]:\n",
    "                for a_id in self.collected_attractions[state_][city_]:\n",
    "                    \n",
    "                    catt += 1\n",
    "                    \n",
    "                    if catt > max_attr:\n",
    "                        print(f'stopped because done {max_attr:,} attractions')\n",
    "                        break\n",
    "                        \n",
    "                    self.driver.get(self.collected_attractions[state_][city_][a_id]['url'])\n",
    "                    \n",
    "                    attr_details = defaultdict(name=None, total_reviews=None, category=None, rating_chart=None)\n",
    "                    \n",
    "                    try:\n",
    "                        attr_details['name'] = self.driver.find_element_by_css_selector('div.attractionsHeader>h1#HEADING').text\n",
    "                    except:\n",
    "                        try:\n",
    "                            # it's probably a tour provider\n",
    "                            tour_operatior_name = self.driver.find_element_by_css_selector('h1[id=\"HEADING\"][class|=\"attractions-supplier-profile-\"]').text.strip()\n",
    "                            print(f'looks like a tour operator: {tour_operatior_name}; skipping')\n",
    "                            continue\n",
    "                        except:\n",
    "                            print(f'failed to find name for attraction {a_id}, skipping..')\n",
    "                            continue\n",
    "                            \n",
    "                    print(f'attraction #{catt:,}/{natt:,}: [ID: {a_id}][{attr_details[\"name\"]}]...')\n",
    "                    \n",
    "                    # how many reviews does this attraction have?\n",
    "                    revs = self._review_count_this_attr()\n",
    "                    \n",
    "                    if revs < min_total_reviews:\n",
    "                        # too few reviews, doesn't make sense to proceed with this attraction\n",
    "                        print(f'only {revs:,} reviews, skipping..')\n",
    "                        continue\n",
    "                    \n",
    "                    # save total reviews for this attraction after filtering\n",
    "                    self.FILTREVS[a_id] = self.select_filters()\n",
    "                    \n",
    "                    print(f'filtered reviews: {self.FILTREVS[a_id]:,}')\n",
    "\n",
    "                    if not self.FILTREVS[a_id]:\n",
    "                        print('skipping..')\n",
    "                        continue\n",
    "                    \n",
    "                    # note that total reviews doesn't depend on filtering\n",
    "                    try:\n",
    "                        attr_details['total_reviews'] = int(self.driver.find_element_by_css_selector('div.ratingContainer').text.split()[0].replace(',',''))\n",
    "                    except:\n",
    "                        pass\n",
    "\n",
    "                    try:\n",
    "                        attr_details['category'] = self.driver.find_element_by_css_selector('span.attractionCategories').text.lower().strip()\n",
    "                    except:\n",
    "                        pass\n",
    "\n",
    "                    try:\n",
    "                        attr_details['rating_chart'] = [tuple(l.strip().split('\\n')) for l in self.driver.find_element_by_css_selector('ul.ratings_chart').text.split('%') if l.strip()]\n",
    "                    except:\n",
    "                        pass\n",
    "                    \n",
    "                    # add new attraction info\n",
    "                    self.collected_attractions[state_][city_][a_id]['attr_name'] = attr_details['name']\n",
    "                    self.collected_attractions[state_][city_][a_id]['category'] = attr_details['category']\n",
    "                    self.collected_attractions[state_][city_][a_id]['total_reviews'] = attr_details['total_reviews']\n",
    "\n",
    "                    # reviews for THIS ATTRACTION\n",
    "                    reviews = defaultdict(lambda: defaultdict())\n",
    "                    reviews_on_page = [0]\n",
    "\n",
    "                    while len(reviews) < self.FILTREVS[a_id]:\n",
    "\n",
    "                        try:\n",
    "                            reviews_this_page = int(WebDriverWait(self.driver, 10) \\\n",
    "                                .until(EC.visibility_of_element_located((By.CSS_SELECTOR, \n",
    "                                        'div[data-contextchoice=\"DETAIL\"]>div.pagination-details'))).text.split('-')[1].strip().split()[0]) \n",
    "                        except:\n",
    "                            if self.FILTREVS[a_id] <= 10:\n",
    "                                reviews_this_page = self.FILTREVS[a_id]\n",
    "                            else:\n",
    "                                try:\n",
    "                                    # just count rating timestamps if any\n",
    "                                    reviews_this_page = len(self.driver.find_elements_by_css_selector('span.ratingDate'))\n",
    "                                except:\n",
    "                                    raise Exception('failed to pick the number of reviews on this page!') \n",
    "                        \n",
    "                        reviews_on_page.append(reviews_this_page)\n",
    "                        \n",
    "                        to_pick = reviews_on_page[-1] - reviews_on_page[-2]\n",
    "                        \n",
    "                        picked_reviews = set()\n",
    "\n",
    "                        while len(picked_reviews) < to_pick:\n",
    "                            \n",
    "                            # first unfold all reviews on the page\n",
    "\n",
    "                            for c in self.driver.find_elements_by_css_selector('div.entry>p.partial_entry>span[class~=\"ulBlueLinks\"][onclick]'):\n",
    "\n",
    "                                self.do_click(c)\n",
    "\n",
    "                            # and now collect all full review texts\n",
    "                            review_ids_this_page = set()\n",
    "                \n",
    "                            n_review_blocks = len(self.driver.find_elements_by_css_selector('div[class=\"reviewSelector\"][id^=\"review\"]'))\n",
    "                            \n",
    "                            while len(review_ids_this_page) < n_review_blocks:\n",
    "                                    \n",
    "                                    for c in self.driver.find_elements_by_css_selector('div[class=\"reviewSelector\"][id^=\"review\"]'):\n",
    "                                        \n",
    "                                        try:\n",
    "                                            _id = c.get_attribute('data-reviewid')\n",
    "                                        except:\n",
    "                                            continue\n",
    "                                            \n",
    "                                        if _id:\n",
    "                                            review_ids_this_page.add(_id)\n",
    "                                        else:\n",
    "                                            try:\n",
    "                                                # id here looks like review_489766616\n",
    "                                                _id = c.get_attribute('id').split('_')[-1]\n",
    "                                            except BaseException as e:\n",
    "                                                print(str(e))\n",
    "                            \n",
    "                            # a set of review ids to collect on this page\n",
    "                            review_ids_to_collect_this_page = review_ids_this_page - set(reviews)\n",
    "\n",
    "                            if review_ids_to_collect_this_page:\n",
    "\n",
    "                                tot_revs = len(review_ids_to_collect_this_page)\n",
    "\n",
    "                            else:\n",
    "                                tot_revs = 0\n",
    "                                print('no new reviews on this page!')\n",
    "\n",
    "                            p = 0\n",
    "\n",
    "                            while p < tot_revs:\n",
    "\n",
    "                                for c in self.driver.find_elements_by_css_selector('div.reviewSelector'):        \n",
    "\n",
    "                                    try:\n",
    "\n",
    "                                        review_id = c.get_attribute('data-reviewid')\n",
    "                                        \n",
    "                                        if not review_id:\n",
    "                                            continue\n",
    "\n",
    "                                        if review_id in review_ids_to_collect_this_page:\n",
    "\n",
    "                                            reviews[review_id]['text'] = c.find_element_by_css_selector('div>div>div.entry>p.partial_entry').text.strip()\n",
    "                                            \n",
    "                                            infotext_css = 'div.member_info>div>div.info_text'\n",
    "                                            \n",
    "                                            try:\n",
    "                                                # this is where a username should sit\n",
    "                                                username = c.find_element_by_css_selector(infotext_css).text.split('\\n')[0]\n",
    "                                            except:\n",
    "                                                # it turns out that sometimes there are legacy anonymous users called\n",
    "                                                # A TripAdvisor Member; check if it's one of these - note a slightly different\n",
    "                                                # structure\n",
    "                                                try:\n",
    "                                                    username = c.find_element_by_css_selector('div.member_info>div.info_text').text.split('\\n')[0]\n",
    "                                                    if 'member' in username.lower():\n",
    "                                                        print(f'found an anonymous user called {username}')\n",
    "                                                except:\n",
    "                                                    break\n",
    "                                            \n",
    "                                            reviews[review_id]['user'] = username\n",
    "                                            reviews[review_id]['user_profile_url'] = f'https://www.tripadvisor.com.au/Profile/{username}'\n",
    "                                            \n",
    "                                            try:\n",
    "                                                userloc = c.find_element_by_css_selector(infotext_css + '>div.userLoc').text\n",
    "                                                reviews[review_id]['user_loc'] = userloc\n",
    "                                                reviews[review_id]['user_country'] = self.get_country(userloc)\n",
    "                                            except:\n",
    "                                                reviews[review_id]['user_loc'] = None\n",
    "                                                \n",
    "                                            try:\n",
    "                                                reviews[review_id]['review_date'] = arrow.get(c.find_element_by_css_selector('div>div>div>span.ratingDate')\n",
    "                                                                                                .get_attribute('title'), 'D MMMM YYYY').format('YYYY-MM-DD')\n",
    "                                            except:\n",
    "                                                reviews[review_id]['review_date'] = None\n",
    "                                                \n",
    "                                            try:\n",
    "                                                reviews[review_id]['experience_date'] = arrow.get(c.find_element_by_css_selector('div>div>div>div.prw_reviews_stay_date_hsx').text, 'MMMM YYYY').format('YYYY-MM')\n",
    "                                            except:\n",
    "                                                reviews[review_id]['experience_date'] = None\n",
    "                                            \n",
    "                                            try:\n",
    "                                                class_full = c.find_element_by_css_selector('div>div>div>span.ui_bubble_rating').get_attribute('class')\n",
    "                                                \n",
    "                                                reviews[review_id]['rating'] = int(re.search(r'(?<=_)\\d{1}', class_full).group(0))\n",
    "                                            except:\n",
    "                                                reviews[review_id]['rating'] = None\n",
    "                                                \n",
    "                                            try:\n",
    "                                                reviews[review_id]['votes'] = int(c.find_element_by_css_selector('span.ui_icon.thumbs-up-fill + span').text.strip())\n",
    "                                            except:\n",
    "                                                # if there's no helpful notes there's no thumbs up icon\n",
    "                                                reviews[review_id]['votes'] = 0\n",
    "                                                \n",
    "                                            try:\n",
    "                                                reviews[review_id]['contributions'] = int(c.find_element_by_css_selector('span.ui_icon.pencil-paper + span').text.strip())\n",
    "                                            except:\n",
    "                                                print('failed to get total contributions')\n",
    "                                                reviews[review_id]['contributions'] = 0\n",
    "                                                      \n",
    "                                            reviews[review_id]['attr_name'] = attr_details['name']\n",
    "                                            reviews[review_id]['attr_id'] = a_id\n",
    "                                            reviews[review_id]['attr_loc'] = city_\n",
    "                                            \n",
    "                                            # remove this reviews id from the set of review ids to collct\n",
    "                                            review_ids_to_collect_this_page -= {review_id}\n",
    "                                            # and put this id into the set of already collected ids\n",
    "                                            picked_reviews.add(review_id)\n",
    "                                            # increment the total of collected reviews on this page\n",
    "                                            p += 1\n",
    "\n",
    "                                        else:\n",
    "                                            continue\n",
    "                                    except:\n",
    "                                        continue\n",
    "\n",
    "                        # now try to click Next\n",
    "                        npage_url = None\n",
    "\n",
    "                        if self.FILTREVS[a_id] <= 10:\n",
    "                            last_page_url = self.driver.current_url\n",
    "                        else:\n",
    "                            try:\n",
    "                                last_page_url = list(self.driver.find_elements_by_css_selector('div.mobile-more>div>div.unified.ui_pagination>div.pageNumbers>a[href]'))[-1].get_attribute('href')\n",
    "                            except:\n",
    "                                last_page_url = self.driver.current_url \n",
    "\n",
    "                        if self.driver.current_url != last_page_url:\n",
    "\n",
    "                            # https://www.tripadvisor.com.au/Attraction_Review-g255097-d1063162-Reviews-or20-Mount_Wellington-Hobart_Greater_Hobart_Tasmania.html\n",
    "\n",
    "                            try:\n",
    "                                pref = int(re.search(r'(?<=-Reviews-or)\\d+', self.driver.current_url).group(0))\n",
    "                            except:\n",
    "                                pref = None\n",
    "\n",
    "                            if pref:\n",
    "                                next_page_url = self.driver.current_url.replace('or' + str(pref), 'or' + str(pref+10))\n",
    "                            else:\n",
    "                                next_page_url = self.driver.current_url.replace('Reviews-', 'Reviews-' + 'or' + str(10) + '-')\n",
    "\n",
    "                            if next_page_url != self.driver.current_url:\n",
    "                                self.driver.get(next_page_url)\n",
    "\n",
    "                        # add reviews for THIS attraction to the dictionary of ALL reviews\n",
    "                        self.REVIEWS.update(reviews)\n",
    "        \n",
    "        self.driver.close()\n",
    "        \n",
    "        return self\n",
    "        \n",
    "    def save_reviews(self):\n",
    "        \n",
    "        if not len(self.REVIEWS):\n",
    "            print('no reviews so nothing to save...')\n",
    "            return self\n",
    "            \n",
    "        file = '-'.join(['reviews', self.MAIN_LOCATION.replace(\" \",\"_\").upper(), \n",
    "                         self.FILTERS['traveller_type'], self.FILTERS['traveller_rating'], \n",
    "                         self.FILTERS['time_of_year']]) + '.json'\n",
    "            \n",
    "        json.dump(self.REVIEWS, open(os.path.join(self.COLLECT_DIR, file), 'w'))\n",
    "        \n",
    "        print(f'saved {len(self.REVIEWS):,} reviews')\n",
    "            \n",
    "        return self\n",
    "    \n",
    "    def save_attractions(self):\n",
    "    \n",
    "        json.dump(self.collected_attractions, \n",
    "                  open(os.path.join(self.COLLECT_DIR, \n",
    "                                    f'attractions-{self.MAIN_LOCATION.replace(\" \",\"_\").upper()}.json'), 'w'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[FILTER]: traveller_rating: Excellent | traveller_type: Friends | time_of_year: Jun-Aug | language: English\n",
      "\n",
      "collecting attractions for HOBART, TASMANIA...\n"
     ]
    },
    {
     "ename": "WebDriverException",
     "evalue": "Message: unknown error: cannot determine loading status\nfrom unknown error: cannot determine loading status\nfrom disconnected: received Inspector.detached event\n  (Session info: chrome=76.0.3809.132)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mWebDriverException\u001b[0m                        Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-a8c7519fcf50>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m                        \u001b[0;34m'time_of_year'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'Jun-Aug'\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# note that this refers to review date (and NOT experience date)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m                        'language':'English'}) \\\n\u001b[0;32m----> 7\u001b[0;31m                     \u001b[0;34m.\u001b[0m\u001b[0mget_attraction_pages\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'tasmania'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m                         \u001b[0;34m.\u001b[0m\u001b[0mget_reviews_from_attraction_pages\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmin_total_reviews\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m170\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_attr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m                             \u001b[0;34m.\u001b[0m\u001b[0msave_reviews\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-6-750b98bbb7da>\u001b[0m in \u001b[0;36mget_attraction_pages\u001b[0;34m(self, loc)\u001b[0m\n\u001b[1;32m    156\u001b[0m            \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'collecting attractions for {city_.upper()}, {state_.upper()}...'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    157\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 158\u001b[0;31m            \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdriver\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhomeurl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    159\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    160\u001b[0m            \u001b[0;31m# ---- find and click the Things to Do icon; assume it MUST be there\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/selenium/webdriver/remote/webdriver.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, url)\u001b[0m\n\u001b[1;32m    331\u001b[0m         \u001b[0mLoads\u001b[0m \u001b[0ma\u001b[0m \u001b[0mweb\u001b[0m \u001b[0mpage\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mcurrent\u001b[0m \u001b[0mbrowser\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    332\u001b[0m         \"\"\"\n\u001b[0;32m--> 333\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mCommand\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGET\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'url'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    334\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    335\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/selenium/webdriver/remote/webdriver.py\u001b[0m in \u001b[0;36mexecute\u001b[0;34m(self, driver_command, params)\u001b[0m\n\u001b[1;32m    319\u001b[0m         \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcommand_executor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdriver_command\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    320\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 321\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merror_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcheck_response\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    322\u001b[0m             response['value'] = self._unwrap_value(\n\u001b[1;32m    323\u001b[0m                 response.get('value', None))\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/selenium/webdriver/remote/errorhandler.py\u001b[0m in \u001b[0;36mcheck_response\u001b[0;34m(self, response)\u001b[0m\n\u001b[1;32m    240\u001b[0m                 \u001b[0malert_text\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'alert'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'text'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    241\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mexception_class\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscreen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstacktrace\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malert_text\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 242\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mexception_class\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscreen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstacktrace\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    243\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    244\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_value_or_default\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdefault\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mWebDriverException\u001b[0m: Message: unknown error: cannot determine loading status\nfrom unknown error: cannot determine loading status\nfrom disconnected: received Inspector.detached event\n  (Session info: chrome=76.0.3809.132)\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    \n",
    "    t = Trip(filter={'traveller_rating': 'Excellent', \n",
    "                      'traveller_type':'Friends', \n",
    "                       'time_of_year': 'Jun-Aug',  # note that this refers to review date (and NOT experience date)\n",
    "                       'language':'English'}) \\\n",
    "                    .get_attraction_pages('tasmania') \\\n",
    "                        .get_reviews_from_attraction_pages(min_total_reviews=170, max_attr=2) \\\n",
    "                            .save_reviews() \\\n",
    "                                .save_attractions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[FILTER]: traveller_rating: Excellent | traveller_type: Friends | time_of_year: Jun-Aug | language: English\n",
      "\n"
     ]
    }
   ],
   "source": [
    "t = Trip(filter={'traveller_rating': 'Excellent', \n",
    "                      'traveller_type':'Friends', \n",
    "                       'time_of_year': 'Jun-Aug',  # note that this refers to review date (and NOT experience date)\n",
    "                       'language':'English'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://www.tripadvisor.com.au/CheapFlightsHome\n",
      "https://www.tripadvisor.com.au/Rentals\n",
      "https://www.tripadvisor.com.au/Restaurants\n",
      "https://www.tripadvisor.com.au/Attractions\n",
      "https://www.tripadvisor.com.au/Profile/Sheraton2417\n",
      "https://www.tripadvisor.com.au/Profile/Sheraton2417?tab=photos\n",
      "https://www.tripadvisor.com.au/Profile/Sheraton2417?tab=reviews\n",
      "https://www.tripadvisor.com.au/members-badgecollection/Sheraton2417\n",
      "https://www.tripadvisor.com.au/TravelMap-a_uid.C55FB0C1DE87C4985FD31D0EEDF2BE23\n",
      "https://www.tripadvisor.com.au/Profile/Sheraton2417\n",
      "https://www.tripadvisor.com.au/Profile/Sheraton2417?tab=photos\n",
      "https://www.tripadvisor.com.au/Profile/Sheraton2417?tab=reviews\n",
      "https://www.tripadvisor.com.au/members-badgecollection/Sheraton2417\n",
      "https://www.tripadvisor.com.au/TravelMap-a_uid.C55FB0C1DE87C4985FD31D0EEDF2BE23\n",
      "https://www.tripadvisor.com.au/Profile/Sheraton2417?tab=photos\n",
      "https://www.tripadvisor.com.au/Profile/Sheraton2417?tab=reviews\n",
      "failed to collect reviewer stats!\n",
      "defaultdict(None, {'display_name': 'S2417', 'user_name': 'Sheraton2417', 'reviews': 75, 'location': 'Bangkok, Thailand', 'info': 'Seasoned Businessman who travels across Asia for work. Marriott Bonvoy Elite Member.'})\n",
      "collecting 75 reviews by Sheraton2417...\n",
      "found See More\n",
      "trying to click..\n",
      "collected all review urls..\n",
      "now starting to collect reviews..\n",
      "review_id= 689982949\n",
      "review date:  16 July 2019\n",
      "experience_date:  Date of stay: July 2019\n",
      "done:  1\n",
      "review_id= 689359926\n",
      "review date:  14 July 2019\n",
      "experience_date:  Date of experience: July 2019\n",
      "done:  2\n",
      "review_id= 699102824\n",
      "review date:  15 August 2019\n",
      "experience_date:  Date of experience: June 2019\n",
      "done:  3\n",
      "review_id= 699091900\n",
      "review date:  15 August 2019\n",
      "experience_date:  Date of travel: July 2019\n",
      "done:  4\n",
      "review_id= 687389463\n",
      "review date:  7 July 2019\n",
      "experience_date:  Date of visit: July 2019\n",
      "done:  5\n",
      "review_id= 689362496\n",
      "review date:  14 July 2019\n",
      "experience_date:  Date of visit: July 2019\n",
      "done:  6\n",
      "review_id= 687670686\n",
      "review date:  8 July 2019\n",
      "experience_date:  Date of visit: June 2019\n",
      "done:  7\n"
     ]
    }
   ],
   "source": [
    "t.process_user_profile('https://www.tripadvisor.com.au/Profile/Sheraton2417')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
